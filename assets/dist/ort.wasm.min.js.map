{"version":3,"sources":["../../common/lib/backend-impl.ts","../../common/lib/backend.ts","../../common/lib/version.ts","../../common/lib/env-impl.ts","../../common/lib/env.ts","../../common/lib/tensor-conversion-impl.ts","../../common/lib/tensor-factory-impl.ts","../../common/lib/tensor-impl-type-mapping.ts","../../common/lib/tensor-utils-impl.ts","../../common/lib/tensor-impl.ts","../../common/lib/tensor.ts","../../common/lib/trace.ts","../../common/lib/inference-session-impl.ts","../../common/lib/inference-session.ts","../../common/lib/tensor-conversion.ts","../../common/lib/tensor-factory.ts","../../common/lib/onnx-model.ts","../../common/lib/onnx-value.ts","../../common/lib/index.ts","../lib/wasm/wasm-utils-env.ts","../lib/wasm/proxy-worker/main.ts","../lib/wasm/wasm-utils-import.ts","../lib/wasm/wasm-factory.ts","../lib/wasm/wasm-utils.ts","../lib/wasm/run-options.ts","../lib/wasm/session-options.ts","../lib/wasm/wasm-common.ts","../lib/wasm/wasm-utils-load-file.ts","../lib/wasm/wasm-core-impl.ts","../lib/wasm/proxy-wrapper.ts","../lib/wasm/session-handler-inference.ts","../lib/backend-wasm.ts","../lib/index.ts","../lib/version.ts"],"names":["backends","backendsSortedByPriority","registerBackend","tryResolveAndInitializeBackend","resolveBackendAndExecutionProviders","init_backend_impl","__esmMin","name","backend","priority","currentBackend","i","backendName","backendInfo","isInitializing","e","options","eps","backendHints","backendNames","errors","availableBackendNames","resolveResult","err","filteredEps","target","prop","init_backend","version","init_version","logLevelValue","env","init_env_impl","value","init_env","tensorToDataURL","tensorToImageData","init_tensor_conversion_impl","tensor","canvas","pixels2DContext","width","height","inputformat","norm","normMean","normBias","stride","rTensorPointer","gTensorPointer","bTensorPointer","aTensorPointer","j","R","G","B","A","image","channels","step","rImagePointer","gImagePointer","bImagePointer","aImagePointer","bufferToTensor","tensorFromImage","tensorFromTexture","tensorFromGpuBuffer","tensorFromMLTensor","tensorFromPinnedBuffer","init_tensor_factory_impl","init_tensor_impl","buffer","outputformat","float32Data","Tensor","isHTMLImageEle","isImageDataEle","isImageBitmap","isString","data","bufferToTensorOptions","createCanvas","createCanvasContext","tempCanvas","resolve","reject","context","newImage","img","texture","download","dispose","dims","gpuBuffer","dataType","mlTensor","type","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","isTypedArrayChecked","checkTypedArray","init_tensor_impl_type_mapping","isBigInt64ArrayAvailable","isBigUint64ArrayAvailable","Float16Array","isFloat16ArrayAvailable","calculateSize","tensorReshape","init_tensor_utils_impl","size","dim","arg0","arg1","arg2","expectedTypedArrayConstructor","maybeDims","typedArrayConstructor","firstElementType","mappedType","releaseData","init_tensor","TRACE","TRACE_FUNC","TRACE_FUNC_BEGIN","TRACE_FUNC_END","TRACE_EVENT_BEGIN","TRACE_EVENT_END","init_trace","deviceType","label","msg","extraMsg","stack","hasTraceFunc","InferenceSession","init_inference_session_impl","_InferenceSession","handler","feeds","fetches","isFetchesEmpty","isFetches","arg1Keys","v","results","returnValue","key","result","arg3","filePathOrUint8Array","byteOffset","byteLength","optionsWithValidatedEPs","init_inference_session","init_tensor_conversion","init_tensor_factory","init_onnx_model","init_onnx_value","esm_exports","__export","init_esm","init_wasm_utils_env","main_exports","main_default","WORKER_NAME","isProxyWorker","init_main","init_wasm_core_impl","init_wasm_factory","init_wasm_utils_import","ev","message","initializeWebAssembly","initRuntime","epName","initEp","bufferData","copyFromExternalBuffer","model","createSession","sessionMetadata","releaseSession","sessionId","inputIndices","inputs","outputIndices","run","outputs","o","extractTransferableBuffers","endProfiling","urlOverride","scriptSrc","origin","getScriptSrc","inferWasmPathPrefixFromScriptSrc","isSameOrigin","normalizeUrl","fallbackUrl","preload","dynamicImportDefault","createProxyWorker","importProxyWorker","embeddedWasmModule","importWasmModule","filename","prefixOverride","baseUrl","absoluteUrl","blob","url","isMultiThreaded","isWasmOverridden","useEmbeddedModule","wasmModuleFilename","wasmModuleUrl","needPreload","wasm","initialized","initializing","aborted","isMultiThreadSupported","isSimdSupported","isRelaxedSimdSupported","getInstance","flags","timeout","numThreads","multiThreadSupported","wasmPaths","wasmPrefixOverride","mjsPathOverrideFlag","mjsPathOverride","wasmPathOverrideFlag","wasmPathOverride","wasmBinaryOverride","objectUrl","ortWasmFactory","isTimeout","tasks","config","fileName","inferredWasmPathPrefix","module","what","allocWasmString","iterateExtraOptions","checkLastError","init_wasm_utils","allocs","dataLength","dataOffset","prefix","seen","ptrSize","paramsOffset","errorCode","errorMessagePointer","errorMessage","setRunOptions","init_run_options","runOptionsHandle","runOptions","tagDataOffset","keyDataOffset","valueDataOffset","alloc","getGraphOptimzationLevel","getExecutionMode","appendDefaultOptions","appendSessionConfig","setExecutionProviders","setSessionOptions","init_session_options","graphOptimizationLevel","executionMode","session","ep","sessionOptionsHandle","executionProviders","epOptions","webgpuOptions","epNameDataOffset","epOptionsCount","keysOffset","valuesOffset","sessionOptions","logIdDataOffset","logSeverityLevel","logVerbosityLevel","optimizedModelFilePathOffset","nameOffset","tensorDataTypeStringToEnum","tensorDataTypeEnumToString","calculateTensorSizeInBytes","tensorTypeToTypedArrayConstructor","logLevelStringToEnum","isGpuBufferSupportedType","isMLTensorSupportedType","dataLocationStringToEnum","init_wasm_common","typeProto","dateType","dimsOrSize","elementSize","a","b","logLevel","location","loadFile","init_wasm_utils_load_file","file","readFile","createReadStream","stream","chunks","chunk","response","contentLengthHeader","fileSize","reader","pages","offset","done","chunkSize","initOrt","activeSessions","getSessionInputOutputCount","getSessionInputOutputMetadata","prepareInputOutputTensor","loggingLevel","webgpuAdapter","powerPreference","forceFallbackAdapter","sessionHandle","index","metadataOffset","elementType","dimsCount","symbolicDimNameOffset","modelDataOffset","modelData","modelDataLength","ioBindingHandle","inputNamesUTF8Encoded","outputNamesUTF8Encoded","loadingPromises","path","provider","webnnOptions","gpuDevice","inputCount","outputCount","enableGraphCapture","inputNames","outputNames","inputMetadata","outputMetadata","outputPreferredLocations","shape","nameString","buf","ioBindingState","tensorHandles","tensorNameUTF8Encoded","actualLocation","rawData","dataByteLength","registerBuffer","registerMLTensor","isGraphInput","isGraphOutput","tensorName","dataTypeEnum","createTemporaryTensor","uploadTensor","tensorId","dimsOffset","d","inputTensors","outputTensors","inputOutputBound","runOptionsAllocs","inputTensorHandles","outputTensorHandles","inputOutputAllocs","preAllocatedOutputs","beforeRunStack","inputValuesOffset","inputNamesOffset","outputValuesOffset","outputNamesOffset","output","outputPromises","beforeGetTensorDataStack","tensorDataOffset","keepOutputTensor","valueType","dimsLength","preferredLocation","stringData","nextOffset","maxBytesToRead","getBuffer","bufferSize","ensureTensor","isGraphInputOutputTypeSupported","p","profileFileName","tensors","buffers","isProxy","proxyWorker","temporaryObjectUrl","initWasmCallbacks","queuedCallbacks","enqueueCallbacks","ensureWorker","onProxyWorkerMessage","initializeWebAssemblyAndOrtRuntime","initializeOrtEp","init_proxy_wrapper","callbacks","queue","worker","transferable","t","serializableInputs","encodeTensorMetadata","decodeTensorMetadata","OnnxruntimeWebAssemblySessionHandler","init_session_handler_inference","getName","pathOrBuffer","inputArray","kvp","outputArray","resultMap","backend_wasm_exports","OnnxruntimeWebAssemblyBackend","initializeFlags","wasmBackend","init_backend_wasm","simd","numCpuLogicalCores","index_exports","index_default"],"mappings":";;;;;kuBAAA,IAgBMA,GACAC,EAYOC,GAwCPC,GAwCOC,GA7GbC,GAAAC,EAAA,kBAgBMN,GAAqC,IAAI,IACzCC,EAAqC,CAAA,EAY9BC,GAAkB,CAACK,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBV,GAAS,IAAIO,CAAI,EACxC,GAAIG,IAAmB,OACrBV,GAAS,IAAIO,EAAM,CAAE,QAAAC,EAAS,SAAAC,CAAQ,CAAE,MACnC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIV,EAAyB,QAAQM,CAAI,EAC3CI,IAAM,IACRV,EAAyB,OAAOU,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIV,EAAyB,OAAQU,IACnD,GAAIX,GAAS,IAAIC,EAAyBU,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnER,EAAyB,OAAOU,EAAG,EAAGJ,CAAI,EAC1C,OAGJN,EAAyB,KAAKM,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAQMJ,GAAiC,MAAOS,GAAkD,CAC9F,IAAMC,EAAcb,GAAS,IAAIY,CAAW,EAC5C,GAAI,CAACC,EACH,MAAO,qBAGT,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,OAAOA,EAAY,MACd,CACL,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAKD,CAAW,GAEhE,MAAMC,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACV,OAAKD,IACHD,EAAY,MAAQ,GAAGE,CAAC,GACxBF,EAAY,QAAU,IAEjBA,EAAY,cAEnB,OAAOA,EAAY,aAGzB,EAWaT,GAAsC,MACjDY,GACyE,CAEzE,IAAMC,EAAMD,EAAQ,oBAAsB,CAAA,EACpCE,EAAeD,EAAI,IAAKN,GAAO,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAK,EAClEQ,EAAeD,EAAa,SAAW,EAAIjB,EAA2BiB,EAGxEV,EACEY,EAAS,CAAA,EACTC,EAAwB,IAAI,IAClC,QAAWT,KAAeO,EAAc,CACtC,IAAMG,EAAgB,MAAMnB,GAA+BS,CAAW,EAClE,OAAOU,GAAkB,SAC3BF,EAAO,KAAK,CAAE,KAAMR,EAAa,IAAKU,CAAa,CAAE,GAEhDd,IACHA,EAAUc,GAERd,IAAYc,GACdD,EAAsB,IAAIT,CAAW,GAM3C,GAAI,CAACJ,EACH,MAAM,IAAI,MAAM,oCAAoCY,EAAO,IAAKL,GAAM,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,EAI5G,OAAW,CAAE,KAAAR,EAAM,IAAAgB,CAAG,IAAMH,EACtBF,EAAa,SAASX,CAAI,GAE5B,QAAQ,KACN,0CAA0CA,CAAI,uDAAuDgB,CAAG,EAAE,EAKhH,IAAMC,EAAcP,EAAI,OAAQN,GAAMU,EAAsB,IAAI,OAAOV,GAAM,SAAWA,EAAIA,EAAE,IAAI,CAAC,EAEnG,MAAO,CACLH,EACA,IAAI,MAAMQ,EAAS,CACjB,IAAK,CAACS,EAAQC,IACRA,IAAS,qBACJF,EAEF,QAAQ,IAAIC,EAAQC,CAAI,EAElC,EAEL,ICnKA,IAAAC,GAAArB,EAAA,kBA+DAD,OC/DA,IAMauB,GANbC,GAAAvB,EAAA,kBAMasB,GAAU,WCNvB,IAQIE,GAESC,EAVbC,GAAA1B,EAAA,kBAIAuB,KAIIC,GAAwC,UAE/BC,EAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAE,OAAQH,EAAO,EAE3B,IAAI,SAASK,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDH,GAAgBG,EAClB,EACA,IAAI,UAAQ,CACV,OAAOH,EACT,GAIF,OAAO,eAAeC,EAAK,WAAY,CAAE,WAAY,EAAI,CAAE,IC/B3D,IA2SaA,EA3SbG,GAAA5B,EAAA,kBAGA0B,KAwSaD,EAAWA,IC3SxB,IASaI,GAmGAC,GA5GbC,GAAA/B,EAAA,kBASa6B,GAAkB,CAACG,EAAgBtB,IAA4C,CAC1F,IAAMuB,EAAS,OAAO,SAAa,IAAc,SAAS,cAAc,QAAQ,EAAI,IAAI,gBAAgB,EAAG,CAAC,EAC5GA,EAAO,MAAQD,EAAO,KAAK,CAAC,EAC5BC,EAAO,OAASD,EAAO,KAAK,CAAC,EAC7B,IAAME,EAAkBD,EAAO,WAAW,IAAI,EAK9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACA1B,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,IAGtBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,GAGxB,IAAMK,EAAc3B,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/D4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASpC,EAAI,EAAGA,EAAI+B,EAAQ/B,IAC1B,QAASyC,EAAI,EAAGA,EAAIX,EAAOW,IAAK,CAC9B,IAAMC,GAAMf,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1ES,GAAMhB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMjB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,EAAIL,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE9GL,EAAgB,UAAY,QAAUa,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEhB,EAAgB,SAASY,EAAGzC,EAAG,EAAG,CAAC,EAGvC,GAAI,cAAe4B,EACjB,OAAOA,EAAO,UAAS,EAEvB,MAAM,IAAI,MAAM,4BAA4B,MAG9C,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaH,GAAoB,CAACE,EAAgBtB,IAAiD,CACjG,IAAMwB,EACJ,OAAO,SAAa,IAChB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EAC/C,IAAI,gBAAgB,EAAG,CAAC,EAAE,WAAW,IAAI,EAC5CiB,EACJ,GAAIjB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAgB,EACA1C,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,IAGxBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,GAE1B,IAAMK,EAAc3B,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhG4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIzB,IAAY,SAEXA,EAAQ,SAAW,QAAa0C,IAAa,GAAK1C,EAAQ,SAAW,QACrE0C,IAAa,GAAK1C,EAAQ,SAAW,OAASA,EAAQ,SAAW,OAElE,MAAM,IAAI,MAAM,+CAA+C,EAKnE,IAAM2C,EAAO,EACTC,EAAgB,EAClBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BU,EAAQjB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QACM/B,EAAI,EACRA,EAAI+B,EAASD,EACbmB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMhD,IAE5F8C,EAAM,KAAKG,CAAa,GAAMtB,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKI,CAAa,GAAMvB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKK,CAAa,GAAMxB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKM,CAAa,EACtBZ,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAGxG,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOY,CACT,ICrNA,IAkCaO,GA8FAC,GAoKAC,GAaAC,GAWAC,GAWAC,GAvUbC,GAAAhE,EAAA,kBAiBAiE,KAiBaP,GAAiB,CAACQ,EAAuCxD,IAA0C,CAC9G,GAAIwD,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIxD,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAE,OAAA0B,EAAQ,MAAAD,CAAK,EAAKzB,EAEpB4B,EAAO5B,EAAQ,MAAQ,CAAE,KAAM,IAAK,KAAM,CAAC,EAC7C6B,EACAC,EAEA,OAAOF,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAOA,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMD,EAAc3B,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DyD,EACJzD,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACvG+B,EAASL,EAASD,EAClBiC,EAAcD,IAAiB,OAAS,IAAI,aAAa1B,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGY,EAAO,EACTC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBgB,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdU,IAAiB,OACnBtB,EAAiBJ,EAAS,EACjB0B,IAAiB,OAC1BzB,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GACjB0B,IAAiB,QAC1BvB,EAAiB,EACjBD,EAAiBF,EACjBC,EAAiBD,EAAS,GAG5B,QACMpC,EAAI,EACRA,EAAIoC,EACJpC,IAAKiD,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAE3Fe,EAAY1B,GAAgB,GAAKwB,EAAOZ,CAAa,EAAId,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYzB,GAAgB,GAAKuB,EAAOX,CAAa,EAAIf,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYxB,GAAgB,GAAKsB,EAAOV,CAAa,EAAIhB,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9EM,IAAmB,IAAMY,IAAkB,KAC7CW,EAAYvB,GAAgB,GAAKqB,EAAOT,CAAa,EAAIjB,EAAS,CAAC,GAAKD,EAAS,CAAC,GAStF,OAHE4B,IAAiB,OACb,IAAIE,EAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,EACxD,IAAIkC,EAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,CAEhE,EAKawB,GAAkB,MAC7BR,EACAzC,IAKmB,CAEnB,IAAM4D,EAAiB,OAAO,iBAAqB,KAAenB,aAAiB,iBAC7EoB,EAAiB,OAAO,UAAc,KAAepB,aAAiB,UACtEqB,EAAgB,OAAO,YAAgB,KAAerB,aAAiB,YACvEsB,EAAW,OAAOtB,GAAU,SAE9BuB,EACAC,EAA+CjE,GAAW,CAAA,EAExDkE,EAAe,IAAK,CACxB,GAAI,OAAO,SAAa,IACtB,OAAO,SAAS,cAAc,QAAQ,EACjC,GAAI,OAAO,gBAAoB,IACpC,OAAO,IAAI,gBAAgB,EAAG,CAAC,EAE/B,MAAM,IAAI,MAAM,yBAAyB,CAE7C,EACMC,EAAuB5C,GACvB,OAAO,kBAAsB,KAAeA,aAAkB,mBAEvDA,aAAkB,gBADpBA,EAAO,WAAW,IAAI,EAItB,KAIX,GAAIqC,EAAgB,CAElB,IAAMrC,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAIE,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MAMlB,GALIzC,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADAiE,EAAwBjE,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7EiE,EAAsB,aAAe,OAEvCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,OAE9BwC,EAAsB,aAAe,OACrCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAGhCD,EAAgB,UAAUiB,EAAO,EAAG,CAAC,EACrCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCmC,EAAgB,CACzB,IAAInC,EACAD,EAiBJ,GAfIzB,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,eAEhB0B,EAASe,EAAM,OACfhB,EAAQgB,EAAM,OAGZzC,IAAY,SACdiE,EAAwBjE,GAE1BiE,EAAsB,OAAS,OAC/BA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAE1BzB,IAAY,OAAW,CACzB,IAAMoE,EAAaF,EAAY,EAE/BE,EAAW,MAAQ3C,EACnB2C,EAAW,OAAS1C,EAEpB,IAAMF,EAAkB2C,EAAoBC,CAAU,EAEtD,GAAI5C,GAAmB,KACrBA,EAAgB,aAAaiB,EAAO,EAAG,CAAC,EACxCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CsC,EAAOvB,EAAM,aAENqB,EAAe,CAExB,GAAI9D,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAMuB,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAME,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MACpB,OAAAjB,EAAgB,UAAUiB,EAAO,EAAG,EAAGhB,EAAOC,CAAM,EACpDsC,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,KACzDuC,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EACvBuB,GAAegB,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAM/C,EAAS2C,EAAY,EACrBK,EAAUJ,EAAoB5C,CAAM,EAC1C,GAAI,CAACkB,GAAS,CAAC8B,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAM/B,EACf+B,EAAS,OAAS,IAAK,CACrBjD,EAAO,MAAQiD,EAAS,MACxBjD,EAAO,OAASiD,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGjD,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMkD,EAAMF,EAAQ,aAAa,EAAG,EAAGhD,EAAO,MAAOA,EAAO,MAAM,EAElE0C,EAAsB,OAAS1C,EAAO,OACtC0C,EAAsB,MAAQ1C,EAAO,MACrC8C,EAAQrB,GAAeyB,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOhB,GAAegB,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKaf,GAAoB,CAC/BwB,EACA1E,IACU,CACV,GAAM,CAAE,MAAAyB,EAAO,OAAAC,EAAQ,SAAAiD,EAAU,QAAAC,CAAO,EAAK5E,EAEvC6E,EAAO,CAAC,EAAGnD,EAAQD,EAAO,CAAC,EACjC,OAAO,IAAIkC,EAAO,CAAE,SAAU,UAAW,KAAM,UAAW,QAAAe,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC9F,EAKazB,GAAsB,CACjC2B,EACA9E,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,EAAO,CAAE,SAAU,aAAc,KAAMoB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC/G,EAKaxB,GAAqB,CAChC4B,EACAhF,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,EAAO,CAAE,SAAU,YAAa,KAAMoB,GAAY,UAAW,SAAAC,EAAU,KAAAH,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC7G,EAKavB,GAAyB,CACpC4B,EACAzB,EACAqB,IACW,IAAIlB,EAAO,CAAE,SAAU,aAAc,KAAAsB,EAAM,KAAMzB,EAAQ,KAAMqB,GAAQ,CAACrB,EAAO,MAAM,CAAC,CAAE,IC3UrG,IAoBa0B,EAeAC,GAcTC,GACSC,GAlDbC,GAAAhG,EAAA,kBAoBa4F,EAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACtB,CAAC,OAAQ,UAAU,EACnB,CAAC,QAAS,UAAU,EACrB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAsB,GACbC,GAAkB,IAAK,CAClC,GAAI,CAACD,GAAqB,CACxBA,GAAsB,GACtB,IAAMG,EAA2B,OAAO,cAAkB,KAAe,cAAc,KACjFC,EAA4B,OAAO,eAAmB,KAAe,eAAe,KAGpFC,EAAgB,WAAmB,aACnCC,EAA0B,OAAOD,EAAiB,KAAeA,EAAa,KAEhFF,IACFL,EAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DK,IACFN,EAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAEhEO,GACFR,EAAsC,IAAI,UAAWO,CAAY,EACjEN,GAAsC,IAAIM,EAAc,SAAS,GAGjEP,EAAsC,IAAI,UAAW,WAAW,EAGtE,IC5EA,IAgBaS,GAkBAC,GAlCbC,GAAAvG,EAAA,kBASAiE,KAOaoC,GAAiBd,GAAoC,CAChE,IAAIiB,EAAO,EACX,QAASnG,EAAI,EAAGA,EAAIkF,EAAK,OAAQlF,IAAK,CACpC,IAAMoG,EAAMlB,EAAKlF,CAAC,EAClB,GAAI,OAAOoG,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQpG,CAAC,8BAA8BoG,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQpG,CAAC,0CAA0CoG,CAAG,EAAE,EAE/ED,GAAQC,EAEV,OAAOD,CACT,EAKaF,GAAgB,CAACtE,EAAgBuD,IAAmC,CAC/E,OAAQvD,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIqC,EAAOrC,EAAO,KAAMA,EAAO,KAAMuD,CAAI,EAClD,IAAK,aACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,aACV,KAAMrC,EAAO,KACb,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,UACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,UACV,QAASrC,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,aACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,aACV,UAAWrC,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,YACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,YACV,SAAUrC,EAAO,SACjB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCvD,EAAO,QAAQ,mBAAmB,EAE1F,ICrEA,IAiDaqC,EAjDbJ,GAAAjE,EAAA,kBAGA+B,KAEAiC,KAoBAgC,KAOAO,KAiBalC,EAAP,KAAa,CAuDjB,YACEqC,EAUAC,EACAC,EAAwB,CAGxBb,GAAe,EAEf,IAAIJ,EACAJ,EAEJ,GAAI,OAAOmB,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBf,EAAOe,EAAK,KACZnB,EAAOmB,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMG,EAAgCjB,EAAsC,IAAID,CAAI,EACpF,GAAI,CAACkB,EACH,MAAM,IAAI,UAAU,qBAAqBlB,CAAI,uCAAuC,EAEtF,GAAI,EAAEe,EAAK,gBAAgBG,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUH,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAIf,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBe,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBe,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,YAAa,CAChB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,kCAAkC,EAEjF,KAAK,aAAee,EAAK,SACzB,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIhC,EACAoC,EAEJ,GAAI,OAAOJ,GAAS,SAMlB,GAFAf,EAAOe,EACPI,EAAYF,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAgD,EAItEjC,EAAOiC,MACF,CAEL,IAAMI,EAAwBnB,EAAsC,IAAIc,CAAI,EAC5E,GAAIK,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BL,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAKD,IAAS,WAAaK,IAA0B,aAAgBL,IAAS,SAAWA,IAAS,OAWhG,MAAM,IAAI,UACR,cAAcA,CAAI,0DAA0DK,EAAsB,IAAI,WAAW,EAE1GL,IAAS,UAAYA,IAAS,QAYvChC,EAAQqC,EAA8B,KAAKJ,EAAM,MAAM,EAIvDjC,EAAQqC,EAA8B,KAAKJ,CAAI,UAExCA,aAAgBI,EACzBrC,EAAOiC,UACEA,aAAgB,kBACzB,GAAID,IAAS,QACXhC,EAAO,WAAW,KAAKiC,CAAI,MAE3B,OAAM,IAAI,UAAU,yDAAyD,UAEtED,IAAS,WAAaC,aAAgB,aAAeI,IAA0B,YAMxFrC,EAAO,IAAK,WAAmB,aAAaiC,EAAK,OAAQA,EAAK,WAAYA,EAAK,MAAM,MAErF,OAAM,IAAI,UAAU,KAAKhB,CAAI,kCAAkCoB,CAAqB,EAAE,UAO1FD,EAAYH,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMM,EAAmB,OAAON,EAAK,CAAC,EACtC,GAAIM,IAAqB,SACvBrB,EAAO,SACPjB,EAAOgC,UACEM,IAAqB,UAC9BrB,EAAO,OAIPjB,EAAO,WAAW,KAAKgC,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCM,CAAgB,GAAG,UAEvEN,aAAgB,kBACzBf,EAAO,QACPjB,EAAO,WAAW,KAAKgC,CAAI,MACtB,CAEL,IAAMO,EAAapB,GAAsC,IACvDa,EAAK,WAA8C,EAErD,GAAIO,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCP,EAAK,WAAW,GAAG,EAE9Ef,EAAOsB,EACPvC,EAAOgC,EAKX,GAAII,IAAc,OAEhBA,EAAY,CAACpC,EAAK,MAAM,UACf,CAAC,MAAM,QAAQoC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAwC,EAE9DvB,EAAOuB,EAEP,KAAK,QAAUpC,EACf,KAAK,aAAe,MAItB,IAAM8B,EAAOH,GAAcd,CAAI,EAE/B,GAAI,KAAK,SAAWiB,IAAS,KAAK,QAAQ,QACnC,GAAAb,IAAS,SAAWA,IAAS,SAAW,KAAK,KAAKa,EAAO,CAAC,IAAM,KAAK,QAAQ,QAGhF,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAIhG,KAAK,KAAOb,EACZ,KAAK,KAAOJ,EACZ,KAAK,KAAOiB,CACd,CAIA,aAAa,UACXrD,EACAzC,EAIwB,CAExB,OAAOiD,GAAgBR,EAAOzC,CAAO,CACvC,CAEA,OAAO,YACL0E,EACA1E,EAAoC,CAEpC,OAAOkD,GAAkBwB,EAAS1E,CAAO,CAC3C,CAEA,OAAO,cACL8E,EACA9E,EAAsC,CAEtC,OAAOmD,GAAoB2B,EAAW9E,CAAO,CAC/C,CAEA,OAAO,aACLgF,EACAhF,EAAqC,CAErC,OAAOoD,GAAmB4B,EAAUhF,CAAO,CAC7C,CAEA,OAAO,iBACLiF,EACAzB,EACAqB,EAAwB,CAExB,OAAOxB,GAAuB4B,EAAMzB,EAAQqB,CAAI,CAClD,CAKA,UAAU7E,EAAgC,CACxC,OAAOmB,GAAgB,KAAMnB,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOoB,GAAkB,KAAMpB,CAAO,CACxC,CAqDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACR,gJAC6E,EAGjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAEA,IAAI,UAAQ,CAEV,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,aACR,MAAM,IAAI,MAAM,6CAA6C,EAE/D,OAAO,KAAK,YACd,CAKA,MAAM,QAAQwG,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aACL,IAAK,YAAa,CAChB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMxC,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXwC,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXxC,UAEP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,aAAe,OACpB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQa,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOe,GAAc,KAAMf,CAAI,CACjC,KC/iBF,IAsYalB,EAtYb8C,GAAAnH,EAAA,kBAIAiE,KAkYaI,EAASA,ICtYtB,IAQa+C,GAQPC,GAqBOC,EAUAC,EAUAC,EAWAC,EApEbC,GAAA1H,EAAA,kBAGA0B,KAKa0F,GAAQ,CAACO,EAAoBC,IAAiB,EACrD,OAAOnG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,UAAU,GAAGkG,CAAU,UAAUC,CAAK,EAAE,CAClD,EAEMP,GAAa,CAACQ,EAAaC,IAAqB,CACpD,IAAMC,EAAQ,IAAI,MAAK,EAAG,OAAO,MAAM,aAAa,GAAK,CAAA,EACrDC,EAAe,GACnB,QAAS3H,EAAI,EAAGA,EAAI0H,EAAM,OAAQ1H,IAAK,CACrC,GAAI2H,GAAgB,CAACD,EAAM1H,CAAC,EAAE,SAAS,YAAY,EAAG,CACpD,IAAIuH,EAAQ,QAAQC,CAAG,KAAKE,EAAM1H,CAAC,EAAE,KAAI,EAAG,MAAM,GAAG,EAAE,CAAC,CAAC,GACrDyH,IACFF,GAAS,KAAKE,CAAQ,IAExBV,GAAM,MAAOQ,CAAK,EAClB,OAEEG,EAAM1H,CAAC,EAAE,SAAS,YAAY,IAChC2H,EAAe,IAGrB,EAKaV,EAAoBQ,GAAqB,EAChD,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAG9D4F,GAAW,QAASS,CAAQ,CAC9B,EAKaP,EAAkBO,GAAqB,EAC9C,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAG9D4F,GAAW,MAAOS,CAAQ,CAC5B,EAKaN,EAAqBM,GAAqB,EACjD,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,KAAK,QAAQqG,CAAQ,EAAE,CACjC,EAKaL,EAAmBK,GAAqB,EAC/C,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,QAAQ,QAAQqG,CAAQ,EAAE,CACpC,IC1EA,IAgBaG,GAhBbC,GAAAlI,EAAA,kBAGAD,KAIAoH,KACAO,KAQaO,GAAP,MAAOE,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkB1B,EAAiCC,EAAiB,CAC5EU,EAAgB,EAChBE,EAAkB,sBAAsB,EACxC,IAAMc,EAAgD,CAAA,EAClD5H,EAAsB,CAAA,EAE1B,GAAI,OAAO2H,GAAU,UAAYA,IAAU,MAAQA,aAAiBhE,GAAU,MAAM,QAAQgE,CAAK,EAC/F,MAAM,IAAI,UACR,+FAA+F,EAInG,IAAIE,EAAiB,GAErB,GAAI,OAAO5B,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBtC,EAClB,MAAM,IAAI,UAAU,8BAA8B,EAGpD,GAAI,MAAM,QAAQsC,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAqC,EAE3D4B,EAAiB,GAEjB,QAAWtI,KAAQ0G,EAAM,CACvB,GAAI,OAAO1G,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAgD,EAEtE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEqI,EAAQrI,CAAI,EAAI,KAGlB,GAAI,OAAO2G,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,MAE/C,CAGL,IAAI4B,EAAY,GACVC,EAAW,OAAO,oBAAoB9B,CAAI,EAChD,QAAW1G,KAAQ,KAAK,YACtB,GAAIwI,EAAS,QAAQxI,CAAI,IAAM,GAAI,CACjC,IAAMyI,EAAK/B,EAA4D1G,CAAI,GACvEyI,IAAM,MAAQA,aAAarE,KAC7BmE,EAAY,GACZD,EAAiB,GACjBD,EAAQrI,CAAI,EAAIyI,GAKtB,GAAIF,GACF,GAAI,OAAO5B,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,OAGpDlG,EAAUiG,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAAyD,EAI/E,QAAW1G,KAAQ,KAAK,WACtB,GAAI,OAAOoI,EAAMpI,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAIsI,EACF,QAAWtI,KAAQ,KAAK,YACtBqI,EAAQrI,CAAI,EAAI,KAMpB,IAAM0I,EAAU,MAAM,KAAK,QAAQ,IAAIN,EAAOC,EAAS5H,CAAO,EACxDkI,EAA6C,CAAA,EACnD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBzE,EACpBuE,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIxE,EAAOyE,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAArB,EAAgB,sBAAsB,EACtCF,EAAc,EACPqB,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAWA,aAAa,OACXlC,EACAC,EACAC,EACAmC,EAAqB,CAErBzB,EAAgB,EAChBE,EAAkB,yBAAyB,EAE3C,IAAIwB,EACAtI,EAA0B,CAAA,EAE9B,GAAI,OAAOgG,GAAS,UAElB,GADAsC,EAAuBtC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3CD,aAAgB,YAEzB,GADAsC,EAAuBtC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAGpDD,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAC7D,CACA,IAAMxC,EAASwC,EACXuC,EAAa,EACbC,EAAaxC,EAAK,WACtB,GAAI,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAsC,EAAatC,EACT,CAAC,OAAO,cAAcsC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,EAAa,GAAKA,GAAc/E,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAgF,EAAaxC,EAAK,WAAauC,EAC3B,OAAOrC,GAAS,SAAU,CAE5B,GADAsC,EAAatC,EACT,CAAC,OAAO,cAAcsC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,GAAc,GAAKD,EAAaC,EAAahF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAa+E,CAAU,IAAI,EAE7F,GAAI,OAAOF,GAAS,UAAYA,IAAS,KACvCrI,EAAUqI,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3C,OAAOnC,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAgC,UAE7C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,EAEpDqC,EAAuB,IAAI,WAAW9E,EAAQ+E,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAqD,EAI3E,GAAM,CAAChJ,EAASiJ,CAAuB,EAAI,MAAMrJ,GAAoCY,CAAO,EACtF0H,EAAU,MAAMlI,EAAQ,8BAA8B8I,EAAsBG,CAAuB,EACzG,OAAA1B,EAAgB,yBAAyB,EACzCF,EAAc,EACP,IAAIY,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,IAAI,eAAa,CACf,OAAO,KAAK,QAAQ,aACtB,CAEA,IAAI,gBAAc,CAChB,OAAO,KAAK,QAAQ,cACtB,KC7OF,IA2mBaH,GA3mBbmB,GAAApJ,EAAA,kBAGAkI,KAwmBaD,GAA4CA,KC3mBzD,IAAAoB,GAAArJ,EAAA,oBCAA,IAAAsJ,GAAAtJ,EAAA,oBCAA,IAAAuJ,GAAAvJ,EAAA,oBCAA,IAAAwJ,GAAAxJ,EAAA,oBCAA,IAAAyJ,GAAA,GAAAC,GAAAD,GAAA,sBAAAxB,GAAA,UAAAb,GAAA,sBAAAI,EAAA,oBAAAC,EAAA,qBAAAH,EAAA,mBAAAC,EAAA,WAAAlD,EAAA,QAAA5C,EAAA,oBAAA7B,KAAA,IAAA+J,EAAA3J,EAAA,kBAmBAqB,KACAO,KACAwH,KACAjC,KACAkC,KACAC,KACA5B,KACA6B,KACAC,OC3BA,IAAAI,GAAA5J,EAAA,oBCAA,IAAA6J,GAAA,GAAAH,GAAAG,GAAA,aAAAC,KAAA,IAmGMC,GACAC,GA0FCF,GA9LPG,GAAAjK,EAAA,kBAsFAkK,KAUAC,KACAC,KAEML,GAAc,wBACdC,GAAgB,WAAW,MAAM,OAASD,GAE5CC,KAEF,KAAK,UAAaK,GAA2C,CAC3D,GAAM,CAAE,KAAA1E,EAAM,GAAI2E,CAAQ,EAAID,EAAG,KACjC,GAAI,CACF,OAAQ1E,EAAM,CACZ,IAAK,YACH4E,GAAsBD,EAAS,IAAI,EAAE,KACnC,IAAM,CACJE,GAAYF,CAAQ,EAAE,KACpB,IAAM,CACJ,YAAY,CAAE,KAAA3E,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,CACF,EACCA,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,MACF,IAAK,UAAW,CACd,GAAM,CAAE,OAAAwJ,EAAQ,IAAAhJ,CAAI,EAAI6I,EACxBI,GAAOjJ,EAAKgJ,CAAM,EAAE,KAClB,IAAM,CACJ,YAAY,CAAE,KAAA9E,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,YAAa,CAChB,GAAM,CAAE,OAAAiD,CAAO,EAAIoG,EACbK,EAAaC,GAAuB1G,CAAM,EAChD,YAAY,CAAE,KAAAyB,EAAM,IAAKgF,CAAW,CAAmB,EACvD,KACF,CACA,IAAK,SAAU,CACb,GAAM,CAAE,MAAAE,EAAO,QAAAnK,CAAQ,EAAI4J,EAC3BQ,GAAcD,EAAOnK,CAAO,EAAE,KAC3BqK,GAAoB,CACnB,YAAY,CAAE,KAAApF,EAAM,IAAKoF,CAAgB,CAAmB,CAC9D,EACC9J,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,UACH+J,GAAeV,CAAQ,EACvB,YAAY,CAAE,KAAA3E,CAAK,CAAC,EACpB,MACF,IAAK,MAAO,CACV,GAAM,CAAE,UAAAsF,EAAW,aAAAC,EAAc,OAAAC,EAAQ,cAAAC,EAAe,QAAA1K,CAAQ,EAAI4J,EACpEe,GAAIJ,EAAWC,EAAcC,EAAQC,EAAe,IAAI,MAAMA,EAAc,MAAM,EAAE,KAAK,IAAI,EAAG1K,CAAO,EAAE,KACtG4K,GAAY,CACPA,EAAQ,KAAMC,GAAMA,EAAE,CAAC,IAAM,KAAK,EACpC,YAAY,CAAE,KAAA5F,EAAM,IAAK,iDAAkD,CAAC,EAE5E,YACE,CAAE,KAAAA,EAAM,IAAK2F,CAAQ,EACrBE,GAA2B,CAAC,GAAGL,EAAQ,GAAGG,CAAO,CAAiC,CACpF,CAEJ,EACCrK,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,gBACHwK,GAAanB,CAAQ,EACrB,YAAY,CAAE,KAAA3E,CAAK,CAAC,EACpB,MACF,QACF,CACF,OAAS1E,EAAK,CACZ,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAmB,CAC7C,CACF,GAGK6I,GAAQE,GACX,KACC0B,GACC,IAAI,OAAOA,GAAeC,EAAY,CAAE,KAAqC,UAAW,KAAM5B,EAAY,CAAC,ICjMjH,IAWM6B,GAmCAC,GAiDOF,EAOAG,GAUPC,GAaAC,GAaAC,GAcAC,GAeAC,GAQAC,GAeOC,GAoBPC,GAwBOC,GA1ObnC,GAAApK,EAAA,kBAIA4J,KAOMgC,GAAmB,OAAO,SAAa,IAAc,OAAY,SAAS,OAmC1EC,GAAe,IAA0B,CAE7C,GAAI,IAkCJ,OAAO,OAAO,SAAa,IACtB,SAAS,eAAqC,IAE/C,OAAO,KAAS,IACd,KAAK,UAAU,KACf,MACR,EAOaF,EAAYE,GAAa,EAOzBC,GAAmC,IAA0B,CACxE,GAAIH,GAAa,CAACA,EAAU,WAAW,OAAO,EAC5C,OAAOA,EAAU,UAAU,EAAGA,EAAU,YAAY,GAAG,EAAI,CAAC,CAGhE,EAKMI,GAAe,CAACS,EAAkBC,IAA4B,CAClE,GAAI,CACF,IAAMC,EAAUD,GAAkBd,EAElC,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,SAAWZ,EACxB,MAAQ,CACN,MAAO,EACT,CACF,EAKMI,GAAe,CAACQ,EAAkBC,IAA4B,CAClE,IAAMC,EAAUD,GAAkBd,EAClC,GAAI,CAEF,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,IACb,MAAQ,CACN,MACF,CACF,EAKMP,GAAc,CAACO,EAAkBC,IAA4B,GAAGA,GAAkB,IAAI,GAAGD,CAAQ,GAcjGN,GAAU,MAAOS,GAAyC,CAE9D,IAAMC,EAAO,MADI,MAAM,MAAMD,EAAa,CAAE,YAAa,aAAc,CAAC,GAC5C,KAAK,EACjC,OAAO,IAAI,gBAAgBC,CAAI,CACjC,EAWMT,GAAuB,MAAUU,IACpC,MAAM,6BAAiCA,IAAM,QAO1CT,GAEwC,cAA+B,QAahEC,GAAoB,SAAmD,CAClF,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,sEAAsE,EAIxF,GAAII,GAAaJ,CAAS,EACxB,MAAO,CAAC,OAAWS,GAAmB,CAAC,EAIzC,IAAMS,EAAM,MAAMX,GAAQP,CAAS,EACnC,MAAO,CAACkB,EAAKT,GAAmBS,CAAG,CAAC,CACtC,EAOMP,GAUA,OAcOC,GAAmB,MAC9Bb,EACAe,EACAK,EACAC,IAC0E,CAM1E,IAAIC,EAAoBV,IAAsB,EAAEZ,GAAee,GAC/D,GAAIO,EACF,GAAKrB,EAyBHqB,EAAoBjB,GAAaJ,CAAS,UAPtCoB,GAAoB,CAACD,EACvBE,EAAoB,OAEpB,OAAM,IAAI,MAAM,yCAAyC,EAO/D,GAAIA,EACF,MAAO,CAAC,OAAWV,EAAmB,EACjC,CACL,IAAMW,EAIA,6BACAC,EAAgBxB,GAAeM,GAAaiB,EAAoBR,CAAc,EAW9EU,EAAc,CAAC,IAAUL,GAAmBI,GAAiB,CAACnB,GAAamB,EAAeT,CAAc,EACxGI,EAAMM,EACR,MAAMjB,GAAQgB,CAAa,EAC1BA,GAAiBjB,GAAYgB,EAAoBR,CAAc,EACpE,MAAO,CAACU,EAAcN,EAAM,OAAW,MAAMV,GAA6DU,CAAG,CAAC,CAChH,CACF,IC5SA,IAQIO,GACAC,GACAC,GACAC,GAEEC,GA0BAC,GA2BAC,GA4BOnD,GA4IAoD,EA1ObxD,GAAAnK,EAAA,kBAMAoK,KAGIiD,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAE5C,GAAI,OAAO,kBAAsB,IAC/B,MAAO,GAGT,GAAI,CAGF,OAAI,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAG,IAAK,GAC3G,EAAG,EAAG,GAAI,EACZ,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,GAAI,EAAG,GAAI,EAAG,IAAK,GAAI,IAAK,GAAI,EAAG,EAAG,EAC7G,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,IAAK,IAAK,EAAG,GAAI,EAC1D,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAyB,IAAe,CAC5C,GAAI,CAgBF,OAAO,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,IAAK,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,GAAI,EAAG,GAAI,EAAG,IAAK,GAAI,GAAI,EAAG,IAC1G,GAAI,GAAI,EAAG,IAAK,GAAI,IAAK,IAAK,EAAG,EACnC,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEanD,GAAwB,MAAOqD,GAA+C,CACzF,GAAIP,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAoD,EAGtED,GAAe,GAGf,IAAMO,EAAUD,EAAM,YAClBE,EAAaF,EAAM,WAGvB,GAAIA,EAAM,OAAS,IAEZ,GAAIA,EAAM,OAAS,WAExB,GAAI,CAACF,GAAuB,EAC1B,MAAM,IAAI,MAAM,uEAAuE,UAEhF,CAACD,GAAgB,EAC1B,MAAM,IAAI,MAAM,+DAA+D,EAIjF,IAAMM,EAAuBP,GAAuB,EAChDM,EAAa,GAAK,CAACC,IACjB,OAAO,KAAS,KAAe,CAAC,KAAK,qBAEvC,QAAQ,KACN,iCACED,EACA,uIAEJ,EAIF,QAAQ,KACN,4GACF,EAGAF,EAAM,WAAaE,EAAa,GAGlC,IAAME,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAuBF,GAAiC,IACxDG,EAAmBD,GAA6B,MAAQA,EACxDE,EAAwBJ,GAAiC,KACzDK,EAAoBD,GAA8B,MAAQA,EAC1DE,EAAqBV,EAAM,WAE3B,CAACW,EAAWC,CAAc,EAAI,MAAMjC,GACxC4B,EACAF,EACAH,EAAa,EACb,CAAC,CAACQ,GAAsB,CAAC,CAACD,CAC5B,EAEII,EAAY,GAEVC,EAA8B,CAAC,EAmErC,GAhEIb,EAAU,GACZa,EAAM,KACJ,IAAI,QAAS3J,GAAY,CACvB,WAAW,IAAM,CACf0J,EAAY,GACZ1J,EAAQ,CACV,EAAG8I,CAAO,CACZ,CAAC,CACH,EAIFa,EAAM,KACJ,IAAI,QAAQ,CAAC3J,EAASC,IAAW,CAC/B,IAAM2J,EAAiC,CAKrC,WAAAb,CACF,EAEA,GAAIQ,EAEFK,EAAO,WAAaL,UACXD,GAAoBJ,EAI7BU,EAAO,WAAcC,GAAaP,GAAoBJ,EAAqBW,UAClET,GAAmBA,EAAgB,QAAQ,OAAO,IAAM,EAEjEQ,EAAO,WAAcC,GAAa,IAAI,IAAIA,EAAUT,CAAe,EAAE,aAC5DI,EAAW,CACpB,IAAMM,EAAyB/C,GAAiC,EAC5D+C,IAEFF,EAAO,WAAcC,GAAaC,EAAyBD,EAE/D,CAEAJ,EAAeG,CAAM,EAAE,KAEpBG,GAAW,CACVxB,GAAe,GACfD,GAAc,GACdD,GAAO0B,EACP/J,EAAQ,EACJwJ,GACF,IAAI,gBAAgBA,CAAS,CAEjC,EAECQ,GAAS,CACRzB,GAAe,GACfC,GAAU,GACVvI,EAAO+J,CAAI,CACb,CACF,CACF,CAAC,CACH,EAEA,MAAM,QAAQ,KAAKL,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DZ,CAAO,IAAI,CAE1F,EAEaF,EAAc,IAAqB,CAC9C,GAAIN,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IChPA,IAKa4B,EAeAC,GAgCAC,EApDbC,GAAAnP,EAAA,kBAGAmK,KAEa6E,EAAkB,CAACtK,EAAc0K,IAA6B,CACzE,IAAMhC,EAAOO,EAAY,EAEnB0B,EAAajC,EAAK,gBAAgB1I,CAAI,EAAI,EAC1C4K,EAAalC,EAAK,QAAQiC,CAAU,EAC1C,OAAAjC,EAAK,aAAa1I,EAAM4K,EAAYD,CAAU,EAC9CD,EAAO,KAAKE,CAAU,EAEfA,CACT,EAMaL,GAAsB,CACjCvO,EACA6O,EACAC,EACApH,IACS,CACT,GAAI,OAAO1H,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAI8O,EAAK,IAAI9O,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/C8O,EAAK,IAAI9O,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACmI,EAAKlH,CAAK,IAAM,CAChD,IAAM1B,EAAOsP,EAASA,EAAS1G,EAAMA,EACrC,GAAI,OAAOlH,GAAU,SACnBsN,GAAoBtN,EAAkC1B,EAAO,IAAKuP,EAAMpH,CAAO,UACtE,OAAOzG,GAAU,UAAY,OAAOA,GAAU,SACvDyG,EAAQnI,EAAM0B,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1ByG,EAAQnI,EAAM0B,EAAQ,IAAM,GAAG,MAE/B,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMauN,EAAkB5E,GAA0B,CACvD,IAAM8C,EAAOO,EAAY,EAEnB5F,EAAQqF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMqC,EAAUrC,EAAK,SACfsC,EAAetC,EAAK,WAAW,EAAIqC,CAAO,EAChDrC,EAAK,iBAAiBsC,EAAcA,EAAeD,CAAO,EAC1D,IAAME,EAAY,OAAOvC,EAAK,SAASsC,EAAcD,IAAY,EAAI,MAAQ,KAAK,CAAC,EAC7EG,EAAsBxC,EAAK,SAASsC,EAAeD,EAAS,GAAG,EAC/DI,EAAeD,EAAsBxC,EAAK,aAAawC,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGtF,CAAO,gBAAgBqF,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAzC,EAAK,aAAarF,CAAK,CACzB,CACF,ICnEA,IAQa+H,GARbC,GAAA/P,EAAA,kBAKAmK,KACAgF,KAEaW,GAAiBpP,GAA6D,CACzF,IAAM0M,EAAOO,EAAY,EACrBqC,EAAmB,EACjBZ,EAAmB,CAAC,EAEpBa,EAA0CvP,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCuP,EAAW,iBAAmB,UAE9B,OAAOvP,EAAQ,kBAAqB,UACpC,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1CA,EAAQ,iBAAmB,GAC3BA,EAAQ,iBAAmB,EAE3B,MAAM,IAAI,MAAM,oCAAoCA,EAAQ,gBAAgB,EAAE,EAGhF,GAAIA,GAAS,oBAAsB,OACjCuP,EAAW,kBAAoB,UACtB,OAAOvP,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBuP,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIxP,GAAS,MAAQ,SACnBwP,EAAgBlB,EAAgBtO,EAAQ,IAAK0O,CAAM,GAGrDY,EAAmB5C,EAAK,qBACtB6C,EAAW,iBACXA,EAAW,kBACX,CAAC,CAACA,EAAW,UACbC,CACF,EACIF,IAAqB,GACvBd,EAAe,2BAA2B,EAGxCxO,GAAS,QAAU,QACrBuO,GAAoBvO,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACmI,EAAKlH,IAAU,CAC7F,IAAMwO,EAAgBnB,EAAgBnG,EAAKuG,CAAM,EAC3CgB,EAAkBpB,EAAgBrN,EAAOyN,CAAM,EAEjDhC,EAAK,sBAAsB4C,EAAkBG,EAAeC,CAAe,IAAM,GACnFlB,EAAe,iCAAiCrG,CAAG,MAAMlH,CAAK,GAAG,CAErE,CAAC,EAGI,CAACqO,EAAkBZ,CAAM,CAClC,OAAS3O,EAAG,CACV,MAAIuP,IAAqB,GACvB5C,EAAK,sBAAsB4C,CAAgB,EAE7CZ,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EACrC5P,CACR,CACF,ICvEA,IAQM6P,GAiBAC,GAWAC,GAsBAC,GAcAC,GA+FOC,GAvKbC,GAAA5Q,EAAA,kBAKAmK,KACAgF,KAEMmB,GAA4BO,GAAqD,CACrF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMN,GAAoBO,GAAqD,CAC7E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMN,GAAwB9P,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMqQ,EAAUrQ,EAAQ,MAAM,QACzBqQ,EAAQ,+BAEXA,EAAQ,6BAA+B,KAKvCrQ,EAAQ,oBACRA,EAAQ,mBAAmB,KAAMsQ,IAAQ,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAE5FtQ,EAAQ,iBAAmB,GAE/B,EAEM+P,GAAsB,CAACQ,EAA8BpI,EAAalH,EAAeyN,IAA2B,CAChH,IAAMe,EAAgBnB,EAAgBnG,EAAKuG,CAAM,EAC3CgB,EAAkBpB,EAAgBrN,EAAOyN,CAAM,EACjDzB,EAAY,EAAE,0BAA0BsD,EAAsBd,EAAeC,CAAe,IAAM,GACpGlB,EAAe,qCAAqCrG,CAAG,MAAMlH,CAAK,GAAG,CAEzE,EAQM+O,GAAwB,MAC5BO,EACAC,EACA9B,IACkB,CAClB,QAAW4B,KAAME,EAAoB,CACnC,IAAIzG,EAAS,OAAOuG,GAAO,SAAWA,EAAKA,EAAG,KACxCG,EAAqC,CAAC,EAG5C,OAAQ1G,EAAQ,CACd,IAAK,QAEH,GADAA,EAAS,QACL,OAAOuG,GAAO,SAAU,CAG1B,IAAMrJ,EAFeqJ,GAEsD,WACvErJ,GACF8I,GAAoBQ,EAAsB,aAActJ,EAAYyH,CAAM,CAE9E,CACA,MACF,IAAK,SA2BD,GADA3E,EAAS,KACL,OAAOuG,GAAO,SAAU,CAC1B,IAAMI,EAAgBJ,EACtB,GAAII,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErGX,GAAoBQ,EAAsB,kBAAmBG,EAAc,gBAAiBhC,CAAM,CACpG,CACF,CAEF,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqC3E,CAAM,EAAE,CACjE,CAEA,IAAM4G,EAAmBrC,EAAgBvE,EAAQ2E,CAAM,EACjDkC,EAAiBH,EAAU,OAC7BI,EAAa,EACbC,EAAe,EACnB,GAAIF,EAAiB,EAAG,CACtBC,EAAa5D,EAAY,EAAE,QAAQ2D,EAAiB3D,EAAY,EAAE,QAAQ,EAC1EyB,EAAO,KAAKmC,CAAU,EACtBC,EAAe7D,EAAY,EAAE,QAAQ2D,EAAiB3D,EAAY,EAAE,QAAQ,EAC5EyB,EAAO,KAAKoC,CAAY,EACxB,QAASnR,EAAI,EAAGA,EAAIiR,EAAgBjR,IAClCsN,EAAY,EAAE,SAAS4D,EAAalR,EAAIsN,EAAY,EAAE,SAAUwD,EAAU9Q,CAAC,EAAE,CAAC,EAAG,GAAG,EACpFsN,EAAY,EAAE,SAAS6D,EAAenR,EAAIsN,EAAY,EAAE,SAAUwD,EAAU9Q,CAAC,EAAE,CAAC,EAAG,GAAG,CAE1F,CAEG,MAAMsN,EAAY,EAAE,4BACnBsD,EACAI,EACAE,EACAC,EACAF,CACF,IAAO,GAEPpC,EAAe,oCAAoCzE,CAAM,GAAG,CAEhE,CACF,EAEakG,GAAoB,MAAOjQ,GAA2E,CACjH,IAAM0M,EAAOO,EAAY,EACrBsD,EAAuB,EACrB7B,EAAmB,CAAC,EAEpBqC,EAAkD/Q,GAAW,CAAC,EACpE8P,GAAqBiB,CAAc,EAEnC,GAAI,CACF,IAAMZ,EAAyBP,GAAyBmB,EAAe,wBAA0B,KAAK,EAChGX,EAAgBP,GAAiBkB,EAAe,eAAiB,YAAY,EAC7EC,EACJ,OAAOD,EAAe,OAAU,SAAWzC,EAAgByC,EAAe,MAAOrC,CAAM,EAAI,EAEvFuC,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,oCAAoCA,CAAgB,EAAE,EAGxE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EACJ,OAAOJ,EAAe,wBAA2B,SAC7CzC,EAAgByC,EAAe,uBAAwBrC,CAAM,EAC7D,EAsBN,GApBA6B,EAAuB7D,EAAK,yBAC1ByD,EACA,CAAC,CAACY,EAAe,kBACjB,CAAC,CAACA,EAAe,iBACjBX,EACA,CAAC,CAACW,EAAe,gBACjB,EACAC,EACAC,EACAC,EACAC,CACF,EACIZ,IAAyB,GAC3B/B,EAAe,+BAA+B,EAG5CuC,EAAe,oBACjB,MAAMf,GAAsBO,EAAsBQ,EAAe,mBAAoBrC,CAAM,EAGzFqC,EAAe,qBAAuB,OAAW,CACnD,GAAI,OAAOA,EAAe,oBAAuB,UAC/C,MAAM,IAAI,MAAM,+CAA+CA,EAAe,kBAAkB,EAAE,EAEpGhB,GACEQ,EACA,qBACAQ,EAAe,mBAAmB,SAAS,EAC3CrC,CACF,CACF,CAEA,GAAIqC,EAAe,uBACjB,OAAW,CAACxR,EAAM0B,CAAK,IAAK,OAAO,QAAQ8P,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOxR,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAO0B,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMmQ,EAAa9C,EAAgB/O,EAAMmP,CAAM,EAC3ChC,EAAK,6BAA6B6D,EAAsBa,EAAYnQ,CAAK,IAAM,GACjFuN,EAAe,wCAAwCjP,CAAI,MAAM0B,CAAK,GAAG,CAE7E,CAGF,OAAI8P,EAAe,QAAU,QAC3BxC,GAAoBwC,EAAe,MAAO,GAAI,IAAI,QAAoC,CAAC5I,EAAKlH,IAAU,CACpG8O,GAAoBQ,EAAsBpI,EAAKlH,EAAOyN,CAAM,CAC9D,CAAC,EAGI,CAAC6B,EAAsB7B,CAAM,CACtC,OAAS3O,EAAG,CACV,MAAIwQ,IAAyB,GACvB7D,EAAK,0BAA0B6D,CAAoB,IAAM,GAC3D/B,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EACrC5P,CACR,CACF,ICnQA,IA2CasR,GAyCAC,GA0CAC,GAqCAC,GAgDAC,GAoBAC,GAcAC,GAgBAC,GArQbC,GAAAvS,EAAA,kBA2Ca+R,GAA8BpM,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,OACH,MAAO,IACT,IAAK,QACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaqM,GAA8BQ,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,OACT,IAAK,IACH,MAAO,QAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaP,GAA6B,CACxCQ,EACAC,IACuB,CACvB,IAAMC,EAAc,CAClB,GACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,GACA,EACA,EACA,EACA,EACA,EACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,EACF,EAAEF,CAAQ,EAEJjM,EAAO,OAAOkM,GAAe,SAAWA,EAAaA,EAAW,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAC/F,OAAOF,EAAc,EAAI,KAAK,KAAKnM,EAAOmM,CAAW,EAAI,MAC3D,EAKaT,GACXvM,GAY+B,CAC/B,OAAQA,EAAM,CACZ,IAAK,UAEH,OAAO,OAAO,aAAiB,KAAe,aAAa,KAAO,aAAe,YACnF,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKawM,GAAwBW,GAA0E,CAC7G,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaV,GAA4BzM,GACvCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKE0M,GAA2B1M,GACtCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKE2M,GAA4BS,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,YACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,ICtRA,IAWaC,GAXbC,GAAAjT,EAAA,kBAGA4J,KAQaoJ,GAAW,MAAOE,GAA4E,CACzG,GAAI,OAAOA,GAAS,SAClB,GAAI,GAEF,GAAI,CACF,GAAM,CAAE,SAAAC,CAAS,EAAI,GAAQ,kBAAkB,EAC/C,OAAO,IAAI,WAAW,MAAMA,EAASD,CAAI,CAAC,CAC5C,OAASzS,EAAG,CACV,GAAIA,EAAE,OAAS,wBAAyB,CAEtC,GAAM,CAAE,iBAAA2S,CAAiB,EAAI,GAAQ,SAAS,EACxCC,EAASD,EAAiBF,CAAI,EAC9BI,EAAuB,CAAC,EAC9B,cAAiBC,KAASF,EACxBC,EAAO,KAAKC,CAAK,EAEnB,OAAO,IAAI,WAAW,OAAO,OAAOD,CAAM,CAAC,CAC7C,CACA,MAAM7S,CACR,KACK,CAEL,IAAM+S,EAAW,MAAM,MAAMN,CAAI,EACjC,GAAI,CAACM,EAAS,GACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,EAAE,EAE9D,IAAMO,EAAsBD,EAAS,QAAQ,IAAI,gBAAgB,EAC3DE,EAAWD,EAAsB,SAASA,EAAqB,EAAE,EAAI,EAC3E,GAAIC,EAAW,WAGb,OAAO,IAAI,WAAW,MAAMF,EAAS,YAAY,CAAC,EAC7C,CAEL,GAAI,CAACA,EAAS,KACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,qBAAqB,EAEjF,IAAMS,EAASH,EAAS,KAAK,UAAU,EAEnCtP,EACJ,GAAI,CAEFA,EAAS,IAAI,YAAYwP,CAAQ,CACnC,OAASjT,EAAG,CACV,GAAIA,aAAa,WAAY,CAE3B,IAAMmT,EAAQ,KAAK,KAAKF,EAAW,KAAK,EACxCxP,EAAS,IAAI,YAAY,OAAO,CAAE,QAAS0P,EAAO,QAASA,CAAM,CAAC,EAAE,MACtE,KACE,OAAMnT,CAEV,CAEA,IAAIoT,EAAS,EAEb,OAAa,CACX,GAAM,CAAE,KAAAC,EAAM,MAAAnS,CAAM,EAAI,MAAMgS,EAAO,KAAK,EAC1C,GAAIG,EACF,MAEF,IAAMC,EAAYpS,EAAM,WACV,IAAI,WAAWuC,EAAQ2P,EAAQE,CAAS,EAChD,IAAIpS,CAAK,EACfkS,GAAUE,CACZ,CACA,OAAO,IAAI,WAAW7P,EAAQ,EAAGwP,CAAQ,CAC3C,CACF,KACK,QAAIR,aAAgB,KAClB,IAAI,WAAW,MAAMA,EAAK,YAAY,CAAC,EACrCA,aAAgB,WAClBA,EAEA,IAAI,WAAWA,CAAI,CAE9B,ICtFA,IAiFMc,GAWOxJ,GAWAE,GAsIPuJ,GAOAC,GAiBAC,GAiDOvJ,GAkBAE,GA6MAE,GA+BAoJ,GAqIA/I,GAwZAI,GAgBAD,GAjmCbtB,GAAAlK,EAAA,kBAQA2J,IAQAoG,KACAa,KACA2B,KAUApI,KACAgF,KACA8D,KAmDMe,GAAU,CAAClG,EAAoBuG,IAA+B,CAChD1G,EAAY,EAAE,SAASG,EAAYuG,CAAY,IAC/C,GAChBnF,EAAe,+BAA+B,CAElD,EAMa1E,GAAc,MAAO/I,GAA4B,CAE5DuS,GAAQvS,EAAI,KAAK,WAAa0Q,GAAqB1Q,EAAI,QAAQ,CAAC,CAClE,EAQaiJ,GAAS,MAAOjJ,EAAUgJ,IAAkC,CAEvEkD,EAAY,EAAE,YAAY,EAG1B,IAAI2G,EAAgB7S,EAAI,OAAO,QAC/B,GAAIgJ,IAAW,SAAU,CACvB,GAAI,OAAO,UAAc,KAAe,CAAC,UAAU,IACjD,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAK6J,GAmBH,GACE,OAAOA,EAAc,QAAW,UAChC,OAAOA,EAAc,UAAa,UAClC,OAAOA,EAAc,eAAkB,WAEvC,MAAM,IAAI,MAAM,kFAAkF,MAxBlF,CAElB,IAAMC,EAAkB9S,EAAI,OAAO,gBACnC,GAAI8S,IAAoB,QAAaA,IAAoB,aAAeA,IAAoB,mBAC1F,MAAM,IAAI,MAAM,qCAAqCA,CAAe,GAAG,EAEzE,IAAMC,EAAuB/S,EAAI,OAAO,qBACxC,GAAI+S,IAAyB,QAAa,OAAOA,GAAyB,UACxE,MAAM,IAAI,MAAM,0CAA0CA,CAAoB,GAAG,EAGnF,GADAF,EAAgB,MAAM,UAAU,IAAI,eAAe,CAAE,gBAAAC,EAAiB,qBAAAC,CAAqB,CAAC,EACxF,CAACF,EACH,MAAM,IAAI,MACR,0GAEF,CAEJ,CAUF,CAGA,GAAI7J,IAAW,UACT,OAAO,UAAc,KAAe,CAAE,UAAyC,IACjF,MAAM,IAAI,MAAM,+CAA+C,CA8CrE,EA8CMwJ,GAAiB,IAAI,IAOrBC,GAA8BO,GAA4C,CAC9E,IAAMrH,EAAOO,EAAY,EACnB5F,EAAQqF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMqC,EAAUrC,EAAK,SACfkC,EAAalC,EAAK,WAAW,EAAIqC,CAAO,EAC5BrC,EAAK,wBAAwBqH,EAAenF,EAAYA,EAAaG,CAAO,IAC5E,GAChBP,EAAe,uCAAuC,EAExD,IAAMvJ,EAAO8J,IAAY,EAAI,MAAQ,MACrC,MAAO,CAAC,OAAOrC,EAAK,SAASkC,EAAY3J,CAAI,CAAC,EAAG,OAAOyH,EAAK,SAASkC,EAAaG,EAAS9J,CAAI,CAAC,CAAC,CACpG,QAAE,CACAyH,EAAK,aAAarF,CAAK,CACzB,CACF,EAEMoM,GAAgC,CACpCM,EACAC,IAC6E,CAC7E,IAAMtH,EAAOO,EAAY,EACnB5F,EAAQqF,EAAK,UAAU,EACzBuH,EAAiB,EACrB,GAAI,CACF,IAAMlF,EAAUrC,EAAK,SACfkC,EAAalC,EAAK,WAAW,EAAIqC,CAAO,EAC5BrC,EAAK,2BAA2BqH,EAAeC,EAAOpF,EAAYA,EAAaG,CAAO,IACtF,GAChBP,EAAe,0CAA0C,EAE3D,IAAM4C,EAAa,OAAO1E,EAAK,SAASkC,EAAY,GAAG,CAAC,EACxDqF,EAAiB,OAAOvH,EAAK,SAASkC,EAAaG,EAAS,GAAG,CAAC,EAEhE,IAAMmF,EAAcxH,EAAK,OAAOuH,EAAiB,CAAC,EAClD,GAAIC,IAAgB,EAClB,MAAO,CAAC9C,EAAY,CAAC,EAIvB,IAAM+C,EAAYzH,EAAK,QAAQuH,EAAiB,EAAI,CAAC,EAE/CpP,EAA+B,CAAC,EACtC,QAASlF,EAAI,EAAGA,EAAIwU,EAAWxU,IAAK,CAClC,IAAMyU,EAAwB,OAAO1H,EAAK,SAASuH,EAAiB,EAAItU,EAAIoP,EAAS,GAAG,CAAC,EACzFlK,EAAK,KACHuP,IAA0B,EACtB1H,EAAK,aAAa0H,CAAqB,EACvC,OAAO1H,EAAK,SAASuH,EAAiB,GAAKtU,EAAIwU,GAAapF,EAAS,GAAG,CAAC,CAC/E,CACF,CACA,MAAO,CAACqC,EAAY8C,EAAarP,CAAI,CACvC,QAAE,CACA6H,EAAK,aAAarF,CAAK,EACnB4M,IAAmB,GACrBvH,EAAK,SAASuH,CAAc,CAEhC,CACF,EAQa/J,GAA0BC,GAAwC,CAC7E,IAAMuC,EAAOO,EAAY,EACnBoH,EAAkB3H,EAAK,QAAQvC,EAAM,UAAU,EACrD,GAAIkK,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DlK,EAAM,UAAU,GAAG,EAEpG,OAAAuC,EAAK,OAAO,IAAIvC,EAAOkK,CAAe,EAC/B,CAACA,EAAiBlK,EAAM,UAAU,CAC3C,EAUaC,GAAgB,MAC3BkK,EACAtU,IACyC,CACzC,IAAIqU,EAAyBE,EACvB7H,EAAOO,EAAY,EAErB,MAAM,QAAQqH,CAAS,EAEzB,CAACD,EAAiBE,CAAe,EAAID,EAC5BA,EAAU,SAAW5H,EAAK,OAAO,OAE1C,CAAC2H,EAAiBE,CAAe,EAAI,CAACD,EAAU,WAAYA,EAAU,UAAU,EAGhF,CAACD,EAAiBE,CAAe,EAAIrK,GAAuBoK,CAAS,EAGvE,IAAIP,EAAgB,EAChBxD,EAAuB,EACvBiE,EAAkB,EAClB9F,EAAmB,CAAC,EAClB+F,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CAGF,GAFA,CAACnE,EAAsB7B,CAAM,EAAI,MAAMuB,GAAkBjQ,CAAO,EAE5DA,GAAS,cAAgB0M,EAAK,kBAAmB,CACnD,IAAMiI,EAAkB,CAAC,EACzB,QAAWnC,KAAQxS,EAAQ,aAAc,CACvC,IAAM4U,EAAO,OAAOpC,GAAS,SAAWA,EAAOA,EAAK,KACpDmC,EAAgB,KACdrC,GAAS,OAAOE,GAAS,SAAWA,EAAOA,EAAK,IAAI,EAAE,KAAMxO,GAAS,CACnE0I,EAAK,kBAAkBkI,EAAM5Q,CAAI,CACnC,CAAC,CACH,CACF,CAGA,MAAM,QAAQ,IAAI2Q,CAAe,CACnC,CAEA,QAAWE,KAAY7U,GAAS,oBAAsB,CAAC,EAErD,IADqB,OAAO6U,GAAa,SAAWA,EAAWA,EAAS,QACnD,QAAS,CAE5B,GADAnI,EAAK,yBAA2B,GAC5B,OAAOmI,GAAa,SAAU,CAChC,IAAMC,EAAeD,EACftQ,EAAWuQ,GAA6D,QACxEC,EAAaD,GAAsD,UACnE7N,GAAc6N,GAAuD,WACrEjB,GAAmBiB,GAAuD,gBAC5EvQ,EACFmI,EAAK,eAAiBnI,EACbwQ,EACTrI,EAAK,eAAiB,MAAMA,EAAK,qBAAsBqI,CAAS,EAEhErI,EAAK,eAAiB,MAAMA,EAAK,qBAAsB,CAAE,WAAAzF,GAAY,gBAAA4M,EAAgB,CAAC,CAE1F,MACEnH,EAAK,eAAiB,MAAMA,EAAK,qBAAsB,EAEzD,KACF,CAGFqH,EAAgB,MAAMrH,EAAK,kBAAkB2H,EAAiBE,EAAiBhE,CAAoB,EACnG7D,EAAK,wBAAwBqH,CAAa,EACtCA,IAAkB,GACpBvF,EAAe,yBAAyB,EAG1C9B,EAAK,sBAAsB,EAGvBA,EAAK,iBACPA,EAAK,uBAAwBqH,EAAerH,EAAK,cAAc,EAC/DA,EAAK,eAAiB,OACtBA,EAAK,yBAA2B,IAGlC,GAAM,CAACsI,EAAYC,CAAW,EAAIzB,GAA2BO,CAAa,EAEpEmB,EAAqB,CAAC,CAAClV,GAAS,mBAEhCmV,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAkD,CAAC,EACnDC,EAAmD,CAAC,EACpDC,EAAwE,CAAC,EAC/E,QAAS5V,EAAI,EAAGA,EAAIqV,EAAYrV,IAAK,CACnC,GAAM,CAACyR,EAAY8C,EAAasB,CAAK,EAAI/B,GAA8BM,EAAepU,CAAC,EACnFyR,IAAe,GACjB5C,EAAe,0BAA0B,EAE3CiG,EAAsB,KAAKrD,CAAU,EACrC,IAAM7R,EAAOmN,EAAK,aAAa0E,CAAU,EACzC+D,EAAW,KAAK5V,CAAI,EACpB8V,EAAc,KACZnB,IAAgB,EACZ,CAAE,KAAA3U,EAAM,SAAU,EAAM,EACxB,CAAE,KAAAA,EAAM,SAAU,GAAM,KAAM+R,GAA2B4C,CAAW,EAAG,MAAOsB,CAAO,CAC3F,CACF,CACA,QAAS7V,EAAI,EAAGA,EAAIsV,EAAatV,IAAK,CACpC,GAAM,CAACyR,EAAY8C,EAAasB,CAAK,EAAI/B,GAA8BM,EAAepU,EAAIqV,CAAU,EAChG5D,IAAe,GACjB5C,EAAe,2BAA2B,EAE5CkG,EAAuB,KAAKtD,CAAU,EACtC,IAAMqE,EAAa/I,EAAK,aAAa0E,CAAU,EAC/CgE,EAAY,KAAKK,CAAU,EAC3BH,EAAe,KACbpB,IAAgB,EACZ,CAAE,KAAMuB,EAAY,SAAU,EAAM,EACpC,CAAE,KAAMA,EAAY,SAAU,GAAM,KAAMnE,GAA2B4C,CAAW,EAAG,MAAOsB,CAAO,CACvG,CA0BF,CAuBA,OAAAjC,GAAe,IAAIQ,EAAe,CAChCA,EACAU,EACAC,EAvBwC,KAyBxCQ,EACA,EACF,CAAC,EACM,CAACnB,EAAeoB,EAAYC,EAAaC,EAAeC,CAAc,CAC/E,OAASvV,EAAG,CACV,MAAA0U,EAAsB,QAASiB,GAAQhJ,EAAK,SAASgJ,CAAG,CAAC,EACzDhB,EAAuB,QAASgB,GAAQhJ,EAAK,SAASgJ,CAAG,CAAC,EAEtDlB,IAAoB,GAClB9H,EAAK,mBAAmB8H,CAAe,IAAM,GAC/ChG,EAAe,2BAA2B,EAI1CuF,IAAkB,GAChBrH,EAAK,mBAAmBqH,CAAa,IAAM,GAC7CvF,EAAe,wBAAwB,EAGrCzO,CACR,QAAE,CACA2M,EAAK,MAAM2H,CAAe,EACtB9D,IAAyB,GACvB7D,EAAK,0BAA0B6D,CAAoB,IAAM,GAC3D/B,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EAG3CjD,EAAK,sBAAsB,CAC7B,CACF,EAEapC,GAAkBC,GAA4B,CACzD,IAAMmC,EAAOO,EAAY,EACnBoD,EAAUkD,GAAe,IAAIhJ,CAAS,EAC5C,GAAI,CAAC8F,EACH,MAAM,IAAI,MAAM,+CAA+C9F,CAAS,EAAE,EAE5E,GAAM,CAACwJ,EAAeU,EAAuBC,EAAwBiB,EAAgBT,CAAkB,EAAI7E,EAEvGsF,IACET,GACExI,EAAK,sBAAsBiJ,EAAe,MAAM,IAAM,GACxDnH,EAAe,4BAA4B,EAG3C9B,EAAK,mBAAmBiJ,EAAe,MAAM,IAAM,GACrDnH,EAAe,2BAA2B,GAI9C9B,EAAK,uBAAuBnC,CAAS,EACrCmC,EAAK,wBAAwBnC,CAAS,EACtCmC,EAAK,yBAAyBnC,CAAS,EAEvCkK,EAAsB,QAASiB,GAAQhJ,EAAK,SAASgJ,CAAG,CAAC,EACzDhB,EAAuB,QAASgB,GAAQhJ,EAAK,SAASgJ,CAAG,CAAC,EACtDhJ,EAAK,mBAAmBqH,CAAa,IAAM,GAC7CvF,EAAe,wBAAwB,EAEzC+E,GAAe,OAAOhJ,CAAS,CACjC,EAEamJ,GAA2B,MACtCpS,EACAsU,EACAlH,EACAnE,EACAsL,EACA7B,EACAkB,EAAqB,KACH,CAClB,GAAI,CAAC5T,EAAQ,CACXsU,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMlJ,EAAOO,EAAY,EACnB8B,EAAUrC,EAAK,SAEf3H,EAAWzD,EAAO,CAAC,EACnBuD,EAAOvD,EAAO,CAAC,EACf+Q,EAAW/Q,EAAO,CAAC,EACrBwU,EAAiBzD,EAEjB0D,EACAC,EAEJ,GAAIjR,IAAa,WAAasN,IAAa,cAAgBA,IAAa,aACtE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAI6C,GAAsB7C,IAAa,aACrC,MAAM,IAAI,MACR,2DAA2D2B,CAAK,mCAClE,EAGF,GAAI3B,IAAa,aAAc,CAC7B,IAAMvN,EAAYxD,EAAO,CAAC,EAAE,UAC5B0U,EAAiBzE,GAA2BF,GAA2BtM,CAAQ,EAAGF,CAAI,EAS/E,CACL,IAAMoR,EAAiBvJ,EAAK,mBAC5B,GAAI,CAACuJ,EACH,MAAM,IAAI,MAAM,qEAAqE,EAEvFF,EAAUE,EAAe1L,EAAWyJ,EAAOlP,EAAWkR,CAAc,CACtE,CACF,SAAW3D,IAAa,YAAa,CACnC,IAAMrN,EAAW1D,EAAO,CAAC,EAAE,SAC3B0U,EAAiBzE,GAA2BF,GAA2BtM,CAAQ,EAAGF,CAAI,EAEtF,IAAMqR,EAAmBxJ,EAAK,sBAC9B,GAAI,CAACwJ,EACH,MAAM,IAAI,MAAM,mEAAmE,EAErFH,EAAUG,EAAiB3L,EAAWvF,EAAUqM,GAA2BtM,CAAQ,EAAGF,CAAI,CAC5F,KAAO,CACL,IAAMb,EAAO1C,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQ0C,CAAI,EAAG,CAEvBgS,EAAiBjH,EAAU/K,EAAK,OAChC+R,EAAUrJ,EAAK,QAAQsJ,CAAc,EACrCtH,EAAO,KAAKqH,CAAO,EACnB,QAASpW,EAAI,EAAGA,EAAIqE,EAAK,OAAQrE,IAAK,CACpC,GAAI,OAAOqE,EAAKrE,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjE+M,EAAK,SAASqJ,EAAUpW,EAAIoP,EAAST,EAAgBtK,EAAKrE,CAAC,EAAG+O,CAAM,EAAG,GAAG,CAC5E,CACF,KAAO,CACL,IAAMyH,EAAezJ,EAAK,kBACpB0J,EAAgB1J,EAAK,mBAC3B,GAAI3H,IAAa,UAAYoR,GAAgBC,EAAe,CAC1D,IAAMC,EAAa3J,EAAK,aAAamJ,CAAqB,EAE1D,GAAIM,EAAa5L,EAAW8L,CAAU,GAAKD,EAAc7L,EAAW8L,CAAU,EAAG,CAC/E,IAAMC,EAAejF,GAA2BtM,CAAQ,EACxDiR,EAAiBzE,GAA2B+E,EAAczR,CAAI,EAC9DiR,EAAiB,YACjB,IAAMS,EAAwB7J,EAAK,2BAC7B8J,EAAe9J,EAAK,kBAC1B,GAAI,CAAC6J,GAAyB,CAACC,EAC7B,MAAM,IAAI,MAAM,mEAAmE,EAErF,IAAMC,EAAW,MAAMF,EAAsBhM,EAAW+L,EAAczR,CAAgB,EACtF2R,EAAaC,EAAU,IAAI,WAAWzS,EAAK,OAAQA,EAAK,WAAYA,EAAK,UAAU,CAAC,EACpF+R,EAAUU,CACZ,MACET,EAAiBhS,EAAK,WACtB+R,EAAUrJ,EAAK,QAAQsJ,CAAc,EACrCtH,EAAO,KAAKqH,CAAO,EACnBrJ,EAAK,OAAO,IAAI,IAAI,WAAW1I,EAAK,OAAQA,EAAK,WAAYgS,CAAc,EAAGD,CAAO,CAEzF,MACEC,EAAiBhS,EAAK,WACtB+R,EAAUrJ,EAAK,QAAQsJ,CAAc,EACrCtH,EAAO,KAAKqH,CAAO,EACnBrJ,EAAK,OAAO,IAAI,IAAI,WAAW1I,EAAK,OAAQA,EAAK,WAAYgS,CAAc,EAAGD,CAAO,CAEzF,CACF,CAEA,IAAM1O,EAAQqF,EAAK,UAAU,EACvBgK,EAAahK,EAAK,WAAW,EAAI7H,EAAK,MAAM,EAClD,GAAI,CACFA,EAAK,QAAQ,CAAC8R,EAAG3C,IAAUtH,EAAK,SAASgK,EAAa1C,EAAQjF,EAAS4H,EAAG5H,IAAY,EAAI,MAAQ,KAAK,CAAC,EACxG,IAAMzN,EAASoL,EAAK,iBAClB2E,GAA2BtM,CAAQ,EACnCgR,EACAC,EACAU,EACA7R,EAAK,OACL+M,GAAyBkE,CAAc,CACzC,EACIxU,IAAW,GACbkN,EAAe,iDAAiDjE,CAAS,WAAWyJ,CAAK,GAAG,EAE9F4B,EAAc,KAAKtU,CAAM,CAC3B,QAAE,CACAoL,EAAK,aAAarF,CAAK,CACzB,CACF,EAKasD,GAAM,MACjBJ,EACAC,EACAoM,EACAlM,EACAmM,EACA7W,IAC8B,CAC9B,IAAM0M,EAAOO,EAAY,EACnB8B,EAAUrC,EAAK,SACf2D,EAAUkD,GAAe,IAAIhJ,CAAS,EAC5C,GAAI,CAAC8F,EACH,MAAM,IAAI,MAAM,6CAA6C9F,CAAS,EAAE,EAE1E,IAAMwJ,EAAgB1D,EAAQ,CAAC,EACzBoE,EAAwBpE,EAAQ,CAAC,EACjCqE,EAAyBrE,EAAQ,CAAC,EAClCsF,EAAiBtF,EAAQ,CAAC,EAC1B6E,EAAqB7E,EAAQ,CAAC,EAC9ByG,EAAmBzG,EAAQ,CAAC,EAE5B2E,EAAaxK,EAAa,OAC1ByK,EAAcvK,EAAc,OAE9B4E,EAAmB,EACnByH,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAC/BC,EAAgC,CAAC,EAEjCC,EAAiB1K,EAAK,UAAU,EAChC2K,EAAoB3K,EAAK,WAAWsI,EAAajG,CAAO,EACxDuI,GAAmB5K,EAAK,WAAWsI,EAAajG,CAAO,EACvDwI,GAAqB7K,EAAK,WAAWuI,EAAclG,CAAO,EAC1DyI,GAAoB9K,EAAK,WAAWuI,EAAclG,CAAO,EAE/D,GAAI,CACF,CAACO,EAAkByH,CAAgB,EAAI3H,GAAcpP,CAAO,EAE5D8G,EAAkB,+BAA+B,EAEjD,QAASnH,EAAI,EAAGA,EAAIqV,EAAYrV,IAC9B,MAAM+T,GACJkD,EAAajX,CAAC,EACdqX,EACAE,EACA3M,EACAkK,EAAsBjK,EAAa7K,CAAC,CAAC,EACrC6K,EAAa7K,CAAC,EACduV,CACF,EAIF,QAASvV,EAAI,EAAGA,EAAIsV,EAAatV,IAC/B,MAAM+T,GACJmD,EAAclX,CAAC,EACfsX,EACAC,EACA3M,EACAmK,EAAuBhK,EAAc/K,CAAC,CAAC,EACvCqV,EAAatK,EAAc/K,CAAC,EAC5BuV,CACF,EAEFnO,EAAgB,+BAA+B,EAE/C,QAASpH,EAAI,EAAGA,EAAIqV,EAAYrV,IAC9B+M,EAAK,SAAS2K,EAAoB1X,EAAIoP,EAASiI,EAAmBrX,CAAC,EAAG,GAAG,EACzE+M,EAAK,SAAS4K,GAAmB3X,EAAIoP,EAAS0F,EAAsBjK,EAAa7K,CAAC,CAAC,EAAG,GAAG,EAE3F,QAASA,EAAI,EAAGA,EAAIsV,EAAatV,IAC/B+M,EAAK,SAAS6K,GAAqB5X,EAAIoP,EAASkI,EAAoBtX,CAAC,EAAG,GAAG,EAC3E+M,EAAK,SAAS8K,GAAoB7X,EAAIoP,EAAS2F,EAAuBhK,EAAc/K,CAAC,CAAC,EAAG,GAAG,EA0D9F+M,EAAK,iBAAiBqH,CAAa,EACnCrH,EAAK,kBAAkBqH,CAAa,EAEpC,IAAI9E,EAUFA,EAAY,MAAMvC,EAAK,QACrBqH,EACAuD,GACAD,EACArC,EACAwC,GACAvC,EACAsC,GACAjI,CACF,EAGEL,IAAc,GAChBT,EAAe,0BAA0B,EAG3C,IAAMiJ,EAA2B,CAAC,EAC5BC,GAA4D,CAAC,EAEnE5Q,EAAkB,0BAA0B,EAC5C,QAASnH,EAAI,EAAGA,EAAIsV,EAAatV,IAAK,CACpC,IAAM2B,EAAS,OAAOoL,EAAK,SAAS6K,GAAqB5X,EAAIoP,EAAS,GAAG,CAAC,EAM1E,GAAIzN,IAAW2V,EAAoBtX,CAAC,GAAKwX,EAAoB,SAASF,EAAoBtX,CAAC,CAAC,EAAG,CAE7F8X,EAAO,KAAKZ,EAAclX,CAAC,CAAE,EACzB2B,IAAW2V,EAAoBtX,CAAC,GAE9B+M,EAAK,kBAAkBpL,CAAM,IAAM,GACrCkN,EAAe,uBAAuB,EAG1C,QACF,CAEA,IAAMmJ,GAA2BjL,EAAK,UAAU,EAE1CkL,EAAmBlL,EAAK,WAAW,EAAIqC,CAAO,EAEhD8I,GAAmB,GACnB5S,EACF2J,EAAa,EACf,GAAI,CACgBlC,EAAK,kBACrBpL,EACAsW,EACAA,EAAmB7I,EACnB6I,EAAmB,EAAI7I,EAEvB6I,EAAmB,EAAI7I,CACzB,IACkB,GAChBP,EAAe,4CAA4C7O,CAAC,GAAG,EAEjE,IAAMmY,GAAY/I,IAAY,EAAI,MAAQ,MACpChK,GAAW,OAAO2H,EAAK,SAASkL,EAAkBE,EAAS,CAAC,EAClElJ,EAAalC,EAAK,SAASkL,EAAmB7I,EAAS,GAAG,EAC1D,IAAM2H,GAAahK,EAAK,SAASkL,EAAmB7I,EAAU,EAAG,GAAG,EAC9DgJ,GAAa,OAAOrL,EAAK,SAASkL,EAAmB7I,EAAU,EAAG+I,EAAS,CAAC,EAC5EjT,EAAO,CAAC,EACd,QAASlF,EAAI,EAAGA,EAAIoY,GAAYpY,IAC9BkF,EAAK,KAAK,OAAO6H,EAAK,SAASgK,GAAa/W,EAAIoP,EAAS+I,EAAS,CAAC,CAAC,EAElEpL,EAAK,SAASgK,EAAU,IAAM,GAChClI,EAAe,oCAAoC,EAErD,IAAM1I,EAAOjB,EAAK,OAAO,CAACqN,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAC3ClN,EAAOqM,GAA2BvM,EAAQ,EAE1C,IAAMiT,GAAoBrC,GAAgB,yBAAyBjL,EAAc/K,CAAC,CAAC,EAEnF,GAAIsF,IAAS,SAAU,CACrB,GAAI+S,KAAsB,cAAgBA,KAAsB,YAC9D,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,EAAuB,CAAC,EAC9B,QAAStY,EAAI,EAAGA,EAAImG,EAAMnG,IAAK,CAC7B,IAAMwT,EAASzG,EAAK,SAASkC,EAAajP,EAAIoP,EAAS,GAAG,EACpDmJ,GAAaxL,EAAK,SAASkC,GAAcjP,EAAI,GAAKoP,EAAS,GAAG,EAC9DoJ,GAAiBxY,IAAMmG,EAAO,EAAI,OAAYoS,GAAa/E,EACjE8E,EAAW,KAAKvL,EAAK,aAAayG,EAAQgF,EAAc,CAAC,CAC3D,CACAV,EAAO,KAAK,CAACxS,EAAMJ,EAAMoT,EAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBlS,EAAO,EAAG,CAClD,IAAMsS,EAAgE1L,EAAK,cAC3E,GAAI,CAAC0L,EACH,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMtT,EAAYsT,EAAUxJ,CAAU,EAChCyJ,EAAa9G,GAA2BxM,GAAUe,CAAI,EAC5D,GAAIuS,IAAe,QAAa,CAAC3G,GAAyBzM,CAAI,EAC5D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAIlD4S,GAAmB,GAwBjBJ,EAAO,KAAK,CACVxS,EACAJ,EACA,CACE,UAAAC,EACA,SAAU4H,EAAK,qBAAsB5H,EAAWuT,EAAYpT,CAAI,EAChE,QAAS,IAAM,CACTyH,EAAK,kBAAkBpL,CAAM,IAAM,GACrCkN,EAAe,uBAAuB,CAE1C,CACF,EACA,YACF,CAAC,CAEL,SAAWwJ,KAAsB,aAAelS,EAAO,EAAG,CACxD,IAAMwS,EAAe5L,EAAK,kBACpB6L,EAAkC7L,EAAK,qCAC7C,GAAI,CAAC4L,GAAgB,CAACC,EACpB,MAAM,IAAI,MAAM,qEAAqE,EAGvF,GADmBhH,GAA2BxM,GAAUe,CAAI,IACzC,QAAa,CAAC6L,GAAwB1M,CAAI,EAC3D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,GAAI,CAACsT,EAAgChO,EAAWtF,EAAM,EAAK,EACzD,MAAM,IAAI,MACR,qCAAqCA,CAAI,oDAC3C,EAMF,IAAMD,GAAW,MAAMsT,EAAa/N,EAAWqE,EAAY7J,GAAUF,EAAM,EAAK,EAGhFgT,GAAmB,GAEnBJ,EAAO,KAAK,CACVxS,EACAJ,EACA,CACE,SAAAG,GACA,SAAU0H,EAAK,8BAA+BkC,EAAY3J,CAAI,EAC9D,QAAS,IAAM,CACbyH,EAAK,qBAAsBkC,CAAU,EACrClC,EAAK,kBAAkBpL,CAAM,CAC/B,CACF,EACA,WACF,CAAC,CACH,SAAW0W,KAAsB,wBAA0BlS,EAAO,EAAG,CACnE,IAAM9B,EAAO0I,EAAK,8BAA+BkC,EAAY3J,CAAgC,EAAE,EACzF+O,EAAQyD,EAAO,OAErBI,GAAmB,GACnBH,GAAe,MACZ,SAAY,CACX,IAAMtP,EAAoC,CAAC4L,EAAO,MAAMhQ,CAAI,EAC5D,OAAA0I,EAAK,qBAAsBkC,CAAU,EACrClC,EAAK,kBAAkBpL,CAAM,EACtB8G,CACT,GAAG,CACL,EACAqP,EAAO,KAAK,CAACxS,EAAMJ,EAAM,CAAC,EAAG,KAAK,CAAC,CACrC,KAAO,CACL,IAAMwB,EAAwBmL,GAAkCvM,CAAI,EAC9DjB,EAAO,IAAIqC,EAAsBP,CAAI,EAC3C,IAAI,WAAW9B,EAAK,OAAQA,EAAK,WAAYA,EAAK,UAAU,EAAE,IAC5D0I,EAAK,OAAO,SAASkC,EAAYA,EAAa5K,EAAK,UAAU,CAC/D,EACAyT,EAAO,KAAK,CAACxS,EAAMJ,EAAMb,EAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACA0I,EAAK,aAAaiL,EAAwB,EACtC1S,IAAS,UAAY2J,GACvBlC,EAAK,MAAMkC,CAAU,EAElBiJ,IACHnL,EAAK,kBAAkBpL,CAAM,CAEjC,CACF,CAEIqU,GAAkB,CAACT,IACjBxI,EAAK,sBAAsBiJ,EAAe,MAAM,IAAM,GACxDnH,EAAe,4BAA4B,EAE7C+E,GAAe,IAAIhJ,EAAW,CAC5BwJ,EACAU,EACAC,EACAiB,EACAT,EACA,EACF,CAAC,GAGH,OAAW,CAAClB,EAAOhQ,CAAI,IAAK,MAAM,QAAQ,IAAI0T,EAAc,EAC1DD,EAAOzD,CAAK,EAAE,CAAC,EAAIhQ,EAErB,OAAA+C,EAAgB,0BAA0B,EACnC0Q,CACT,QAAE,CACA/K,EAAK,gBAAgBqH,CAAa,EAElCrH,EAAK,aAAa0K,CAAc,EAchCJ,EAAmB,QAAShP,GAAM0E,EAAK,kBAAkB1E,CAAC,CAAC,EAC3DiP,EAAoB,QAASjP,GAAM0E,EAAK,kBAAkB1E,CAAC,CAAC,EAC5DkP,EAAkB,QAASsB,GAAM9L,EAAK,MAAM8L,CAAC,CAAC,EAE1ClJ,IAAqB,GACvB5C,EAAK,sBAAsB4C,CAAgB,EAE7CyH,EAAiB,QAASyB,GAAM9L,EAAK,MAAM8L,CAAC,CAAC,CAC/C,CACF,EAKazN,GAAgBR,GAA4B,CACvD,IAAMmC,EAAOO,EAAY,EACnBoD,EAAUkD,GAAe,IAAIhJ,CAAS,EAC5C,GAAI,CAAC8F,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAM0D,EAAgB1D,EAAQ,CAAC,EAGzBoI,EAAkB/L,EAAK,iBAAiBqH,CAAa,EACvD0E,IAAoB,GACtBjK,EAAe,iCAAiC,EAElD9B,EAAK,SAAS+L,CAAe,CAC/B,EAEa3N,GAA8B4N,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAWrX,KAAUoX,EAAS,CAC5B,IAAM1U,EAAO1C,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQ0C,CAAI,GAAK,WAAYA,GACtC2U,EAAQ,KAAK3U,EAAK,MAAM,CAE5B,CACA,OAAO2U,CACT,IC1mCA,IAoBMC,GACFC,EACAjM,GACAD,GACAE,GACAiM,GAGAC,GACEC,GAEAC,GASAC,GAMAC,GAkCOC,GAiFAC,GAaAnP,GAaAE,GAwBAE,GAaAK,GAgCAI,GAhQbuO,GAAAha,EAAA,kBAGA2J,IASAO,KACAC,KACAC,KAMMkP,GAAU,IAAe,CAAC,CAAC7X,EAAI,KAAK,OAAS,OAAO,SAAa,IAEnE6L,GAAe,GACfD,GAAc,GACdE,GAAU,GAKRmM,GAAiF,IAAI,IAErFC,GAAmB,CAAChU,EAA8BsU,IAA+C,CACrG,IAAMC,EAAQR,GAAgB,IAAI/T,CAAI,EAClCuU,EACFA,EAAM,KAAKD,CAAS,EAEpBP,GAAgB,IAAI/T,EAAM,CAACsU,CAAS,CAAC,CAEzC,EAEML,GAAe,IAAY,CAC/B,GAAItM,IAAgB,CAACD,IAAeE,IAAW,CAACgM,EAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMM,GAAwBxP,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACHiD,GAAe,GACXjD,EAAG,KAAK,KACVkD,GAAU,GACVkM,GAAkB,CAAC,EAAEpP,EAAG,KAAK,GAAG,IAEhCgD,GAAc,GACdoM,GAAkB,CAAC,EAAE,GAEnBD,KACF,IAAI,gBAAgBA,EAAkB,EACtCA,GAAqB,QAEvB,MACF,IAAK,UACL,IAAK,YACL,IAAK,SACL,IAAK,UACL,IAAK,MACL,IAAK,gBAAiB,CACpB,IAAMS,EAAYP,GAAgB,IAAIrP,EAAG,KAAK,IAAI,EAC9CA,EAAG,KAAK,IACV4P,EAAU,MAAM,EAAG,CAAC,EAAE5P,EAAG,KAAK,GAAG,EAEjC4P,EAAU,MAAM,EAAG,CAAC,EAAE5P,EAAG,KAAK,GAAI,EAEpC,KACF,CACA,QACF,CACF,EAEayP,GAAqC,SAA2B,CAC3E,GAAI,CAAAzM,GAGJ,IAAIC,GACF,MAAM,IAAI,MAAM,0CAA0C,EAE5D,GAAIC,GACF,MAAM,IAAI,MAAM,uCAAuC,EAKzD,GAFAD,GAAe,GAEuBgM,GAAQ,EAC5C,OAAO,IAAI,QAAc,CAACvU,EAASC,IAAW,CAC5CuU,GAAa,UAAU,EAElBlN,GAAkB,EAAE,KAAK,CAAC,CAACkC,EAAW4L,CAAM,IAAM,CACrD,GAAI,CACFZ,EAAcY,EACdZ,EAAY,QAAWlP,GAAmBrF,EAAOqF,CAAE,EACnDkP,EAAY,UAAYM,GACxBJ,GAAoB,CAAC1U,EAASC,CAAM,EACpC,IAAMsF,EAA0B,CAAE,KAAM,YAAa,GAAI7I,CAAI,EAM7D,GAAyC,CAAC6I,EAAQ,GAAI,KAAK,WAAaiE,EAAW,CAGjF,IAAMM,EAAyB/C,GAAiC,EAC5D+C,IACFvE,EAAQ,GAAI,KAAK,UAAYuE,EAEjC,CAwBA0K,EAAY,YAAYjP,CAAO,EAC/BkP,GAAqBjL,CACvB,OAAS9N,EAAG,CACVuE,EAAOvE,CAAC,CACV,CACF,EAAGuE,CAAM,CACX,CAAC,EAED,GAAI,CACF,MAAMuF,GAAsB9I,EAAI,IAAI,EACpC,MAAW+I,GAAY/I,CAAG,EAC1B4L,GAAc,EAChB,OAAS,EAAG,CACV,MAAAE,GAAU,GACJ,CACR,QAAE,CACAD,GAAe,EACjB,EAEJ,EAEayM,GAAkB,MAAOtP,GAAkC,CACtE,GAAsC6O,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7U,EAASC,IAAW,CAC5C2U,GAAiB,UAAW,CAAC5U,EAASC,CAAM,CAAC,EAC7C,IAAMsF,EAA0B,CAAE,KAAM,UAAW,GAAI,CAAE,OAAAG,EAAQ,IAAAhJ,CAAI,CAAE,EACvE8X,EAAa,YAAYjP,CAAO,CAClC,CAAC,EAED,MAAWI,GAAOjJ,EAAKgJ,CAAM,CAEjC,EAEaG,GAAyB,MAAO1G,GACLoV,GAAQ,GAC5CM,GAAa,EACN,IAAI,QAAoC,CAAC7U,EAASC,IAAW,CAClE2U,GAAiB,YAAa,CAAC5U,EAASC,CAAM,CAAC,EAC/C,IAAMsF,EAA0B,CAAE,KAAM,YAAa,GAAI,CAAE,OAAApG,CAAO,CAAE,EACpEqV,EAAa,YAAYjP,EAAS,CAACpG,EAAO,MAAM,CAAC,CACnD,CAAC,GAEW0G,GAAuB1G,CAAM,EAIhC4G,GAAgB,MAC3BD,EACAnK,IACyC,CACzC,GAAsC4Y,GAAQ,EAAG,CAE/C,GAAI5Y,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAAkZ,GAAa,EACN,IAAI,QAAqC,CAAC7U,EAASC,IAAW,CACnE2U,GAAiB,SAAU,CAAC5U,EAASC,CAAM,CAAC,EAC5C,IAAMsF,EAA0B,CAAE,KAAM,SAAU,GAAI,CAAE,MAAAO,EAAO,QAAS,CAAE,GAAGnK,CAAQ,CAAE,CAAE,EACnF0Z,EAA+B,CAAC,EAClCvP,aAAiB,YACnBuP,EAAa,KAAKvP,EAAM,MAAM,EAEhC0O,EAAa,YAAYjP,EAAS8P,CAAY,CAChD,CAAC,CACH,KACE,QAAYtP,GAAcD,EAAOnK,CAAO,CAE5C,EAEasK,GAAiB,MAAOC,GAAqC,CACxE,GAAsCqO,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7U,EAASC,IAAW,CAC5C2U,GAAiB,UAAW,CAAC5U,EAASC,CAAM,CAAC,EAC7C,IAAMsF,EAA0B,CAAE,KAAM,UAAW,GAAIW,CAAU,EACjEsO,EAAa,YAAYjP,CAAO,CAClC,CAAC,EAEIU,GAAeC,CAAS,CAEjC,EAEaI,GAAM,MACjBJ,EACAC,EACAC,EACAC,EACAE,EACA5K,IAC8B,CAC9B,GAAsC4Y,GAAQ,EAAG,CAE/C,GAAInO,EAAO,KAAMkP,GAAMA,EAAE,CAAC,IAAM,KAAK,EACnC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAI/O,EAAQ,KAAM+O,GAAMA,CAAC,EACvB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAT,GAAa,EACN,IAAI,QAAsC,CAAC7U,EAASC,IAAW,CACpE2U,GAAiB,MAAO,CAAC5U,EAASC,CAAM,CAAC,EACzC,IAAMsV,EAAqBnP,EACrBb,EAA0B,CAC9B,KAAM,MACN,GAAI,CAAE,UAAAW,EAAW,aAAAC,EAAc,OAAQoP,EAAoB,cAAAlP,EAAe,QAAA1K,CAAQ,CACpF,EACA6Y,EAAa,YAAYjP,EAAckB,GAA2B8O,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYjP,GAAIJ,EAAWC,EAAcC,EAAQC,EAAeE,EAAS5K,CAAO,CAEpF,EAEa+K,GAAe,MAAOR,GAAqC,CACtE,GAAsCqO,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7U,EAASC,IAAW,CAC5C2U,GAAiB,gBAAiB,CAAC5U,EAASC,CAAM,CAAC,EACnD,IAAMsF,EAA0B,CAAE,KAAM,gBAAiB,GAAIW,CAAU,EACvEsO,EAAa,YAAYjP,CAAO,CAClC,CAAC,EAEImB,GAAaR,CAAS,CAE/B,IC3QA,IAkBasP,GAaAC,GAyBAC,GAxDbC,GAAA1a,EAAA,kBAGA2J,IAUAqQ,KACAzH,KACA3I,KACAqJ,KAEasH,GAAuB,CAACvY,EAAgB2Y,IAA0C,CAC7F,OAAQ3Y,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,UAAWA,EAAO,SAAU,EAAG,YAAY,EACjF,IAAK,YACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,SAAUA,EAAO,QAAS,EAAG,WAAW,EAC9E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQ2Y,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaH,GAAwBxY,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIqC,EAAOrC,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMyD,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAACoQ,GAAyB3M,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAE,UAAAD,EAAW,SAAAH,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EACjD,OAAOqC,EAAO,cAAcmB,EAAW,CAAE,SAAAC,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACzF,CACA,IAAK,YAAa,CAChB,IAAMG,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAACqQ,GAAwB5M,CAAQ,EACnC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,oCAAoC,EAE1F,GAAM,CAAE,SAAAC,EAAU,SAAAL,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EAChD,OAAOqC,EAAO,aAAaqB,EAAU,CAAE,SAAAD,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BtD,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEayY,GAAN,KAA8E,CAQnF,MAAM,8BAA8BnF,EAAmD,CAErF,OAAO1K,GAAuB,MAAMoI,GAASsC,CAAI,CAAC,CACpD,CAEA,MAAM,UAAUsF,EAAmCla,EAA0D,CAC3G4G,EAAiB,EACjB,IAAIuD,EAEA,OAAO+P,GAAiB,SAOxB/P,EAAQ,MAAM,KAAK,8BAA8B+P,CAAY,EAG/D/P,EAAQ+P,EAGV,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,YAAa,KAAK,cAAe,KAAK,cAAc,EAAI,MAAM9P,GACnGD,EACAnK,CACF,EACA6G,EAAe,CACjB,CAEA,MAAM,SAAyB,CAC7B,OAAOyD,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IACJ3C,EACAC,EACA5H,EACoC,CACpC4G,EAAiB,EACjB,IAAMuT,EAAuB,CAAC,EACxB3P,EAAyB,CAAC,EAChC,OAAO,QAAQ7C,CAAK,EAAE,QAASyS,GAAQ,CACrC,IAAM7a,EAAO6a,EAAI,CAAC,EACZ9Y,EAAS8Y,EAAI,CAAC,EACdpG,EAAQ,KAAK,WAAW,QAAQzU,CAAI,EAC1C,GAAIyU,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBzU,CAAI,GAAG,EAE3C4a,EAAW,KAAK7Y,CAAM,EACtBkJ,EAAa,KAAKwJ,CAAK,CACzB,CAAC,EAED,IAAMqG,EAAoC,CAAC,EACrC3P,EAA0B,CAAC,EACjC,OAAO,QAAQ9C,CAAO,EAAE,QAASwS,GAAQ,CACvC,IAAM7a,EAAO6a,EAAI,CAAC,EACZ9Y,EAAS8Y,EAAI,CAAC,EACdpG,EAAQ,KAAK,YAAY,QAAQzU,CAAI,EAC3C,GAAIyU,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBzU,CAAI,GAAG,EAE5C8a,EAAY,KAAK/Y,CAAM,EACvBoJ,EAAc,KAAKsJ,CAAK,CAC1B,CAAC,EAED,IAAMvJ,EAAS0P,EAAW,IAAI,CAACR,EAAGha,IAChCka,GAAqBF,EAAG,IAAM,UAAU,KAAK,WAAWnP,EAAa7K,CAAC,CAAC,CAAC,GAAG,CAC7E,EACMiL,EAAUyP,EAAY,IAAI,CAACV,EAAGha,IAClCga,EAAIE,GAAqBF,EAAG,IAAM,WAAW,KAAK,YAAYjP,EAAc/K,CAAC,CAAC,CAAC,GAAG,EAAI,IACxF,EAEMsI,EAAU,MAAM0C,GAAI,KAAK,UAAWH,EAAcC,EAAQC,EAAeE,EAAS5K,CAAO,EAEzFsa,EAAuC,CAAC,EAC9C,QAAS3a,EAAI,EAAGA,EAAIsI,EAAQ,OAAQtI,IAClC2a,EAAU,KAAK,YAAY5P,EAAc/K,CAAC,CAAC,CAAC,EAAI0a,EAAY1a,CAAC,GAAKma,GAAqB7R,EAAQtI,CAAC,CAAC,EAEnG,OAAAkH,EAAe,EACRyT,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdvP,GAAa,KAAK,SAAS,CAClC,CACF,ICzJA,IAAAwP,GAAA,GAAAvR,GAAAuR,GAAA,mCAAAC,GAAA,oBAAAC,GAAA,gBAAAC,KAAA,IAcaD,GA4CAD,GAqCAE,GA/FbC,GAAArb,EAAA,kBAGA2J,IAEAqQ,KACAU,KAQaS,GAAkB,IAAY,EACrC,OAAO1Z,EAAI,KAAK,aAAgB,UAAYA,EAAI,KAAK,YAAc,KACrEA,EAAI,KAAK,YAAc,GAGzB,IAAM6Z,EAAO7Z,EAAI,KAAK,KAiBtB,GAhBI,OAAO6Z,GAAS,WAAaA,IAAS,QAAaA,IAAS,SAAWA,IAAS,YAElF,QAAQ,KACN,qDAAqDA,CAAI,4DAC3D,EACA7Z,EAAI,KAAK,KAAO,IAGd,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,EAAI,KAAK,UAAU,GAAKA,EAAI,KAAK,YAAc,EAY9G,GAAI,OAAO,KAAS,KAAe,CAAC,KAAK,oBACvCA,EAAI,KAAK,WAAa,MACjB,CACL,IAAM8Z,EACJ,OAAO,UAAc,IAAc,GAAQ,SAAS,EAAE,KAAK,EAAE,OAAS,UAAU,oBAClF9Z,EAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAM8Z,GAAsB,GAAK,CAAC,CAAC,CAC5E,CAEJ,EAEaL,GAAN,KAAuD,CAS5D,MAAM,KAAK5a,EAAoC,CAE7C6a,GAAgB,EAGhB,MAAMrB,GAAmC,EAGzC,MAAMC,GAAgBzZ,CAAW,CACnC,CASA,MAAM,8BACJsa,EACAla,EACkC,CAClC,IAAM0H,EAAU,IAAIqS,GACpB,aAAMrS,EAAQ,UAAUwS,EAAcla,CAAO,EACtC0H,CACT,CACF,EAEagT,GAAc,IAAIF,KC/F/B,IAAAM,GAAA,GAAA9R,GAAA8R,GAAA,sBAAAvT,GAAA,UAAAb,GAAA,sBAAAI,EAAA,oBAAAC,EAAA,qBAAAH,EAAA,mBAAAC,EAAA,WAAAlD,EAAA,YAAAoX,GAAA,QAAAha,EAAA,oBAAA7B,KASA+J,IACAA,IAGAA,ICPO,IAAMrI,GAAU,SDKvB,IAAOma,GAAQhS,GAwBe,CAC5B,IAAM2R,EAAc,cAA0B,YAO9Cxb,GAAgB,MAAOwb,EAAa,EAAE,EACtCxb,GAAgB,OAAQwb,EAAa,EAAE,CACzC,CAEA,OAAO,eAAe3Z,EAAI,SAAU,MAAO,CAAE,MAAOH,GAAS,WAAY,EAAK,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Backend } from './backend.js';\r\nimport { InferenceSession } from './inference-session.js';\r\n\r\ninterface BackendInfo {\r\n  backend: Backend;\r\n  priority: number;\r\n\r\n  initPromise?: Promise<void>;\r\n  initialized?: boolean;\r\n  aborted?: boolean;\r\n  error?: string;\r\n}\r\n\r\nconst backends: Map<string, BackendInfo> = new Map();\r\nconst backendsSortedByPriority: string[] = [];\r\n\r\n/**\r\n * Register a backend.\r\n *\r\n * @param name - the name as a key to lookup as an execution provider.\r\n * @param backend - the backend object.\r\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\r\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\r\n *\r\n * @ignore\r\n */\r\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\r\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\r\n    const currentBackend = backends.get(name);\r\n    if (currentBackend === undefined) {\r\n      backends.set(name, { backend, priority });\r\n    } else if (currentBackend.priority > priority) {\r\n      // same name is already registered with a higher priority. skip registeration.\r\n      return;\r\n    } else if (currentBackend.priority === priority) {\r\n      if (currentBackend.backend !== backend) {\r\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\r\n      }\r\n    }\r\n\r\n    if (priority >= 0) {\r\n      const i = backendsSortedByPriority.indexOf(name);\r\n      if (i !== -1) {\r\n        backendsSortedByPriority.splice(i, 1);\r\n      }\r\n\r\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\r\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\r\n          backendsSortedByPriority.splice(i, 0, name);\r\n          return;\r\n        }\r\n      }\r\n      backendsSortedByPriority.push(name);\r\n    }\r\n    return;\r\n  }\r\n\r\n  throw new TypeError('not a valid backend');\r\n};\r\n\r\n/**\r\n * Try to resolve and initialize a backend.\r\n *\r\n * @param backendName - the name of the backend.\r\n * @returns the backend instance if resolved and initialized successfully, or an error message if failed.\r\n */\r\nconst tryResolveAndInitializeBackend = async (backendName: string): Promise<Backend | string> => {\r\n  const backendInfo = backends.get(backendName);\r\n  if (!backendInfo) {\r\n    return 'backend not found.';\r\n  }\r\n\r\n  if (backendInfo.initialized) {\r\n    return backendInfo.backend;\r\n  } else if (backendInfo.aborted) {\r\n    return backendInfo.error!;\r\n  } else {\r\n    const isInitializing = !!backendInfo.initPromise;\r\n    try {\r\n      if (!isInitializing) {\r\n        backendInfo.initPromise = backendInfo.backend.init(backendName);\r\n      }\r\n      await backendInfo.initPromise;\r\n      backendInfo.initialized = true;\r\n      return backendInfo.backend;\r\n    } catch (e) {\r\n      if (!isInitializing) {\r\n        backendInfo.error = `${e}`;\r\n        backendInfo.aborted = true;\r\n      }\r\n      return backendInfo.error!;\r\n    } finally {\r\n      delete backendInfo.initPromise;\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * Resolve execution providers from the specific session options.\r\n *\r\n * @param options - the session options object.\r\n * @returns a promise that resolves to a tuple of an initialized backend instance and a session options object with\r\n * filtered EP list.\r\n *\r\n * @ignore\r\n */\r\nexport const resolveBackendAndExecutionProviders = async (\r\n  options: InferenceSession.SessionOptions,\r\n): Promise<[backend: Backend, options: InferenceSession.SessionOptions]> => {\r\n  // extract backend hints from session options\r\n  const eps = options.executionProviders || [];\r\n  const backendHints = eps.map((i) => (typeof i === 'string' ? i : i.name));\r\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\r\n\r\n  // try to resolve and initialize all requested backends\r\n  let backend: Backend | undefined;\r\n  const errors = [];\r\n  const availableBackendNames = new Set<string>();\r\n  for (const backendName of backendNames) {\r\n    const resolveResult = await tryResolveAndInitializeBackend(backendName);\r\n    if (typeof resolveResult === 'string') {\r\n      errors.push({ name: backendName, err: resolveResult });\r\n    } else {\r\n      if (!backend) {\r\n        backend = resolveResult;\r\n      }\r\n      if (backend === resolveResult) {\r\n        availableBackendNames.add(backendName);\r\n      }\r\n    }\r\n  }\r\n\r\n  // if no backend is available, throw error.\r\n  if (!backend) {\r\n    throw new Error(`no available backend found. ERR: ${errors.map((e) => `[${e.name}] ${e.err}`).join(', ')}`);\r\n  }\r\n\r\n  // for each explicitly requested backend, if it's not available, output warning message.\r\n  for (const { name, err } of errors) {\r\n    if (backendHints.includes(name)) {\r\n      // eslint-disable-next-line no-console\r\n      console.warn(\r\n        `removing requested execution provider \"${name}\" from session options because it is not available: ${err}`,\r\n      );\r\n    }\r\n  }\r\n\r\n  const filteredEps = eps.filter((i) => availableBackendNames.has(typeof i === 'string' ? i : i.name));\r\n\r\n  return [\r\n    backend,\r\n    new Proxy(options, {\r\n      get: (target, prop) => {\r\n        if (prop === 'executionProviders') {\r\n          return filteredEps;\r\n        }\r\n        return Reflect.get(target, prop);\r\n      },\r\n    }),\r\n  ];\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession } from './inference-session.js';\r\nimport { OnnxValue } from './onnx-value.js';\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport declare namespace SessionHandler {\r\n  type FeedsType = { [name: string]: OnnxValue };\r\n  type FetchesType = { [name: string]: OnnxValue | null };\r\n  type ReturnType = { [name: string]: OnnxValue };\r\n}\r\n\r\n/**\r\n * Represents shared SessionHandler functionality\r\n *\r\n * @ignore\r\n */\r\ninterface SessionHandler {\r\n  dispose(): Promise<void>;\r\n\r\n  readonly inputNames: readonly string[];\r\n  readonly outputNames: readonly string[];\r\n\r\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n}\r\n\r\n/**\r\n * Represent a handler instance of an inference session.\r\n *\r\n * @ignore\r\n */\r\nexport interface InferenceSessionHandler extends SessionHandler {\r\n  startProfiling(): void;\r\n  endProfiling(): void;\r\n\r\n  run(\r\n    feeds: SessionHandler.FeedsType,\r\n    fetches: SessionHandler.FetchesType,\r\n    options: InferenceSession.RunOptions,\r\n  ): Promise<SessionHandler.ReturnType>;\r\n}\r\n\r\n/**\r\n * Represent a backend that provides implementation of model inferencing.\r\n *\r\n * @ignore\r\n */\r\nexport interface Backend {\r\n  /**\r\n   * Initialize the backend asynchronously. Should throw when failed.\r\n   */\r\n  init(backendName: string): Promise<void>;\r\n\r\n  createInferenceSessionHandler(\r\n    uriOrBuffer: string | Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n}\r\n\r\nexport { registerBackend } from './backend-impl.js';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// This file is generated by /js/scripts/update-version.ts\r\n// Do not modify file content manually.\r\n\r\nexport const version = '1.23.0';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Env } from './env.js';\r\nimport { version } from './version.js';\r\n\r\ntype LogLevelType = Env['logLevel'];\r\n\r\nlet logLevelValue: Required<LogLevelType> = 'warning';\r\n\r\nexport const env: Env = {\r\n  wasm: {} as Env.WebAssemblyFlags,\r\n  webgl: {} as Env.WebGLFlags,\r\n  webgpu: {} as Env.WebGpuFlags,\r\n  versions: { common: version },\r\n\r\n  set logLevel(value: LogLevelType) {\r\n    if (value === undefined) {\r\n      return;\r\n    }\r\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\r\n      throw new Error(`Unsupported logging level: ${value}`);\r\n    }\r\n    logLevelValue = value;\r\n  },\r\n  get logLevel(): Required<LogLevelType> {\r\n    return logLevelValue;\r\n  },\r\n};\r\n\r\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\r\nObject.defineProperty(env, 'logLevel', { enumerable: true });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env as envImpl } from './env-impl.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\nexport declare namespace Env {\r\n  export type WasmPathPrefix = string;\r\n  export interface WasmFilePaths {\r\n    /**\r\n     * Specify the override path for the main .wasm file.\r\n     *\r\n     * This path should be an absolute path.\r\n     *\r\n     * If not modified, the filename of the .wasm file is:\r\n     * - `ort-wasm-simd-threaded.wasm` for default build\r\n     * - `ort-wasm-simd-threaded.jsep.wasm` for JSEP build (with WebGPU and WebNN)\r\n     * - `ort-wasm-simd-threaded.asyncify.wasm` for WebGPU build with Asyncify (with WebNN)\r\n     */\r\n    wasm?: URL | string;\r\n    /**\r\n     * Specify the override path for the main .mjs file.\r\n     *\r\n     * This path should be an absolute path.\r\n     *\r\n     * If not modified, the filename of the .mjs file is:\r\n     * - `ort-wasm-simd-threaded.mjs` for default build\r\n     * - `ort-wasm-simd-threaded.jsep.mjs` for JSEP build (with WebGPU and WebNN)\r\n     * - `ort-wasm-simd-threaded.asyncify.mjs` for WebGPU build with Asyncify (with WebNN)\r\n     */\r\n    mjs?: URL | string;\r\n  }\r\n  export type WasmPrefixOrFilePaths = WasmPathPrefix | WasmFilePaths;\r\n  export interface WebAssemblyFlags {\r\n    /**\r\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\r\n     * to 1, no worker thread will be spawned.\r\n     *\r\n     * This setting is available only when WebAssembly multithread feature is available in current context.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    numThreads?: number;\r\n\r\n    /**\r\n     * set a value indicating whether to enable SIMD.\r\n     *\r\n     * ONNX Runtime will perform feature detection based on the value of this property. Specifically, when the value is\r\n     * set to:\r\n     * - `undefined`, `true` or `\"fixed\"`: will check availability of Fixed-width SIMD.\r\n     * - `\"relaxed\"`: will check availability of Relaxed SIMD.\r\n     * - `false`: will not perform SIMD feature checking.\r\n     *\r\n     * Setting this property does not make ONNX Runtime to switch to the corresponding runtime automatically. User need\r\n     * to set `wasmPaths` or `wasmBinary` property to load the corresponding runtime.\r\n     *\r\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\r\n     *\r\n     * @defaultValue `true`\r\n     */\r\n    simd?: boolean | 'fixed' | 'relaxed';\r\n\r\n    /**\r\n     * set or get a boolean value indicating whether to enable trace.\r\n     *\r\n     * @defaultValue `false`\r\n     *\r\n     * @deprecated Use `env.trace` instead. If `env.trace` is set, this property will be ignored.\r\n     */\r\n    trace?: boolean;\r\n\r\n    /**\r\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\r\n     * value indicates no timeout is set.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    initTimeout?: number;\r\n\r\n    /**\r\n     * Set a custom URL prefix to the .wasm/.mjs files, or an object of overrides for both .wasm/.mjs file. The override\r\n     * path should be an absolute path.\r\n     */\r\n    wasmPaths?: WasmPrefixOrFilePaths;\r\n\r\n    /**\r\n     * Set a custom buffer which contains the WebAssembly binary. If this property is set, the `wasmPaths` property will\r\n     * be ignored.\r\n     */\r\n    wasmBinary?: ArrayBufferLike | Uint8Array;\r\n\r\n    /**\r\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    proxy?: boolean;\r\n  }\r\n\r\n  export interface WebGLFlags {\r\n    /**\r\n     * Set or get the WebGL Context ID (webgl or webgl2).\r\n     *\r\n     * @defaultValue `'webgl2'`\r\n     */\r\n    contextId?: 'webgl' | 'webgl2';\r\n    /**\r\n     * Get the WebGL rendering context.\r\n     */\r\n    readonly context: WebGLRenderingContext;\r\n    /**\r\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\r\n     *\r\n     * @deprecated\r\n     */\r\n    matmulMaxBatchSize?: number;\r\n    /**\r\n     * Set or get the texture cache mode.\r\n     *\r\n     * @defaultValue `'full'`\r\n     */\r\n    textureCacheMode?: 'initializerOnly' | 'full';\r\n    /**\r\n     * Set or get the packed texture mode\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    pack?: boolean;\r\n    /**\r\n     * Set or get whether enable async download.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    async?: boolean;\r\n  }\r\n\r\n  export interface WebGpuProfilingDataV1TensorMetadata {\r\n    dims: readonly number[];\r\n    dataType: string;\r\n  }\r\n  export interface WebGpuProfilingDataV1 {\r\n    version: 1;\r\n    inputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\r\n    outputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\r\n    kernelId: number;\r\n    kernelType: string;\r\n    kernelName: string;\r\n    programName: string;\r\n    startTime: number;\r\n    endTime: number;\r\n  }\r\n\r\n  export type WebGpuProfilingData = WebGpuProfilingDataV1;\r\n\r\n  export interface WebGpuFlags {\r\n    /**\r\n     * Set or get the profiling mode.\r\n     *\r\n     * @deprecated Use `env.webgpu.profiling.mode` instead. If `env.webgpu.profiling.mode` is set, this property will be\r\n     * ignored.\r\n     */\r\n    profilingMode?: 'off' | 'default';\r\n    /**\r\n     * Set or get the profiling configuration.\r\n     */\r\n    profiling: {\r\n      /**\r\n       * Set or get the profiling mode.\r\n       *\r\n       * @defaultValue `'off'`\r\n       */\r\n      mode?: 'off' | 'default';\r\n\r\n      /**\r\n       * Set or get a callback function when a profiling data is received. If not set, the profiling data will be\r\n       * printed to console.\r\n       */\r\n      ondata?: (data: WebGpuProfilingData) => void;\r\n    };\r\n    /**\r\n     * Set or get the power preference.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as options for `navigator.gpu.requestAdapter()`.\r\n     *\r\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\r\n     *\r\n     * @defaultValue `undefined`\r\n     *\r\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\r\n     * you want to use a specific power preference.\r\n     */\r\n    powerPreference?: 'low-power' | 'high-performance';\r\n    /**\r\n     * Set or get the force fallback adapter flag.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as options for `navigator.gpu.requestAdapter()`.\r\n     *\r\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\r\n     *\r\n     * @defaultValue `undefined`\r\n     *\r\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\r\n     * you want to use a specific fallback option.\r\n     */\r\n    forceFallbackAdapter?: boolean;\r\n    /**\r\n     * Set or get the adapter for WebGPU.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as the GPU adapter for the underlying WebGPU backend to create GPU device.\r\n     *\r\n     * If this property is not set, it will be available to get after the first WebGPU inference session is created. The\r\n     * value will be the GPU adapter that created by the underlying WebGPU backend.\r\n     *\r\n     * When use with TypeScript, the type of this property is `GPUAdapter` defined in \"@webgpu/types\".\r\n     *\r\n     * @deprecated It is no longer recommended to use this property. The latest WebGPU spec adds `GPUDevice.adapterInfo`\r\n     * (https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo), which allows to get the adapter information from the\r\n     * device. When it's available, there is no need to set/get the {@link adapter} property.\r\n     */\r\n    adapter: TryGetGlobalType<'GPUAdapter'>;\r\n    /**\r\n     * Set or get the GPU device for WebGPU.\r\n     *\r\n     * There are 3 valid scenarios of accessing this property:\r\n     * - Set a value before the first WebGPU inference session is created. The value will be used by the WebGPU backend\r\n     * to perform calculations. If the value is not a `GPUDevice` object, an error will be thrown.\r\n     * - Get the value before the first WebGPU inference session is created. This will try to create a new GPUDevice\r\n     * instance. Returns a `Promise` that resolves to a `GPUDevice` object.\r\n     * - Get the value after the first WebGPU inference session is created. Returns a resolved `Promise` to the\r\n     * `GPUDevice` object used by the WebGPU backend.\r\n     */\r\n    get device(): Promise<TryGetGlobalType<'GPUDevice'>>;\r\n    set device(value: TryGetGlobalType<'GPUDevice'>);\r\n    /**\r\n     * Set or get whether validate input content.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    validateInputContent?: boolean;\r\n  }\r\n}\r\n\r\nexport interface Env {\r\n  /**\r\n   * set the severity level for logging.\r\n   *\r\n   * @defaultValue `'warning'`\r\n   */\r\n  logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal';\r\n\r\n  /**\r\n   * Indicate whether run in debug mode.\r\n   *\r\n   * @defaultValue `false`\r\n   */\r\n  debug?: boolean;\r\n\r\n  /**\r\n   * set or get a boolean value indicating whether to enable trace.\r\n   *\r\n   * @defaultValue `false`\r\n   */\r\n  trace?: boolean;\r\n\r\n  /**\r\n   * Get version of the current package.\r\n   */\r\n  readonly versions: {\r\n    readonly common: string;\r\n    readonly web?: string;\r\n    readonly node?: string;\r\n    // eslint-disable-next-line @typescript-eslint/naming-convention\r\n    readonly 'react-native'?: string;\r\n  };\r\n\r\n  /**\r\n   * Represent a set of flags for WebAssembly\r\n   */\r\n  readonly wasm: Env.WebAssemblyFlags;\r\n\r\n  /**\r\n   * Represent a set of flags for WebGL\r\n   */\r\n  readonly webgl: Env.WebGLFlags;\r\n\r\n  /**\r\n   * Represent a set of flags for WebGPU\r\n   */\r\n  readonly webgpu: Env.WebGpuFlags;\r\n\r\n  [name: string]: unknown;\r\n}\r\n\r\n/**\r\n * Represent a set of flags as a global singleton.\r\n */\r\nexport const env: Env = envImpl;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\r\nimport { Tensor } from './tensor.js';\r\n\r\n/**\r\n * implementation of Tensor.toDataURL()\r\n */\r\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\r\n  const canvas = typeof document !== 'undefined' ? document.createElement('canvas') : new OffscreenCanvas(1, 1);\r\n  canvas.width = tensor.dims[3];\r\n  canvas.height = tensor.dims[2];\r\n  const pixels2DContext = canvas.getContext('2d') as\r\n    | CanvasRenderingContext2D\r\n    | OffscreenCanvasRenderingContext2D\r\n    | null;\r\n\r\n  if (pixels2DContext != null) {\r\n    // Default values for height and width & format\r\n    let width: number;\r\n    let height: number;\r\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\r\n      width = tensor.dims[2];\r\n      height = tensor.dims[3];\r\n    } else {\r\n      // Default layout is NCWH\r\n      width = tensor.dims[3];\r\n      height = tensor.dims[2];\r\n    }\r\n\r\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\r\n\r\n    const norm = options?.norm;\r\n    let normMean: [number, number, number, number];\r\n    let normBias: [number, number, number, number];\r\n    if (norm === undefined || norm.mean === undefined) {\r\n      normMean = [255, 255, 255, 255];\r\n    } else {\r\n      if (typeof norm.mean === 'number') {\r\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n      } else {\r\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\r\n        if (norm.mean[3] !== undefined) {\r\n          normMean[3] = norm.mean[3];\r\n        }\r\n      }\r\n    }\r\n    if (norm === undefined || norm.bias === undefined) {\r\n      normBias = [0, 0, 0, 0];\r\n    } else {\r\n      if (typeof norm.bias === 'number') {\r\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n      } else {\r\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\r\n        if (norm.bias[3] !== undefined) {\r\n          normBias[3] = norm.bias[3];\r\n        }\r\n      }\r\n    }\r\n\r\n    const stride = height * width;\r\n    // Default pointer assignments\r\n    let rTensorPointer = 0,\r\n      gTensorPointer = stride,\r\n      bTensorPointer = stride * 2,\r\n      aTensorPointer = -1;\r\n\r\n    // Updating the pointer assignments based on the input image format\r\n    if (inputformat === 'RGBA') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n      aTensorPointer = stride * 3;\r\n    } else if (inputformat === 'RGB') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n    } else if (inputformat === 'RBG') {\r\n      rTensorPointer = 0;\r\n      bTensorPointer = stride;\r\n      gTensorPointer = stride * 2;\r\n    }\r\n\r\n    for (let i = 0; i < height; i++) {\r\n      for (let j = 0; j < width; j++) {\r\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\r\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\r\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\r\n        const A = aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\r\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\r\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\r\n        pixels2DContext.fillRect(j, i, 1, 1);\r\n      }\r\n    }\r\n    if ('toDataURL' in canvas) {\r\n      return canvas.toDataURL();\r\n    } else {\r\n      throw new Error('toDataURL is not supported');\r\n    }\r\n  } else {\r\n    throw new Error('Can not access image data');\r\n  }\r\n};\r\n\r\n/**\r\n * implementation of Tensor.toImageData()\r\n */\r\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\r\n  const pixels2DContext =\r\n    typeof document !== 'undefined'\r\n      ? document.createElement('canvas').getContext('2d')\r\n      : (new OffscreenCanvas(1, 1).getContext('2d') as OffscreenCanvasRenderingContext2D);\r\n  let image: ImageData;\r\n  if (pixels2DContext != null) {\r\n    // Default values for height and width & format\r\n    let width: number;\r\n    let height: number;\r\n    let channels: number;\r\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\r\n      width = tensor.dims[2];\r\n      height = tensor.dims[1];\r\n      channels = tensor.dims[3];\r\n    } else {\r\n      // Default layout is NCWH\r\n      width = tensor.dims[3];\r\n      height = tensor.dims[2];\r\n      channels = tensor.dims[1];\r\n    }\r\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\r\n\r\n    const norm = options?.norm;\r\n    let normMean: [number, number, number, number];\r\n    let normBias: [number, number, number, number];\r\n    if (norm === undefined || norm.mean === undefined) {\r\n      normMean = [255, 255, 255, 255];\r\n    } else {\r\n      if (typeof norm.mean === 'number') {\r\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n      } else {\r\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\r\n        if (norm.mean[3] !== undefined) {\r\n          normMean[3] = norm.mean[3];\r\n        }\r\n      }\r\n    }\r\n    if (norm === undefined || norm.bias === undefined) {\r\n      normBias = [0, 0, 0, 0];\r\n    } else {\r\n      if (typeof norm.bias === 'number') {\r\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n      } else {\r\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\r\n        if (norm.bias[3] !== undefined) {\r\n          normBias[3] = norm.bias[3];\r\n        }\r\n      }\r\n    }\r\n\r\n    const stride = height * width;\r\n    if (options !== undefined) {\r\n      if (\r\n        (options.format !== undefined && channels === 4 && options.format !== 'RGBA') ||\r\n        (channels === 3 && options.format !== 'RGB' && options.format !== 'BGR')\r\n      ) {\r\n        throw new Error(\"Tensor format doesn't match input tensor dims\");\r\n      }\r\n    }\r\n\r\n    // Default pointer assignments\r\n    const step = 4;\r\n    let rImagePointer = 0,\r\n      gImagePointer = 1,\r\n      bImagePointer = 2,\r\n      aImagePointer = 3;\r\n    let rTensorPointer = 0,\r\n      gTensorPointer = stride,\r\n      bTensorPointer = stride * 2,\r\n      aTensorPointer = -1;\r\n\r\n    // Updating the pointer assignments based on the input image format\r\n    if (inputformat === 'RGBA') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n      aTensorPointer = stride * 3;\r\n    } else if (inputformat === 'RGB') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n    } else if (inputformat === 'RBG') {\r\n      rTensorPointer = 0;\r\n      bTensorPointer = stride;\r\n      gTensorPointer = stride * 2;\r\n    }\r\n\r\n    image = pixels2DContext.createImageData(width, height);\r\n\r\n    for (\r\n      let i = 0;\r\n      i < height * width;\r\n      rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++\r\n    ) {\r\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\r\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\r\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\r\n      image.data[aImagePointer] =\r\n        aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\r\n    }\r\n  } else {\r\n    throw new Error('Can not access image data');\r\n  }\r\n  return image;\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  OptionsDimensions,\r\n  OptionsFormat,\r\n  OptionsNormalizationParameters,\r\n  OptionsTensorFormat,\r\n  OptionsTensorLayout,\r\n  TensorFromGpuBufferOptions,\r\n  TensorFromImageBitmapOptions,\r\n  TensorFromImageDataOptions,\r\n  TensorFromImageElementOptions,\r\n  TensorFromMLTensorOptions,\r\n  TensorFromTextureOptions,\r\n  TensorFromUrlOptions,\r\n} from './tensor-factory.js';\r\nimport { Tensor } from './tensor-impl.js';\r\nimport { Tensor as TensorInterface } from './tensor.js';\r\n\r\ninterface BufferToTensorOptions\r\n  extends OptionsDimensions,\r\n    OptionsTensorLayout,\r\n    OptionsNormalizationParameters,\r\n    OptionsFormat,\r\n    OptionsTensorFormat {}\r\n\r\n/**\r\n * Create a new tensor object from image object\r\n *\r\n * @param buffer - Extracted image buffer data - assuming RGBA format\r\n * @param imageFormat - input image configuration - required configurations height, width, format\r\n * @param tensorFormat - output tensor configuration - Default is RGB format\r\n */\r\nexport const bufferToTensor = (buffer: Uint8ClampedArray | undefined, options: BufferToTensorOptions): Tensor => {\r\n  if (buffer === undefined) {\r\n    throw new Error('Image buffer must be defined');\r\n  }\r\n  if (options.height === undefined || options.width === undefined) {\r\n    throw new Error('Image height and width must be defined');\r\n  }\r\n  if (options.tensorLayout === 'NHWC') {\r\n    throw new Error('NHWC Tensor layout is not supported yet');\r\n  }\r\n\r\n  const { height, width } = options;\r\n\r\n  const norm = options.norm ?? { mean: 255, bias: 0 };\r\n  let normMean: [number, number, number, number];\r\n  let normBias: [number, number, number, number];\r\n\r\n  if (typeof norm.mean === 'number') {\r\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n  } else {\r\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\r\n  }\r\n\r\n  if (typeof norm.bias === 'number') {\r\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n  } else {\r\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\r\n  }\r\n\r\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\r\n  // default value is RGBA since imagedata and HTMLImageElement uses it\r\n\r\n  const outputformat =\r\n    options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\r\n  const stride = height * width;\r\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\r\n\r\n  // Default pointer assignments\r\n  let step = 4,\r\n    rImagePointer = 0,\r\n    gImagePointer = 1,\r\n    bImagePointer = 2,\r\n    aImagePointer = 3;\r\n  let rTensorPointer = 0,\r\n    gTensorPointer = stride,\r\n    bTensorPointer = stride * 2,\r\n    aTensorPointer = -1;\r\n\r\n  // Updating the pointer assignments based on the input image format\r\n  if (inputformat === 'RGB') {\r\n    step = 3;\r\n    rImagePointer = 0;\r\n    gImagePointer = 1;\r\n    bImagePointer = 2;\r\n    aImagePointer = -1;\r\n  }\r\n\r\n  // Updating the pointer assignments based on the output tensor format\r\n  if (outputformat === 'RGBA') {\r\n    aTensorPointer = stride * 3;\r\n  } else if (outputformat === 'RBG') {\r\n    rTensorPointer = 0;\r\n    bTensorPointer = stride;\r\n    gTensorPointer = stride * 2;\r\n  } else if (outputformat === 'BGR') {\r\n    bTensorPointer = 0;\r\n    gTensorPointer = stride;\r\n    rTensorPointer = stride * 2;\r\n  }\r\n\r\n  for (\r\n    let i = 0;\r\n    i < stride;\r\n    i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step\r\n  ) {\r\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\r\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\r\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\r\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\r\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\r\n    }\r\n  }\r\n\r\n  // Float32Array -> ort.Tensor\r\n  const outputTensor =\r\n    outputformat === 'RGBA'\r\n      ? new Tensor('float32', float32Data, [1, 4, height, width])\r\n      : new Tensor('float32', float32Data, [1, 3, height, width]);\r\n  return outputTensor;\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromImage().\r\n */\r\nexport const tensorFromImage = async (\r\n  image: ImageData | HTMLImageElement | ImageBitmap | string,\r\n  options?:\r\n    | TensorFromImageDataOptions\r\n    | TensorFromImageElementOptions\r\n    | TensorFromImageBitmapOptions\r\n    | TensorFromUrlOptions,\r\n): Promise<Tensor> => {\r\n  // checking the type of image object\r\n  const isHTMLImageEle = typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement;\r\n  const isImageDataEle = typeof ImageData !== 'undefined' && image instanceof ImageData;\r\n  const isImageBitmap = typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap;\r\n  const isString = typeof image === 'string';\r\n\r\n  let data: Uint8ClampedArray | undefined;\r\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\r\n\r\n  const createCanvas = () => {\r\n    if (typeof document !== 'undefined') {\r\n      return document.createElement('canvas');\r\n    } else if (typeof OffscreenCanvas !== 'undefined') {\r\n      return new OffscreenCanvas(1, 1);\r\n    } else {\r\n      throw new Error('Canvas is not supported');\r\n    }\r\n  };\r\n  const createCanvasContext = (canvas: HTMLCanvasElement | OffscreenCanvas) => {\r\n    if (typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement) {\r\n      return canvas.getContext('2d');\r\n    } else if (canvas instanceof OffscreenCanvas) {\r\n      return canvas.getContext('2d') as OffscreenCanvasRenderingContext2D;\r\n    } else {\r\n      return null;\r\n    }\r\n  };\r\n  // filling and checking image configuration options\r\n  if (isHTMLImageEle) {\r\n    // HTMLImageElement - image object - format is RGBA by default\r\n    const canvas = createCanvas();\r\n    canvas.width = image.width;\r\n    canvas.height = image.height;\r\n    const pixels2DContext = createCanvasContext(canvas);\r\n\r\n    if (pixels2DContext != null) {\r\n      let height = image.height;\r\n      let width = image.width;\r\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\r\n        height = options.resizedHeight;\r\n        width = options.resizedWidth;\r\n      }\r\n\r\n      if (options !== undefined) {\r\n        bufferToTensorOptions = options;\r\n        if (options.tensorFormat !== undefined) {\r\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\r\n        } else {\r\n          bufferToTensorOptions.tensorFormat = 'RGBA';\r\n        }\r\n        bufferToTensorOptions.height = height;\r\n        bufferToTensorOptions.width = width;\r\n      } else {\r\n        bufferToTensorOptions.tensorFormat = 'RGBA';\r\n        bufferToTensorOptions.height = height;\r\n        bufferToTensorOptions.width = width;\r\n      }\r\n\r\n      pixels2DContext.drawImage(image, 0, 0);\r\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n    } else {\r\n      throw new Error('Can not access image data');\r\n    }\r\n  } else if (isImageDataEle) {\r\n    let height: number;\r\n    let width: number;\r\n\r\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\r\n      height = options.resizedHeight;\r\n      width = options.resizedWidth;\r\n    } else {\r\n      height = image.height;\r\n      width = image.width;\r\n    }\r\n\r\n    if (options !== undefined) {\r\n      bufferToTensorOptions = options;\r\n    }\r\n    bufferToTensorOptions.format = 'RGBA';\r\n    bufferToTensorOptions.height = height;\r\n    bufferToTensorOptions.width = width;\r\n\r\n    if (options !== undefined) {\r\n      const tempCanvas = createCanvas();\r\n\r\n      tempCanvas.width = width;\r\n      tempCanvas.height = height;\r\n\r\n      const pixels2DContext = createCanvasContext(tempCanvas);\r\n\r\n      if (pixels2DContext != null) {\r\n        pixels2DContext.putImageData(image, 0, 0);\r\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n      } else {\r\n        throw new Error('Can not access image data');\r\n      }\r\n    } else {\r\n      data = image.data;\r\n    }\r\n  } else if (isImageBitmap) {\r\n    // ImageBitmap - image object - format must be provided by user\r\n    if (options === undefined) {\r\n      throw new Error('Please provide image config with format for Imagebitmap');\r\n    }\r\n\r\n    const canvas = createCanvas();\r\n    canvas.width = image.width;\r\n    canvas.height = image.height;\r\n    const pixels2DContext = createCanvasContext(canvas);\r\n\r\n    if (pixels2DContext != null) {\r\n      const height = image.height;\r\n      const width = image.width;\r\n      pixels2DContext.drawImage(image, 0, 0, width, height);\r\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n      bufferToTensorOptions.height = height;\r\n      bufferToTensorOptions.width = width;\r\n      return bufferToTensor(data, bufferToTensorOptions);\r\n    } else {\r\n      throw new Error('Can not access image data');\r\n    }\r\n  } else if (isString) {\r\n    return new Promise((resolve, reject) => {\r\n      const canvas = createCanvas();\r\n      const context = createCanvasContext(canvas);\r\n      if (!image || !context) {\r\n        return reject();\r\n      }\r\n      const newImage = new Image();\r\n      newImage.crossOrigin = 'Anonymous';\r\n      newImage.src = image;\r\n      newImage.onload = () => {\r\n        canvas.width = newImage.width;\r\n        canvas.height = newImage.height;\r\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\r\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\r\n\r\n        bufferToTensorOptions.height = canvas.height;\r\n        bufferToTensorOptions.width = canvas.width;\r\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\r\n      };\r\n    });\r\n  } else {\r\n    throw new Error('Input data provided is not supported - aborted tensor creation');\r\n  }\r\n\r\n  if (data !== undefined) {\r\n    return bufferToTensor(data, bufferToTensorOptions);\r\n  } else {\r\n    throw new Error('Input data provided is not supported - aborted tensor creation');\r\n  }\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromTexture().\r\n */\r\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\r\n  texture: TensorInterface.TextureType,\r\n  options: TensorFromTextureOptions<T>,\r\n): Tensor => {\r\n  const { width, height, download, dispose } = options;\r\n  // Always assume RGBAF32. TODO: support different texture format\r\n  const dims = [1, height, width, 4];\r\n  return new Tensor({ location: 'texture', type: 'float32', texture, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromGpuBuffer().\r\n */\r\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\r\n  gpuBuffer: TensorInterface.GpuBufferType,\r\n  options: TensorFromGpuBufferOptions<T>,\r\n): Tensor => {\r\n  const { dataType, dims, download, dispose } = options;\r\n  return new Tensor({ location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromMLTensor().\r\n */\r\nexport const tensorFromMLTensor = <T extends TensorInterface.MLTensorDataTypes>(\r\n  mlTensor: TensorInterface.MLTensorType,\r\n  options: TensorFromMLTensorOptions<T>,\r\n): Tensor => {\r\n  const { dataType, dims, download, dispose } = options;\r\n  return new Tensor({ location: 'ml-tensor', type: dataType ?? 'float32', mlTensor, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromPinnedBuffer().\r\n */\r\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\r\n  type: T,\r\n  buffer: TensorInterface.DataTypeMap[T],\r\n  dims?: readonly number[],\r\n): Tensor => new Tensor({ location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length] });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from './tensor.js';\r\n\r\nexport type SupportedTypedArrayConstructors =\r\n  | Float32ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Int8ArrayConstructor\r\n  | Uint16ArrayConstructor\r\n  | Int16ArrayConstructor\r\n  | Int32ArrayConstructor\r\n  | BigInt64ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Float64ArrayConstructor\r\n  | Uint32ArrayConstructor\r\n  | BigUint64ArrayConstructor;\r\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\r\n  ['float32', Float32Array],\r\n  ['uint8', Uint8Array],\r\n  ['int8', Int8Array],\r\n  ['uint16', Uint16Array],\r\n  ['int16', Int16Array],\r\n  ['int32', Int32Array],\r\n  ['bool', Uint8Array],\r\n  ['float64', Float64Array],\r\n  ['uint32', Uint32Array],\r\n  ['int4', Uint8Array],\r\n  ['uint4', Uint8Array],\r\n]);\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\r\n  [Float32Array, 'float32'],\r\n  [Uint8Array, 'uint8'],\r\n  [Int8Array, 'int8'],\r\n  [Uint16Array, 'uint16'],\r\n  [Int16Array, 'int16'],\r\n  [Int32Array, 'int32'],\r\n  [Float64Array, 'float64'],\r\n  [Uint32Array, 'uint32'],\r\n]);\r\n\r\n// the following code allows delaying execution of BigInt/Float16Array checking. This allows lazy initialization for\r\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt/Float16Array\r\n// polyfill if available.\r\nlet isTypedArrayChecked = false;\r\nexport const checkTypedArray = () => {\r\n  if (!isTypedArrayChecked) {\r\n    isTypedArrayChecked = true;\r\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && BigInt64Array.from;\r\n    const isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && BigUint64Array.from;\r\n\r\n    // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\r\n    const Float16Array = (globalThis as any).Float16Array;\r\n    const isFloat16ArrayAvailable = typeof Float16Array !== 'undefined' && Float16Array.from;\r\n\r\n    if (isBigInt64ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\r\n    }\r\n    if (isBigUint64ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\r\n    }\r\n    if (isFloat16ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Float16Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(Float16Array, 'float16');\r\n    } else {\r\n      // if Float16Array is not available, use 'Uint16Array' to store the data.\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Uint16Array);\r\n    }\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  CpuPinnedConstructorParameters,\r\n  GpuBufferConstructorParameters,\r\n  MLTensorConstructorParameters,\r\n  TextureConstructorParameters,\r\n} from './tensor-factory.js';\r\nimport { Tensor } from './tensor-impl.js';\r\n\r\n/**\r\n * calculate size from dims.\r\n *\r\n * @param dims the dims array. May be an illegal input.\r\n */\r\nexport const calculateSize = (dims: readonly unknown[]): number => {\r\n  let size = 1;\r\n  for (let i = 0; i < dims.length; i++) {\r\n    const dim = dims[i];\r\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\r\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\r\n    }\r\n    if (dim < 0) {\r\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\r\n    }\r\n    size *= dim;\r\n  }\r\n  return size;\r\n};\r\n\r\n/**\r\n * implementation of Tensor.reshape()\r\n */\r\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\r\n  switch (tensor.location) {\r\n    case 'cpu':\r\n      return new Tensor(tensor.type, tensor.data, dims);\r\n    case 'cpu-pinned':\r\n      return new Tensor({\r\n        location: 'cpu-pinned',\r\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\r\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'texture':\r\n      return new Tensor({\r\n        location: 'texture',\r\n        texture: tensor.texture,\r\n        type: tensor.type as TextureConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'gpu-buffer':\r\n      return new Tensor({\r\n        location: 'gpu-buffer',\r\n        gpuBuffer: tensor.gpuBuffer,\r\n        type: tensor.type as GpuBufferConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'ml-tensor':\r\n      return new Tensor({\r\n        location: 'ml-tensor',\r\n        mlTensor: tensor.mlTensor,\r\n        type: tensor.type as MLTensorConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    default:\r\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { tensorToDataURL, tensorToImageData } from './tensor-conversion-impl.js';\r\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\r\nimport {\r\n  tensorFromGpuBuffer,\r\n  tensorFromImage,\r\n  tensorFromMLTensor,\r\n  tensorFromPinnedBuffer,\r\n  tensorFromTexture,\r\n} from './tensor-factory-impl.js';\r\nimport {\r\n  CpuPinnedConstructorParameters,\r\n  GpuBufferConstructorParameters,\r\n  MLTensorConstructorParameters,\r\n  TensorFromGpuBufferOptions,\r\n  TensorFromImageBitmapOptions,\r\n  TensorFromImageDataOptions,\r\n  TensorFromImageElementOptions,\r\n  TensorFromMLTensorOptions,\r\n  TensorFromTextureOptions,\r\n  TensorFromUrlOptions,\r\n  TextureConstructorParameters,\r\n} from './tensor-factory.js';\r\nimport {\r\n  checkTypedArray,\r\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP,\r\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP,\r\n  SupportedTypedArray,\r\n  SupportedTypedArrayConstructors,\r\n} from './tensor-impl-type-mapping.js';\r\nimport { calculateSize, tensorReshape } from './tensor-utils-impl.js';\r\nimport { Tensor as TensorInterface } from './tensor.js';\r\n\r\n// type aliases for those exported from Tensor interface\r\n\r\ntype TensorType = TensorInterface.Type;\r\ntype TensorDataType = TensorInterface.DataType;\r\ntype TensorDataLocation = TensorInterface.DataLocation;\r\ntype TensorTextureType = TensorInterface.TextureType;\r\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\r\ntype TensorMLTensorType = TensorInterface.MLTensorType;\r\n\r\n/**\r\n * the implementation of Tensor interface.\r\n *\r\n * @ignore\r\n */\r\nexport class Tensor implements TensorInterface {\r\n  // #region constructors\r\n\r\n  /**\r\n   * Construct a new CPU tensor object from the given type, data and dims.\r\n   */\r\n  constructor(\r\n    type: TensorType,\r\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly number[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  );\r\n  /**\r\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\r\n   */\r\n  constructor(\r\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  );\r\n  /**\r\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'cpu-pinned'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: CpuPinnedConstructorParameters);\r\n  /**\r\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'texture'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: TextureConstructorParameters);\r\n  /**\r\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'gpu-buffer'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: GpuBufferConstructorParameters);\r\n\r\n  /**\r\n   * Construct a new tensor object from the WebNN MLTensor with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'ml-tensor'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: MLTensorConstructorParameters);\r\n\r\n  /**\r\n   * implementation.\r\n   */\r\n  constructor(\r\n    arg0:\r\n      | TensorType\r\n      | TensorDataType\r\n      | Uint8ClampedArray\r\n      | readonly string[]\r\n      | readonly boolean[]\r\n      | CpuPinnedConstructorParameters\r\n      | TextureConstructorParameters\r\n      | GpuBufferConstructorParameters\r\n      | MLTensorConstructorParameters,\r\n    arg1?: TensorDataType | Uint8ClampedArray | readonly number[] | readonly string[] | readonly boolean[],\r\n    arg2?: readonly number[],\r\n  ) {\r\n    // perform one-time check for BigInt/Float16Array support\r\n    checkTypedArray();\r\n\r\n    let type: TensorType;\r\n    let dims: readonly number[];\r\n\r\n    if (typeof arg0 === 'object' && 'location' in arg0) {\r\n      //\r\n      // constructing tensor from specific location\r\n      //\r\n      this.dataLocation = arg0.location;\r\n      type = arg0.type;\r\n      dims = arg0.dims;\r\n      switch (arg0.location) {\r\n        case 'cpu-pinned': {\r\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\r\n          if (!expectedTypedArrayConstructor) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\r\n          }\r\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\r\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\r\n          }\r\n          this.cpuData = arg0.data;\r\n          break;\r\n        }\r\n        case 'texture': {\r\n          if (type !== 'float32') {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\r\n          }\r\n          this.gpuTextureData = arg0.texture;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        case 'gpu-buffer': {\r\n          if (\r\n            type !== 'float32' &&\r\n            type !== 'float16' &&\r\n            type !== 'int32' &&\r\n            type !== 'int64' &&\r\n            type !== 'uint32' &&\r\n            type !== 'uint8' &&\r\n            type !== 'bool' &&\r\n            type !== 'uint4' &&\r\n            type !== 'int4'\r\n          ) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\r\n          }\r\n          this.gpuBufferData = arg0.gpuBuffer;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        case 'ml-tensor': {\r\n          if (\r\n            type !== 'float32' &&\r\n            type !== 'float16' &&\r\n            type !== 'int32' &&\r\n            type !== 'int64' &&\r\n            type !== 'uint32' &&\r\n            type !== 'uint64' &&\r\n            type !== 'int8' &&\r\n            type !== 'uint8' &&\r\n            type !== 'bool' &&\r\n            type !== 'uint4' &&\r\n            type !== 'int4'\r\n          ) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from MLTensor`);\r\n          }\r\n          this.mlTensorData = arg0.mlTensor;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        default:\r\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\r\n      }\r\n    } else {\r\n      //\r\n      // constructing tensor of location 'cpu'\r\n      //\r\n      let data: TensorDataType;\r\n      let maybeDims: typeof arg1 | typeof arg2;\r\n      // check whether arg0 is type or data\r\n      if (typeof arg0 === 'string') {\r\n        //\r\n        // Override: constructor(type, data, ...)\r\n        //\r\n        type = arg0;\r\n        maybeDims = arg2;\r\n        if (arg0 === 'string') {\r\n          // string tensor\r\n          if (!Array.isArray(arg1)) {\r\n            throw new TypeError(\"A string tensor's data must be a string array.\");\r\n          }\r\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\r\n          // error will be populated at inference\r\n          data = arg1;\r\n        } else {\r\n          // numeric tensor\r\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\r\n          if (typedArrayConstructor === undefined) {\r\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\r\n          }\r\n          if (Array.isArray(arg1)) {\r\n            if ((arg0 === 'float16' && typedArrayConstructor === Uint16Array) || arg0 === 'uint4' || arg0 === 'int4') {\r\n              // - 'float16':\r\n              //   When no Float16Array polyfill is used, we cannot create 'float16' tensor from number array.\r\n              //\r\n              //   Throw error here because when user try to use number array as data,\r\n              //   e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\r\n              //   Uint16Array.from(arg1) which generates wrong data.\r\n              //\r\n              // - 'uint4' and 'int4':\r\n              //   Uint8Array.from(arg1) will generate wrong data for 'uint4' and 'int4' tensor.\r\n              //\r\n              throw new TypeError(\r\n                `Creating a ${arg0} tensor from number array is not supported. Please use ${typedArrayConstructor.name} as data.`,\r\n              );\r\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\r\n              // use 'as any' here because:\r\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\r\n              // see https://github.com/microsoft/TypeScript/issues/17002\r\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\r\n              // does not accept parameter mapFn.\r\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\r\n              // type.\r\n\r\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\r\n\r\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\r\n            } else {\r\n              // assume 'arg1' is of type \"readonly number[]\" here.\r\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n              data = (typedArrayConstructor as any).from(arg1);\r\n            }\r\n          } else if (arg1 instanceof typedArrayConstructor) {\r\n            data = arg1;\r\n          } else if (arg1 instanceof Uint8ClampedArray) {\r\n            if (arg0 === 'uint8') {\r\n              data = Uint8Array.from(arg1);\r\n            } else {\r\n              throw new TypeError(`A Uint8ClampedArray tensor's data must be type of uint8`);\r\n            }\r\n          } else if (arg0 === 'float16' && arg1 instanceof Uint16Array && typedArrayConstructor !== Uint16Array) {\r\n            // when Float16Array is available and data is of type Uint16Array.\r\n            // We allow Uint16Array to be passed in as data for 'float16' tensor until Float16Array is generally\r\n            // supported in JavaScript environment.\r\n\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n            data = new (globalThis as any).Float16Array(arg1.buffer, arg1.byteOffset, arg1.length);\r\n          } else {\r\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\r\n          }\r\n        }\r\n      } else {\r\n        //\r\n        // Override: constructor(data, ...)\r\n        //\r\n        maybeDims = arg1;\r\n        if (Array.isArray(arg0)) {\r\n          // only boolean[] and string[] is supported\r\n          if (arg0.length === 0) {\r\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\r\n          }\r\n          const firstElementType = typeof arg0[0];\r\n          if (firstElementType === 'string') {\r\n            type = 'string';\r\n            data = arg0;\r\n          } else if (firstElementType === 'boolean') {\r\n            type = 'bool';\r\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\r\n            // wrong type. We use 'as any' to make it happy.\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n            data = Uint8Array.from(arg0 as any[]);\r\n          } else {\r\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\r\n          }\r\n        } else if (arg0 instanceof Uint8ClampedArray) {\r\n          type = 'uint8';\r\n          data = Uint8Array.from(arg0);\r\n        } else {\r\n          // get tensor type from TypedArray\r\n          const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(\r\n            arg0.constructor as SupportedTypedArrayConstructors,\r\n          );\r\n          if (mappedType === undefined) {\r\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\r\n          }\r\n          type = mappedType;\r\n          data = arg0 as SupportedTypedArray;\r\n        }\r\n      }\r\n\r\n      // type and data is processed, now processing dims\r\n      if (maybeDims === undefined) {\r\n        // assume 1-D tensor if dims omitted\r\n        maybeDims = [data.length];\r\n      } else if (!Array.isArray(maybeDims)) {\r\n        throw new TypeError(\"A tensor's dims must be a number array\");\r\n      }\r\n      dims = maybeDims as readonly number[];\r\n\r\n      this.cpuData = data;\r\n      this.dataLocation = 'cpu';\r\n    }\r\n\r\n    // perform check on dims\r\n    const size = calculateSize(dims);\r\n    // if data is on CPU, check whether data length matches tensor size\r\n    if (this.cpuData && size !== this.cpuData.length) {\r\n      if ((type === 'uint4' || type === 'int4') && Math.ceil(size / 2) === this.cpuData.length) {\r\n        // for (u)int4, the data length is half of the tensor size. So we check this special case when size is odd.\r\n      } else {\r\n        throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\r\n      }\r\n    }\r\n\r\n    this.type = type;\r\n    this.dims = dims;\r\n    this.size = size;\r\n  }\r\n  // #endregion\r\n\r\n  // #region factory\r\n  static async fromImage(\r\n    image: ImageData | HTMLImageElement | ImageBitmap | string,\r\n    options?:\r\n      | TensorFromImageDataOptions\r\n      | TensorFromImageElementOptions\r\n      | TensorFromImageBitmapOptions\r\n      | TensorFromUrlOptions,\r\n  ): Promise<TensorInterface> {\r\n    return tensorFromImage(image, options);\r\n  }\r\n\r\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\r\n    texture: TensorTextureType,\r\n    options: TensorFromTextureOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromTexture(texture, options);\r\n  }\r\n\r\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\r\n    gpuBuffer: TensorGpuBufferType,\r\n    options: TensorFromGpuBufferOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromGpuBuffer(gpuBuffer, options);\r\n  }\r\n\r\n  static fromMLTensor<T extends TensorInterface.MLTensorDataTypes>(\r\n    mlTensor: TensorMLTensorType,\r\n    options: TensorFromMLTensorOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromMLTensor(mlTensor, options);\r\n  }\r\n\r\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\r\n    type: T,\r\n    buffer: TensorInterface.DataTypeMap[T],\r\n    dims?: readonly number[],\r\n  ): Tensor {\r\n    return tensorFromPinnedBuffer(type, buffer, dims);\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region conversions\r\n  toDataURL(options?: TensorToDataUrlOptions): string {\r\n    return tensorToDataURL(this, options);\r\n  }\r\n\r\n  toImageData(options?: TensorToImageDataOptions): ImageData {\r\n    return tensorToImageData(this, options);\r\n  }\r\n  // #endregion\r\n\r\n  // #region public fields\r\n  readonly dims: readonly number[];\r\n  readonly type: TensorType;\r\n  readonly size: number;\r\n  // #endregion\r\n\r\n  // #region private fields\r\n\r\n  /**\r\n   * stores the location of the data.\r\n   */\r\n  private dataLocation: TensorDataLocation;\r\n\r\n  /**\r\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\r\n   */\r\n  private cpuData?: TensorDataType;\r\n\r\n  /**\r\n   * stores the underlying texture when location is 'texture'. otherwise empty.\r\n   */\r\n  private gpuTextureData?: TensorTextureType;\r\n\r\n  /**\r\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\r\n   */\r\n  private gpuBufferData?: TensorGpuBufferType;\r\n\r\n  /**\r\n   * stores the underlying WebNN MLTensor when location is 'ml-tensor'. otherwise empty.\r\n   */\r\n  private mlTensorData?: TensorMLTensorType;\r\n\r\n  /**\r\n   * stores an optional downloader function to download data from GPU to CPU.\r\n   */\r\n  private downloader?(): Promise<TensorDataType>;\r\n\r\n  /**\r\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\r\n   */\r\n  private isDownloading?: boolean;\r\n\r\n  /**\r\n   * stores an optional disposer function to dispose the underlying data.\r\n   */\r\n  private disposer?(): void;\r\n  // #endregion\r\n\r\n  // #region properties\r\n  get data(): TensorDataType {\r\n    this.ensureValid();\r\n    if (!this.cpuData) {\r\n      throw new Error(\r\n        'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\r\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.',\r\n      );\r\n    }\r\n    return this.cpuData;\r\n  }\r\n\r\n  get location(): TensorDataLocation {\r\n    return this.dataLocation;\r\n  }\r\n\r\n  get texture(): TensorTextureType {\r\n    this.ensureValid();\r\n    if (!this.gpuTextureData) {\r\n      throw new Error('The data is not stored as a WebGL texture.');\r\n    }\r\n    return this.gpuTextureData;\r\n  }\r\n\r\n  get gpuBuffer(): TensorGpuBufferType {\r\n    this.ensureValid();\r\n    if (!this.gpuBufferData) {\r\n      throw new Error('The data is not stored as a WebGPU buffer.');\r\n    }\r\n    return this.gpuBufferData;\r\n  }\r\n\r\n  get mlTensor(): TensorMLTensorType {\r\n    this.ensureValid();\r\n    if (!this.mlTensorData) {\r\n      throw new Error('The data is not stored as a WebNN MLTensor.');\r\n    }\r\n    return this.mlTensorData;\r\n  }\r\n  // #endregion\r\n\r\n  // #region methods\r\n\r\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\r\n    this.ensureValid();\r\n    switch (this.dataLocation) {\r\n      case 'cpu':\r\n      case 'cpu-pinned':\r\n        return this.data;\r\n      case 'texture':\r\n      case 'gpu-buffer':\r\n      case 'ml-tensor': {\r\n        if (!this.downloader) {\r\n          throw new Error('The current tensor is not created with a specified data downloader.');\r\n        }\r\n        if (this.isDownloading) {\r\n          throw new Error('The current tensor is being downloaded.');\r\n        }\r\n        try {\r\n          this.isDownloading = true;\r\n          const data = await this.downloader();\r\n          this.downloader = undefined;\r\n          this.dataLocation = 'cpu';\r\n          this.cpuData = data;\r\n\r\n          if (releaseData && this.disposer) {\r\n            this.disposer();\r\n            this.disposer = undefined;\r\n          }\r\n\r\n          return data;\r\n        } finally {\r\n          this.isDownloading = false;\r\n        }\r\n      }\r\n      default:\r\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\r\n    }\r\n  }\r\n\r\n  dispose(): void {\r\n    if (this.isDownloading) {\r\n      throw new Error('The current tensor is being downloaded.');\r\n    }\r\n\r\n    if (this.disposer) {\r\n      this.disposer();\r\n      this.disposer = undefined;\r\n    }\r\n    this.cpuData = undefined;\r\n    this.gpuTextureData = undefined;\r\n    this.gpuBufferData = undefined;\r\n    this.mlTensorData = undefined;\r\n    this.downloader = undefined;\r\n    this.isDownloading = undefined;\r\n\r\n    this.dataLocation = 'none';\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region tensor utilities\r\n  private ensureValid(): void {\r\n    if (this.dataLocation === 'none') {\r\n      throw new Error('The tensor is disposed.');\r\n    }\r\n  }\r\n\r\n  reshape(dims: readonly number[]): TensorInterface {\r\n    this.ensureValid();\r\n    if (this.downloader || this.disposer) {\r\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\r\n    }\r\n    return tensorReshape(this, dims);\r\n  }\r\n  // #endregion\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { TensorFactory } from './tensor-factory.js';\r\nimport { Tensor as TensorImpl } from './tensor-impl.js';\r\nimport { TypedTensorUtils } from './tensor-utils.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\n/**\r\n * represent a basic tensor with specified dimensions and data type.\r\n */\r\ninterface TypedTensorBase<T extends Tensor.Type> {\r\n  /**\r\n   * Get the dimensions of the tensor.\r\n   */\r\n  readonly dims: readonly number[];\r\n  /**\r\n   * Get the data type of the tensor.\r\n   */\r\n  readonly type: T;\r\n  /**\r\n   * Get the buffer data of the tensor.\r\n   *\r\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\r\n   */\r\n  readonly data: Tensor.DataTypeMap[T];\r\n  /**\r\n   * Get the location of the data.\r\n   */\r\n  readonly location: Tensor.DataLocation;\r\n  /**\r\n   * Get the WebGL texture that holds the tensor data.\r\n   *\r\n   * If the data is not on GPU as WebGL texture, throw error.\r\n   */\r\n  readonly texture: Tensor.TextureType;\r\n  /**\r\n   * Get the WebGPU buffer that holds the tensor data.\r\n   *\r\n   * If the data is not on GPU as WebGPU buffer, throw error.\r\n   */\r\n  readonly gpuBuffer: Tensor.GpuBufferType;\r\n\r\n  /**\r\n   * Get the WebNN MLTensor that holds the tensor data.\r\n   *\r\n   * If the data is not in a WebNN MLTensor, throw error.\r\n   */\r\n  readonly mlTensor: Tensor.MLTensorType;\r\n\r\n  /**\r\n   * Get the buffer data of the tensor.\r\n   *\r\n   * If the data is on CPU, returns the data immediately.\r\n   * If the data is on GPU, downloads the data and returns the promise.\r\n   *\r\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\r\n   */\r\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\r\n\r\n  /**\r\n   * Dispose the tensor data.\r\n   *\r\n   * If the data is on CPU, remove its internal reference to the underlying data.\r\n   * If the data is on GPU, release the data on GPU.\r\n   *\r\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\r\n   */\r\n  dispose(): void;\r\n}\r\n\r\nexport declare namespace Tensor {\r\n  interface DataTypeMap {\r\n    float32: Float32Array;\r\n    uint8: Uint8Array;\r\n    int8: Int8Array;\r\n    uint16: Uint16Array;\r\n    int16: Int16Array;\r\n    int32: Int32Array;\r\n    int64: BigInt64Array;\r\n    string: string[];\r\n    bool: Uint8Array;\r\n    float16: Uint16Array; // Keep using Uint16Array until we have a concrete solution for float 16.\r\n    float64: Float64Array;\r\n    uint32: Uint32Array;\r\n    uint64: BigUint64Array;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n    uint4: Uint8Array;\r\n    int4: Int8Array;\r\n  }\r\n\r\n  interface ElementTypeMap {\r\n    float32: number;\r\n    uint8: number;\r\n    int8: number;\r\n    uint16: number;\r\n    int16: number;\r\n    int32: number;\r\n    int64: bigint;\r\n    string: string;\r\n    bool: boolean;\r\n    float16: number; // Keep using Uint16Array until we have a concrete solution for float 16.\r\n    float64: number;\r\n    uint32: number;\r\n    uint64: bigint;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n    uint4: number;\r\n    int4: number;\r\n  }\r\n\r\n  type DataType = DataTypeMap[Type];\r\n  type ElementType = ElementTypeMap[Type];\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a pinned CPU buffer\r\n   */\r\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\r\n\r\n  /**\r\n   * type alias for WebGL texture\r\n   */\r\n  export type TextureType = WebGLTexture;\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebGL texture\r\n   */\r\n  export type TextureDataTypes = 'float32';\r\n\r\n  type GpuBufferTypeFallback = { size: number; mapState: 'unmapped' | 'pending' | 'mapped' };\r\n  /**\r\n   * type alias for WebGPU buffer\r\n   */\r\n  export type GpuBufferType = TryGetGlobalType<'GPUBuffer', GpuBufferTypeFallback>;\r\n\r\n  type MLTensorTypeFallback = { destroy(): void };\r\n  /**\r\n   * type alias for WebNN MLTensor\r\n   *\r\n   * The specification for WebNN's MLTensor is currently in flux.\r\n   */\r\n  export type MLTensorType = TryGetGlobalType<'MLTensor', MLTensorTypeFallback>;\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebGPU buffer\r\n   */\r\n  export type GpuBufferDataTypes = 'float32' | 'float16' | 'int32' | 'int64' | 'uint32' | 'uint8' | 'bool';\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebNN MLTensor\r\n   */\r\n  export type MLTensorDataTypes =\r\n    | 'float32'\r\n    | 'float16'\r\n    | 'int8'\r\n    | 'uint8'\r\n    | 'int32'\r\n    | 'uint32'\r\n    | 'int64'\r\n    | 'uint64'\r\n    | 'bool'\r\n    | 'uint4'\r\n    | 'int4';\r\n\r\n  /**\r\n   * represent where the tensor data is stored\r\n   */\r\n  export type DataLocation = 'none' | 'cpu' | 'cpu-pinned' | 'texture' | 'gpu-buffer' | 'ml-tensor';\r\n\r\n  /**\r\n   * represent the data type of a tensor\r\n   */\r\n  export type Type = keyof DataTypeMap;\r\n}\r\n\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\r\n\r\n/**\r\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\r\n */\r\nexport interface TensorConstructor extends TensorFactory {\r\n  // #region CPU tensor - specify element type\r\n  /**\r\n   * Construct a new string tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: 'string',\r\n    data: Tensor.DataTypeMap['string'] | readonly string[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: 'bool',\r\n    data: Tensor.DataTypeMap['bool'] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from a Uint8ClampedArray, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (type: 'uint8', data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new <T extends 'uint64' | 'int64'>(\r\n    type: T,\r\n    data: Tensor.DataTypeMap[T] | readonly bigint[] | readonly number[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * Construct a new numeric tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new <T extends Exclude<Tensor.Type, 'string' | 'bool' | 'uint64' | 'int64'>>(\r\n    type: T,\r\n    data: Tensor.DataTypeMap[T] | readonly number[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n  // #endregion\r\n\r\n  // #region CPU tensor - infer element types\r\n\r\n  /**\r\n   * Construct a new float32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\r\n\r\n  /**\r\n   * Construct a new int8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new uint16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\r\n\r\n  /**\r\n   * Construct a new int16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\r\n\r\n  /**\r\n   * Construct a new int32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\r\n\r\n  /**\r\n   * Construct a new int64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\r\n\r\n  /**\r\n   * Construct a new string tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new float64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\r\n\r\n  /**\r\n   * Construct a new uint32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\r\n\r\n  /**\r\n   * Construct a new uint64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\r\n\r\n  // #endregion\r\n\r\n  // #region CPU tensor - fall back to non-generic tensor type declaration\r\n\r\n  /**\r\n   * Construct a new tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: Tensor.Type,\r\n    data: Tensor.DataType | readonly number[] | readonly string[] | readonly bigint[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  ): Tensor;\r\n\r\n  /**\r\n   * Construct a new tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Tensor.DataType, dims?: readonly number[]): Tensor;\r\n  // #endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const Tensor = TensorImpl as TensorConstructor;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env } from './env-impl.js';\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE = (deviceType: string, label: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.timeStamp(`${deviceType}::ORT::${label}`);\r\n};\r\n\r\nconst TRACE_FUNC = (msg: string, extraMsg?: string) => {\r\n  const stack = new Error().stack?.split(/\\r\\n|\\r|\\n/g) || [];\r\n  let hasTraceFunc = false;\r\n  for (let i = 0; i < stack.length; i++) {\r\n    if (hasTraceFunc && !stack[i].includes('TRACE_FUNC')) {\r\n      let label = `FUNC_${msg}::${stack[i].trim().split(' ')[1]}`;\r\n      if (extraMsg) {\r\n        label += `::${extraMsg}`;\r\n      }\r\n      TRACE('CPU', label);\r\n      return;\r\n    }\r\n    if (stack[i].includes('TRACE_FUNC')) {\r\n      hasTraceFunc = true;\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_FUNC_BEGIN = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  TRACE_FUNC('BEGIN', extraMsg);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_FUNC_END = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  TRACE_FUNC('END', extraMsg);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_EVENT_BEGIN = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.time(`ORT::${extraMsg}`);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_EVENT_END = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.timeEnd(`ORT::${extraMsg}`);\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { resolveBackendAndExecutionProviders } from './backend-impl.js';\r\nimport { InferenceSessionHandler } from './backend.js';\r\nimport { InferenceSession as InferenceSessionInterface } from './inference-session.js';\r\nimport { OnnxValue } from './onnx-value.js';\r\nimport { Tensor } from './tensor.js';\r\nimport { TRACE_FUNC_BEGIN, TRACE_FUNC_END, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from './trace.js';\r\n\r\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\r\ntype RunOptions = InferenceSessionInterface.RunOptions;\r\ntype FeedsType = InferenceSessionInterface.FeedsType;\r\ntype FetchesType = InferenceSessionInterface.FetchesType;\r\ntype ReturnType = InferenceSessionInterface.ReturnType;\r\n\r\nexport class InferenceSession implements InferenceSessionInterface {\r\n  private constructor(handler: InferenceSessionHandler) {\r\n    this.handler = handler;\r\n  }\r\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\r\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\r\n  async run(feeds: FeedsType, arg1?: FetchesType | RunOptions, arg2?: RunOptions): Promise<ReturnType> {\r\n    TRACE_FUNC_BEGIN();\r\n    TRACE_EVENT_BEGIN('InferenceSession.run');\r\n    const fetches: { [name: string]: OnnxValue | null } = {};\r\n    let options: RunOptions = {};\r\n    // check inputs\r\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\r\n      throw new TypeError(\r\n        \"'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.\",\r\n      );\r\n    }\r\n\r\n    let isFetchesEmpty = true;\r\n    // determine which override is being used\r\n    if (typeof arg1 === 'object') {\r\n      if (arg1 === null) {\r\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\r\n      }\r\n      if (arg1 instanceof Tensor) {\r\n        throw new TypeError(\"'fetches' cannot be a Tensor\");\r\n      }\r\n\r\n      if (Array.isArray(arg1)) {\r\n        if (arg1.length === 0) {\r\n          throw new TypeError(\"'fetches' cannot be an empty array.\");\r\n        }\r\n        isFetchesEmpty = false;\r\n        // output names\r\n        for (const name of arg1) {\r\n          if (typeof name !== 'string') {\r\n            throw new TypeError(\"'fetches' must be a string array or an object.\");\r\n          }\r\n          if (this.outputNames.indexOf(name) === -1) {\r\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\r\n          }\r\n          fetches[name] = null;\r\n        }\r\n\r\n        if (typeof arg2 === 'object' && arg2 !== null) {\r\n          options = arg2;\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError(\"'options' must be an object.\");\r\n        }\r\n      } else {\r\n        // decide whether arg1 is fetches or options\r\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\r\n        let isFetches = false;\r\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\r\n        for (const name of this.outputNames) {\r\n          if (arg1Keys.indexOf(name) !== -1) {\r\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\r\n            if (v === null || v instanceof Tensor) {\r\n              isFetches = true;\r\n              isFetchesEmpty = false;\r\n              fetches[name] = v;\r\n            }\r\n          }\r\n        }\r\n\r\n        if (isFetches) {\r\n          if (typeof arg2 === 'object' && arg2 !== null) {\r\n            options = arg2;\r\n          } else if (typeof arg2 !== 'undefined') {\r\n            throw new TypeError(\"'options' must be an object.\");\r\n          }\r\n        } else {\r\n          options = arg1 as RunOptions;\r\n        }\r\n      }\r\n    } else if (typeof arg1 !== 'undefined') {\r\n      throw new TypeError(\"Unexpected argument[1]: must be 'fetches' or 'options'.\");\r\n    }\r\n\r\n    // check if all inputs are in feed\r\n    for (const name of this.inputNames) {\r\n      if (typeof feeds[name] === 'undefined') {\r\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\r\n      }\r\n    }\r\n\r\n    // if no fetches is specified, we use the full output names list\r\n    if (isFetchesEmpty) {\r\n      for (const name of this.outputNames) {\r\n        fetches[name] = null;\r\n      }\r\n    }\r\n\r\n    // feeds, fetches and options are prepared\r\n\r\n    const results = await this.handler.run(feeds, fetches, options);\r\n    const returnValue: { [name: string]: OnnxValue } = {};\r\n    for (const key in results) {\r\n      if (Object.hasOwnProperty.call(results, key)) {\r\n        const result = results[key];\r\n        if (result instanceof Tensor) {\r\n          returnValue[key] = result;\r\n        } else {\r\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\r\n        }\r\n      }\r\n    }\r\n    TRACE_EVENT_END('InferenceSession.run');\r\n    TRACE_FUNC_END();\r\n    return returnValue;\r\n  }\r\n\r\n  async release(): Promise<void> {\r\n    return this.handler.dispose();\r\n  }\r\n\r\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(\r\n    buffer: ArrayBufferLike,\r\n    byteOffset: number,\r\n    byteLength?: number,\r\n    options?: SessionOptions,\r\n  ): Promise<InferenceSessionInterface>;\r\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static async create(\r\n    arg0: string | ArrayBufferLike | Uint8Array,\r\n    arg1?: SessionOptions | number,\r\n    arg2?: number,\r\n    arg3?: SessionOptions,\r\n  ): Promise<InferenceSessionInterface> {\r\n    TRACE_FUNC_BEGIN();\r\n    TRACE_EVENT_BEGIN('InferenceSession.create');\r\n    // either load from a file or buffer\r\n    let filePathOrUint8Array: string | Uint8Array;\r\n    let options: SessionOptions = {};\r\n\r\n    if (typeof arg0 === 'string') {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n    } else if (arg0 instanceof Uint8Array) {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n    } else if (\r\n      arg0 instanceof ArrayBuffer ||\r\n      (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)\r\n    ) {\r\n      const buffer = arg0;\r\n      let byteOffset = 0;\r\n      let byteLength = arg0.byteLength;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 === 'number') {\r\n        byteOffset = arg1;\r\n        if (!Number.isSafeInteger(byteOffset)) {\r\n          throw new RangeError(\"'byteOffset' must be an integer.\");\r\n        }\r\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\r\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\r\n        }\r\n        byteLength = arg0.byteLength - byteOffset;\r\n        if (typeof arg2 === 'number') {\r\n          byteLength = arg2;\r\n          if (!Number.isSafeInteger(byteLength)) {\r\n            throw new RangeError(\"'byteLength' must be an integer.\");\r\n          }\r\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\r\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\r\n          }\r\n          if (typeof arg3 === 'object' && arg3 !== null) {\r\n            options = arg3;\r\n          } else if (typeof arg3 !== 'undefined') {\r\n            throw new TypeError(\"'options' must be an object.\");\r\n          }\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError(\"'byteLength' must be a number.\");\r\n        }\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\r\n    } else {\r\n      throw new TypeError(\"Unexpected argument[0]: must be 'path' or 'buffer'.\");\r\n    }\r\n\r\n    // resolve backend, update session options with validated EPs, and create session handler\r\n    const [backend, optionsWithValidatedEPs] = await resolveBackendAndExecutionProviders(options);\r\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, optionsWithValidatedEPs);\r\n    TRACE_EVENT_END('InferenceSession.create');\r\n    TRACE_FUNC_END();\r\n    return new InferenceSession(handler);\r\n  }\r\n\r\n  startProfiling(): void {\r\n    this.handler.startProfiling();\r\n  }\r\n  endProfiling(): void {\r\n    this.handler.endProfiling();\r\n  }\r\n\r\n  get inputNames(): readonly string[] {\r\n    return this.handler.inputNames;\r\n  }\r\n  get outputNames(): readonly string[] {\r\n    return this.handler.outputNames;\r\n  }\r\n\r\n  get inputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\r\n    return this.handler.inputMetadata;\r\n  }\r\n\r\n  get outputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\r\n    return this.handler.outputMetadata;\r\n  }\r\n\r\n  private handler: InferenceSessionHandler;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession as InferenceSessionImpl } from './inference-session-impl.js';\r\nimport { OnnxModelOptions } from './onnx-model.js';\r\nimport { OnnxValue, OnnxValueDataLocation } from './onnx-value.js';\r\nimport type { Tensor } from './tensor.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\nexport declare namespace InferenceSession {\r\n  // #region input/output types\r\n\r\n  type OnnxValueMapType = { readonly [name: string]: OnnxValue };\r\n  type NullableOnnxValueMapType = { readonly [name: string]: OnnxValue | null };\r\n\r\n  /**\r\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type FeedsType = OnnxValueMapType;\r\n\r\n  /**\r\n   * A fetches (model outputs) could be one of the following:\r\n   *\r\n   * - Omitted. Use model's output names definition.\r\n   * - An array of string indicating the output names.\r\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\r\n   *\r\n   * @remark\r\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\r\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\r\n   * internally.\r\n   */\r\n  type FetchesType = readonly string[] | NullableOnnxValueMapType;\r\n\r\n  /**\r\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type ReturnType = OnnxValueMapType;\r\n\r\n  // #endregion\r\n\r\n  // #region session options\r\n\r\n  /**\r\n   * A set of configurations for session behavior.\r\n   */\r\n  export interface SessionOptions extends OnnxModelOptions {\r\n    /**\r\n     * An array of execution provider options.\r\n     *\r\n     * An execution provider option can be a string indicating the name of the execution provider,\r\n     * or an object of corresponding type.\r\n     */\r\n    executionProviders?: readonly ExecutionProviderConfig[];\r\n\r\n    /**\r\n     * The intra OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    intraOpNumThreads?: number;\r\n\r\n    /**\r\n     * The inter OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    interOpNumThreads?: number;\r\n\r\n    /**\r\n     * The free dimension override.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    freeDimensionOverrides?: { readonly [dimensionName: string]: number };\r\n\r\n    /**\r\n     * The optimization level.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    graphOptimizationLevel?: 'disabled' | 'basic' | 'extended' | 'layout' | 'all';\r\n\r\n    /**\r\n     * Whether enable CPU memory arena.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableCpuMemArena?: boolean;\r\n\r\n    /**\r\n     * Whether enable memory pattern.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableMemPattern?: boolean;\r\n\r\n    /**\r\n     * Execution mode.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    executionMode?: 'sequential' | 'parallel';\r\n\r\n    /**\r\n     * Optimized model file path.\r\n     *\r\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\r\n     * with a pop-up window.\r\n     */\r\n    optimizedModelFilePath?: string;\r\n\r\n    /**\r\n     * Whether enable profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    enableProfiling?: boolean;\r\n\r\n    /**\r\n     * File prefix for profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    profileFilePrefix?: string;\r\n\r\n    /**\r\n     * Log ID.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logId?: string;\r\n\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\r\n     * preferred data location as corresponding values.\r\n     *\r\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\r\n     */\r\n    preferredOutputLocation?: OnnxValueDataLocation | { readonly [outputName: string]: OnnxValueDataLocation };\r\n\r\n    /**\r\n     * Whether enable graph capture.\r\n     * This setting is available only in ONNXRuntime Web for WebGPU EP.\r\n     */\r\n    enableGraphCapture?: boolean;\r\n\r\n    /**\r\n     * Store configurations for a session. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\r\n     * onnxruntime_session_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     * ```js\r\n     * extra: {\r\n     *   session: {\r\n     *     set_denormal_as_zero: \"1\",\r\n     *     disable_prepacking: \"1\"\r\n     *   },\r\n     *   optimization: {\r\n     *     enable_gelu_approximation: \"1\"\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  // #region execution providers\r\n\r\n  // Currently, we have the following backends to support execution providers:\r\n  // Backend Node.js binding: supports 'cpu', 'dml' (win32), 'coreml' (macOS) and 'cuda' (linux).\r\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'webgpu' and 'webnn'.\r\n  // Backend ONNX.js: supports 'webgl'.\r\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\r\n  interface ExecutionProviderOptionMap {\r\n    coreml: CoreMLExecutionProviderOption;\r\n    cpu: CpuExecutionProviderOption;\r\n    cuda: CudaExecutionProviderOption;\r\n    dml: DmlExecutionProviderOption;\r\n    nnapi: NnapiExecutionProviderOption;\r\n    tensorrt: TensorRtExecutionProviderOption;\r\n    wasm: WebAssemblyExecutionProviderOption;\r\n    webgl: WebGLExecutionProviderOption;\r\n    webgpu: WebGpuExecutionProviderOption;\r\n    webnn: WebNNExecutionProviderOption;\r\n    qnn: QnnExecutionProviderOption;\r\n    xnnpack: XnnpackExecutionProviderOption;\r\n  }\r\n\r\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\r\n  type ExecutionProviderConfig =\r\n    | ExecutionProviderOptionMap[ExecutionProviderName]\r\n    | ExecutionProviderOption\r\n    | ExecutionProviderName\r\n    | string;\r\n\r\n  export interface ExecutionProviderOption {\r\n    readonly name: string;\r\n  }\r\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cpu';\r\n    useArena?: boolean;\r\n  }\r\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cuda';\r\n    deviceId?: number;\r\n  }\r\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'dml';\r\n    deviceId?: number;\r\n  }\r\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'tensorrt';\r\n    deviceId?: number;\r\n  }\r\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'wasm';\r\n  }\r\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'webgl';\r\n    // TODO: add flags\r\n  }\r\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'xnnpack';\r\n  }\r\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'webgpu';\r\n    preferredLayout?: 'NCHW' | 'NHWC';\r\n  }\r\n\r\n  // #region WebNN options\r\n\r\n  interface WebNNExecutionProviderName extends ExecutionProviderOption {\r\n    readonly name: 'webnn';\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for creating a WebNN MLContext.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dictdef-mlcontextoptions\r\n   */\r\n  export interface WebNNContextOptions {\r\n    deviceType?: 'cpu' | 'gpu' | 'npu';\r\n    numThreads?: number;\r\n    powerPreference?: 'default' | 'low-power' | 'high-performance';\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider without MLContext.\r\n   */\r\n  export interface WebNNOptionsWithoutMLContext extends WebNNExecutionProviderName, WebNNContextOptions {\r\n    context?: never;\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider with MLContext.\r\n   *\r\n   * When MLContext is provided, the deviceType is also required so that the WebNN EP can determine the preferred\r\n   * channel layout.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext\r\n   */\r\n  export interface WebNNOptionsWithMLContext\r\n    extends WebNNExecutionProviderName,\r\n      Omit<WebNNContextOptions, 'deviceType'>,\r\n      Required<Pick<WebNNContextOptions, 'deviceType'>> {\r\n    context: TryGetGlobalType<'MLContext'>;\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider with MLContext which is created from GPUDevice.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext-gpudevice\r\n   */\r\n  export interface WebNNOptionsWebGpu extends WebNNExecutionProviderName {\r\n    context: TryGetGlobalType<'MLContext'>;\r\n    gpuDevice: TryGetGlobalType<'GPUDevice'>;\r\n  }\r\n\r\n  /**\r\n   * Options for WebNN execution provider.\r\n   */\r\n  export type WebNNExecutionProviderOption =\r\n    | WebNNOptionsWithoutMLContext\r\n    | WebNNOptionsWithMLContext\r\n    | WebNNOptionsWebGpu;\r\n\r\n  // #endregion\r\n\r\n  export interface QnnExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'qnn';\r\n    /**\r\n     * Specify the QNN backend type. E.g., 'cpu' or 'htp'.\r\n     * Mutually exclusive with `backendPath`.\r\n     *\r\n     * @default 'htp'\r\n     */\r\n    backendType?: string;\r\n    /**\r\n     * Specify a path to the QNN backend library.\r\n     * Mutually exclusive with `backendType`.\r\n     */\r\n    backendPath?: string;\r\n    /**\r\n     * Specify whether to enable HTP FP16 precision.\r\n     *\r\n     * @default true\r\n     */\r\n    enableFp16Precision?: boolean;\r\n  }\r\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'coreml';\r\n    /**\r\n     * The bit flags for CoreML execution provider.\r\n     *\r\n     * ```\r\n     * COREML_FLAG_USE_CPU_ONLY = 0x001\r\n     * COREML_FLAG_ENABLE_ON_SUBGRAPH = 0x002\r\n     * COREML_FLAG_ONLY_ENABLE_DEVICE_WITH_ANE = 0x004\r\n     * COREML_FLAG_ONLY_ALLOW_STATIC_INPUT_SHAPES = 0x008\r\n     * COREML_FLAG_CREATE_MLPROGRAM = 0x010\r\n     * COREML_FLAG_USE_CPU_AND_GPU = 0x020\r\n     * ```\r\n     *\r\n     * See include/onnxruntime/core/providers/coreml/coreml_provider_factory.h for more details.\r\n     *\r\n     * This flag is available only in ONNXRuntime (Node.js binding).\r\n     */\r\n    coreMlFlags?: number;\r\n    /**\r\n     * Specify whether to use CPU only in CoreML EP.\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    useCPUOnly?: boolean;\r\n    useCPUAndGPU?: boolean;\r\n    /**\r\n     * Specify whether to enable CoreML EP on subgraph.\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    enableOnSubgraph?: boolean;\r\n    /**\r\n     * Specify whether to only enable CoreML EP for Apple devices with ANE (Apple Neural Engine).\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    onlyEnableDeviceWithANE?: boolean;\r\n  }\r\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'nnapi';\r\n    useFP16?: boolean;\r\n    useNCHW?: boolean;\r\n    cpuDisabled?: boolean;\r\n    cpuOnly?: boolean;\r\n  }\r\n  // #endregion\r\n\r\n  // #endregion\r\n\r\n  // #region run options\r\n\r\n  /**\r\n   * A set of configurations for inference run behavior\r\n   */\r\n  export interface RunOptions {\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Terminate all incomplete OrtRun calls as soon as possible if true\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    terminate?: boolean;\r\n\r\n    /**\r\n     * A tag for the Run() calls using this\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    tag?: string;\r\n\r\n    /**\r\n     * Set a single run configuration entry. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\r\n     * onnxruntime_run_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     *\r\n     * ```js\r\n     * extra: {\r\n     *   memory: {\r\n     *     enable_memory_arena_shrinkage: \"1\",\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region value metadata\r\n\r\n  /**\r\n   * The common part of the value metadata type for both tensor and non-tensor values.\r\n   */\r\n  export interface ValueMetadataBase {\r\n    /**\r\n     * The name of the specified input or output.\r\n     */\r\n    readonly name: string;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a non-tensor value.\r\n   */\r\n  export interface NonTensorValueMetadata extends ValueMetadataBase {\r\n    /**\r\n     * Get a value indicating whether the value is a tensor.\r\n     */\r\n    readonly isTensor: false;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a tensor value.\r\n   */\r\n  export interface TensorValueMetadata extends ValueMetadataBase {\r\n    /**\r\n     * Get a value indicating whether the value is a tensor.\r\n     */\r\n    readonly isTensor: true;\r\n    /**\r\n     * Get the data type of the tensor.\r\n     */\r\n    readonly type: Tensor.Type;\r\n    /**\r\n     * Get the shape of the tensor.\r\n     *\r\n     * If the shape is not defined, the value will an empty array. Otherwise, it will be an array representing the shape\r\n     * of the tensor. Each element in the array can be a number or a string. If the element is a number, it represents\r\n     * the corresponding dimension size. If the element is a string, it represents a symbolic dimension.\r\n     */\r\n    readonly shape: ReadonlyArray<number | string>;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a value.\r\n   */\r\n  export type ValueMetadata = NonTensorValueMetadata | TensorValueMetadata;\r\n\r\n  // #endregion\r\n}\r\n\r\n/**\r\n * Represent a runtime instance of an ONNX model.\r\n */\r\nexport interface InferenceSession {\r\n  // #region run()\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds, fetches and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\r\n   * detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(\r\n    feeds: InferenceSession.FeedsType,\r\n    fetches: InferenceSession.FetchesType,\r\n    options?: InferenceSession.RunOptions,\r\n  ): Promise<InferenceSession.ReturnType>;\r\n\r\n  // #endregion\r\n\r\n  // #region release()\r\n\r\n  /**\r\n   * Release the inference session and the underlying resources.\r\n   */\r\n  release(): Promise<void>;\r\n\r\n  // #endregion\r\n\r\n  // #region profiling\r\n\r\n  /**\r\n   * Start profiling.\r\n   */\r\n  startProfiling(): void;\r\n\r\n  /**\r\n   * End profiling.\r\n   */\r\n  endProfiling(): void;\r\n\r\n  // #endregion\r\n\r\n  // #region metadata\r\n\r\n  /**\r\n   * Get input names of the loaded model.\r\n   */\r\n  readonly inputNames: readonly string[];\r\n\r\n  /**\r\n   * Get output names of the loaded model.\r\n   */\r\n  readonly outputNames: readonly string[];\r\n\r\n  /**\r\n   * Get input metadata of the loaded model.\r\n   */\r\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  /**\r\n   * Get output metadata of the loaded model.\r\n   */\r\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  // #endregion\r\n}\r\n\r\nexport interface InferenceSessionFactory {\r\n  // #region create()\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an ONNX model file.\r\n   *\r\n   * @param uri - The URI or file path of the model to load.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\r\n   * @param byteLength - The length in bytes of the array buffer.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(\r\n    buffer: ArrayBufferLike,\r\n    byteOffset: number,\r\n    byteLength?: number,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from a Uint8Array.\r\n   *\r\n   * @param buffer - A Uint8Array representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  // #endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { OptionsFormat, OptionsNormalizationParameters, OptionsTensorLayout } from './tensor-factory.js';\r\n\r\nexport interface TensorToDataUrlOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\r\n\r\nexport interface TensorToImageDataOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\r\n\r\nexport interface ConversionUtils {\r\n  /**\r\n   * creates a DataURL instance from tensor\r\n   *\r\n   * @param options - An optional object representing options for creating a DataURL instance from the tensor.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `format`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * @returns a DataURL string representing the image converted from tensor data\r\n   */\r\n  toDataURL(options?: TensorToDataUrlOptions): string;\r\n\r\n  /**\r\n   * creates an ImageData instance from tensor\r\n   *\r\n   * @param options - An optional object representing options for creating an ImageData instance from the tensor.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `format`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * @returns an ImageData instance representing the image converted from tensor data\r\n   */\r\n  toImageData(options?: TensorToImageDataOptions): ImageData;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor, TypedTensor } from './tensor.js';\r\n\r\nexport type ImageFormat = 'RGB' | 'RGBA' | 'BGR' | 'RBG';\r\nexport type ImageTensorLayout = 'NHWC' | 'NCHW';\r\n\r\n// the following region contains type definitions for constructing tensor from a specific location.\r\n\r\n// #region types for constructing a tensor from a specific location\r\n\r\n/**\r\n * represent common properties of the parameter for constructing a tensor from a specific location.\r\n */\r\ninterface CommonConstructorParameters<T> extends Pick<Tensor, 'dims'> {\r\n  /**\r\n   * Specify the data type of the tensor.\r\n   */\r\n  readonly type: T;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a GPU resource.\r\n */\r\ninterface GpuResourceConstructorParameters<T extends Tensor.Type> {\r\n  /**\r\n   * an optional callback function to download data from GPU to CPU.\r\n   *\r\n   * If not provided, the tensor treat the GPU data as external resource.\r\n   */\r\n  download?(): Promise<Tensor.DataTypeMap[T]>;\r\n\r\n  /**\r\n   * an optional callback function that will be called when the tensor is disposed.\r\n   *\r\n   * If not provided, the tensor treat the GPU data as external resource.\r\n   */\r\n  dispose?(): void;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a pinned CPU buffer\r\n */\r\nexport interface CpuPinnedConstructorParameters<T extends Tensor.CpuPinnedDataTypes = Tensor.CpuPinnedDataTypes>\r\n  extends CommonConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'cpu-pinned'.\r\n   */\r\n  readonly location: 'cpu-pinned';\r\n  /**\r\n   * Specify the CPU pinned buffer that holds the tensor data.\r\n   */\r\n  readonly data: Tensor.DataTypeMap[T];\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a WebGL texture\r\n */\r\nexport interface TextureConstructorParameters<T extends Tensor.TextureDataTypes = Tensor.TextureDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'texture'.\r\n   */\r\n  readonly location: 'texture';\r\n  /**\r\n   * Specify the WebGL texture that holds the tensor data.\r\n   */\r\n  readonly texture: Tensor.TextureType;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a WebGPU buffer\r\n */\r\nexport interface GpuBufferConstructorParameters<T extends Tensor.GpuBufferDataTypes = Tensor.GpuBufferDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'gpu-buffer'.\r\n   */\r\n  readonly location: 'gpu-buffer';\r\n  /**\r\n   * Specify the WebGPU buffer that holds the tensor data.\r\n   */\r\n  readonly gpuBuffer: Tensor.GpuBufferType;\r\n}\r\n\r\nexport interface MLTensorConstructorParameters<T extends Tensor.MLTensorDataTypes = Tensor.MLTensorDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'ml-tensor'.\r\n   */\r\n  readonly location: 'ml-tensor';\r\n\r\n  /**\r\n   * Specify the WebNN MLTensor that holds the tensor data.\r\n   */\r\n  readonly mlTensor: Tensor.MLTensorType;\r\n}\r\n\r\n// #endregion\r\n\r\n// the following region contains type definitions of each individual options.\r\n// the tensor factory functions use a composition of those options as the parameter type.\r\n\r\n// #region Options fields\r\n\r\nexport interface OptionsFormat {\r\n  /**\r\n   * Describes the image format represented in RGBA color space.\r\n   */\r\n  format?: ImageFormat;\r\n}\r\n\r\nexport interface OptionsTensorFormat {\r\n  /**\r\n   * Describes the image format of the tensor.\r\n   *\r\n   * NOTE: this is different from option 'format'. While option 'format' represents the original image, 'tensorFormat'\r\n   * represents the target format of the tensor. A transpose will be performed if they are different.\r\n   */\r\n  tensorFormat?: ImageFormat;\r\n}\r\n\r\nexport interface OptionsTensorDataType {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: 'float32' | 'uint8';\r\n}\r\n\r\nexport interface OptionsTensorLayout {\r\n  /**\r\n   * Describes the tensor layout when representing data of one or more image(s).\r\n   */\r\n  tensorLayout?: ImageTensorLayout;\r\n}\r\n\r\nexport interface OptionsDimensions {\r\n  /**\r\n   * Describes the image height in pixel\r\n   */\r\n  height?: number;\r\n  /**\r\n   * Describes the image width in pixel\r\n   */\r\n  width?: number;\r\n}\r\n\r\nexport interface OptionResizedDimensions {\r\n  /**\r\n   * Describes the resized height. If omitted, original height will be used.\r\n   */\r\n  resizedHeight?: number;\r\n  /**\r\n   * Describes resized width - can be accessed via tensor dimensions as well\r\n   */\r\n  resizedWidth?: number;\r\n}\r\n\r\nexport interface OptionsNormalizationParameters {\r\n  /**\r\n   * Describes normalization parameters when preprocessing the image as model input.\r\n   *\r\n   * Data element are ranged from 0 to 255.\r\n   */\r\n  norm?: {\r\n    /**\r\n     * The 'bias' value for image normalization.\r\n     * - If omitted, use default value 0.\r\n     * - If it's a single number, apply to each channel\r\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\r\n     * for the corresponding image format\r\n     */\r\n    bias?: number | [number, number, number] | [number, number, number, number];\r\n    /**\r\n     * The 'mean' value for image normalization.\r\n     * - If omitted, use default value 255.\r\n     * - If it's a single number, apply to each channel\r\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\r\n     * for the corresponding image format\r\n     */\r\n    mean?: number | [number, number, number] | [number, number, number, number];\r\n  };\r\n}\r\n\r\n// #endregion\r\n\r\n// #region Options composition\r\n\r\nexport interface TensorFromImageDataOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromImageElementOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromUrlOptions\r\n  extends OptionsDimensions,\r\n    OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromImageBitmapOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromTextureOptions<T extends Tensor.TextureDataTypes>\r\n  extends Required<OptionsDimensions>,\r\n    OptionsFormat,\r\n    GpuResourceConstructorParameters<T> /* TODO: add more */ {}\r\n\r\nexport interface TensorFromGpuBufferOptions<T extends Tensor.GpuBufferDataTypes>\r\n  extends Pick<Tensor, 'dims'>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: T;\r\n}\r\n\r\nexport interface TensorFromMLTensorOptions<T extends Tensor.MLTensorDataTypes>\r\n  extends Pick<Tensor, 'dims'>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: T;\r\n}\r\n\r\n// #endregion\r\n\r\n/**\r\n * type TensorFactory defines the factory functions of 'Tensor' to create tensor instances from existing data or\r\n * resources.\r\n */\r\nexport interface TensorFactory {\r\n  /**\r\n   * create a tensor from an ImageData object\r\n   *\r\n   * @param imageData - the ImageData object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from ImageData.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    imageData: ImageData,\r\n    options?: TensorFromImageDataOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from a HTMLImageElement object\r\n   *\r\n   * @param imageElement - the HTMLImageElement object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from HTMLImageElement.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    imageElement: HTMLImageElement,\r\n    options?: TensorFromImageElementOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from URL\r\n   *\r\n   * @param urlSource - a string as a URL to the image or a data URL containing the image data.\r\n   * @param options - An optional object representing options for creating tensor from URL.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(urlSource: string, options?: TensorFromUrlOptions): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from an ImageBitmap object\r\n   *\r\n   * @param bitmap - the ImageBitmap object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from URL.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    bitmap: ImageBitmap,\r\n    options: TensorFromImageBitmapOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from a WebGL texture\r\n   *\r\n   * @param texture - the WebGLTexture object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from WebGL texture.\r\n   *\r\n   * The options include following properties:\r\n   * - `width`: the width of the texture. Required.\r\n   * - `height`: the height of the texture. Required.\r\n   * - `format`: the format of the texture. If omitted, assume 'RGBA'.\r\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\r\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\r\n   * need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\r\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromTexture<T extends Tensor.TextureDataTypes = 'float32'>(\r\n    texture: Tensor.TextureType,\r\n    options: TensorFromTextureOptions<T>,\r\n  ): TypedTensor<'float32'>;\r\n\r\n  /**\r\n   * create a tensor from a WebGPU buffer\r\n   *\r\n   * @param buffer - the GPUBuffer object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from WebGPU buffer.\r\n   *\r\n   * The options include following properties:\r\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\r\n   * - `dims`: the dimension of the tensor. Required.\r\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\r\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\r\n   * need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\r\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromGpuBuffer<T extends Tensor.GpuBufferDataTypes>(\r\n    buffer: Tensor.GpuBufferType,\r\n    options: TensorFromGpuBufferOptions<T>,\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * create a tensor from a WebNN MLTensor\r\n   *\r\n   * @param tensor - the MLTensor object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from a WebNN MLTensor.\r\n   *\r\n   * The options include following properties:\r\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\r\n   * - `dims`: the dimension of the tensor. Required.\r\n   * - `download`: an optional function to download the tensor data from the MLTensor to CPU. If omitted, the MLTensor\r\n   * data will not be able to download. Usually, this is provided by the WebNN backend for the inference outputs.\r\n   * Users don't need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on the WebNN MLTensor. If omitted, the MLTensor will\r\n   * not be disposed. Usually, this is provided by the WebNN backend for the inference outputs. Users don't need to\r\n   * provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromMLTensor<T extends Tensor.MLTensorDataTypes>(\r\n    tensor: Tensor.MLTensorType,\r\n    options: TensorFromMLTensorOptions<T>,\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * create a tensor from a pre-allocated buffer. The buffer will be used as a pinned buffer.\r\n   *\r\n   * @param type - the tensor element type.\r\n   * @param buffer - a TypedArray corresponding to the type.\r\n   * @param dims - specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromPinnedBuffer<T extends Exclude<Tensor.Type, 'string'>>(\r\n    type: T,\r\n    buffer: Tensor.DataTypeMap[T],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/**\r\n * A string that represents a file's URL or path.\r\n *\r\n * Path is vailable only in onnxruntime-node or onnxruntime-web running in Node.js.\r\n */\r\nexport type FileUrlOrPath = string;\r\n\r\n/**\r\n * A Blob object that represents a file.\r\n */\r\nexport type FileBlob = Blob;\r\n\r\n/**\r\n * A Uint8Array, ArrayBuffer or SharedArrayBuffer object that represents a file content.\r\n *\r\n * When it is an ArrayBuffer or SharedArrayBuffer, the whole buffer is assumed to be the file content.\r\n */\r\nexport type FileData = Uint8Array | ArrayBufferLike;\r\n\r\n/**\r\n * Represents a file that can be loaded by the ONNX Runtime JavaScript API.\r\n */\r\nexport type FileType = FileUrlOrPath | FileBlob | FileData;\r\n\r\n/**\r\n * Represents an external data file.\r\n */\r\nexport interface ExternalDataFileDescription {\r\n  /**\r\n   * Specify the external data file.\r\n   */\r\n  data: FileType;\r\n  /**\r\n   * Specify the file path.\r\n   */\r\n  path: string;\r\n}\r\n\r\n/**\r\n * Represents an external data file.\r\n *\r\n * When using a string, it should be a file URL or path that in the same directory as the model file.\r\n */\r\nexport type ExternalDataFileType = ExternalDataFileDescription | FileUrlOrPath;\r\n\r\n/**\r\n * Options for model loading.\r\n */\r\nexport interface OnnxModelOptions {\r\n  /**\r\n   * Specifying a list of files that represents the external data.\r\n   */\r\n  externalData?: readonly ExternalDataFileType[];\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from './tensor.js';\r\n\r\nexport type NonTensorType = never;\r\n\r\n/**\r\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\r\n *\r\n * NOTE: currently not support non-tensor\r\n */\r\nexport type OnnxValue = Tensor | NonTensorType;\r\n\r\n/**\r\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\r\n */\r\nexport type OnnxValueDataLocation = Tensor.DataLocation;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/**\r\n * # ONNX Runtime JavaScript API\r\n *\r\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\r\n *\r\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\r\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\r\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\r\n *\r\n * See also:\r\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript/)\r\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\r\n *\r\n * @packageDocumentation\r\n */\r\n\r\nexport * from './backend.js';\r\nexport * from './env.js';\r\nexport * from './inference-session.js';\r\nexport * from './tensor.js';\r\nexport * from './tensor-conversion.js';\r\nexport * from './tensor-factory.js';\r\nexport * from './trace.js';\r\nexport * from './onnx-model.js';\r\nexport * from './onnx-value.js';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nexport const isNode = !!(typeof process !== 'undefined' && process.versions && process.versions.node);\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/// <reference lib=\"webworker\" />\r\n\r\n//\r\n// * type hack for \"HTMLImageElement\"\r\n//\r\n// in typescript, the type of \"HTMLImageElement\" is defined in lib.dom.d.ts, which is conflict with lib.webworker.d.ts.\r\n// when we use webworker, the lib.webworker.d.ts will be used, which does not have HTMLImageElement defined.\r\n//\r\n// we will get the following errors complaining that HTMLImageElement is not defined:\r\n//\r\n// ====================================================================================================================\r\n//\r\n// ../common/dist/cjs/tensor-factory.d.ts:187:29 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 187     fromImage(imageElement: HTMLImageElement, options?: TensorFromImageElementOptions):\r\n// Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n//                                 ~~~~~~~~~~~~~~~~\r\n//\r\n// node_modules/@webgpu/types/dist/index.d.ts:83:7 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 83     | HTMLImageElement\r\n//          ~~~~~~~~~~~~~~~~\r\n//\r\n// ====================================================================================================================\r\n//\r\n// `HTMLImageElement` is only used in type declaration and not in real code. So we define it as `unknown` here to\r\n// bypass the type check.\r\n\r\n//\r\n// * type hack for \"document\"\r\n//\r\n// in typescript, the type of \"document\" is defined in lib.dom.d.ts, so it's not available in webworker.\r\n//\r\n// we will get the following errors complaining that document is not defined:\r\n//\r\n// ====================================================================================================================\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:33 - error TS2584: Cannot find name 'document'. Do you need to change your target\r\n// library? Try changing the 'lib' compiler option to include 'dom'.\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                   ~~~~~~~~\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:61 - error TS2584: Cannot find name 'document'. Do you need to change your target\r\n// library? Try changing the 'lib' compiler option to include 'dom'.\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                                               ~~~~~~~~\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:88 - error TS2552: Cannot find name 'HTMLScriptElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                                                                          ~~~~~~~~~~~~~~~~~\r\n// ====================================================================================================================\r\n//\r\n// `document` is used to get the current script URL, which is not available in webworker. This file is served as a\r\n// \"dual\" file for entries of both webworker and the esm module.\r\n//\r\ndeclare global {\r\n  type HTMLImageElement = unknown;\r\n  type HTMLScriptElement = { src?: string };\r\n  const document: undefined | { currentScript?: HTMLScriptElement };\r\n}\r\n\r\n/**\r\n * @summary\r\n *\r\n * This file is served as a \"dual\" file for both entries of the following:\r\n * - The proxy worker itself.\r\n *   - When used as a worker, it listens to the messages from the main thread and performs the corresponding operations.\r\n *   - Should be imported directly using `new Worker()` in the main thread.\r\n *\r\n * - The ESM module that creates the proxy worker (as a worker launcher).\r\n *   - When used as a worker launcher, it creates the proxy worker and returns it.\r\n *   - Should be imported using `import()` in the main thread, with the query parameter `import=1`.\r\n *\r\n * This file will be always compiling into ESM format.\r\n */\r\n\r\nimport type { OrtWasmMessage, SerializableTensorMetadata } from '../proxy-messages.js';\r\nimport {\r\n  createSession,\r\n  copyFromExternalBuffer,\r\n  endProfiling,\r\n  extractTransferableBuffers,\r\n  initEp,\r\n  initRuntime,\r\n  releaseSession,\r\n  run,\r\n} from '../wasm-core-impl.js';\r\nimport { initializeWebAssembly } from '../wasm-factory.js';\r\nimport { scriptSrc } from '../wasm-utils-import.js';\r\n\r\nconst WORKER_NAME = 'ort-wasm-proxy-worker';\r\nconst isProxyWorker = globalThis.self?.name === WORKER_NAME;\r\n\r\nif (isProxyWorker) {\r\n  // Worker thread\r\n  self.onmessage = (ev: MessageEvent<OrtWasmMessage>): void => {\r\n    const { type, in: message } = ev.data;\r\n    try {\r\n      switch (type) {\r\n        case 'init-wasm':\r\n          initializeWebAssembly(message!.wasm).then(\r\n            () => {\r\n              initRuntime(message!).then(\r\n                () => {\r\n                  postMessage({ type });\r\n                },\r\n                (err) => {\r\n                  postMessage({ type, err });\r\n                },\r\n              );\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        case 'init-ep': {\r\n          const { epName, env } = message!;\r\n          initEp(env, epName).then(\r\n            () => {\r\n              postMessage({ type });\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'copy-from': {\r\n          const { buffer } = message!;\r\n          const bufferData = copyFromExternalBuffer(buffer);\r\n          postMessage({ type, out: bufferData } as OrtWasmMessage);\r\n          break;\r\n        }\r\n        case 'create': {\r\n          const { model, options } = message!;\r\n          createSession(model, options).then(\r\n            (sessionMetadata) => {\r\n              postMessage({ type, out: sessionMetadata } as OrtWasmMessage);\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'release':\r\n          releaseSession(message!);\r\n          postMessage({ type });\r\n          break;\r\n        case 'run': {\r\n          const { sessionId, inputIndices, inputs, outputIndices, options } = message!;\r\n          run(sessionId, inputIndices, inputs, outputIndices, new Array(outputIndices.length).fill(null), options).then(\r\n            (outputs) => {\r\n              if (outputs.some((o) => o[3] !== 'cpu')) {\r\n                postMessage({ type, err: 'Proxy does not support non-cpu tensor location.' });\r\n              } else {\r\n                postMessage(\r\n                  { type, out: outputs } as OrtWasmMessage,\r\n                  extractTransferableBuffers([...inputs, ...outputs] as SerializableTensorMetadata[]),\r\n                );\r\n              }\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'end-profiling':\r\n          endProfiling(message!);\r\n          postMessage({ type });\r\n          break;\r\n        default:\r\n      }\r\n    } catch (err) {\r\n      postMessage({ type, err } as OrtWasmMessage);\r\n    }\r\n  };\r\n}\r\n\r\nexport default isProxyWorker\r\n  ? null\r\n  : (urlOverride?: string) =>\r\n      new Worker(urlOverride ?? scriptSrc!, { type: BUILD_DEFS.IS_ESM ? 'module' : 'classic', name: WORKER_NAME });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport type { OrtWasmModule } from './wasm-types';\r\nimport { isNode } from './wasm-utils-env';\r\n\r\n/**\r\n * The origin of the current location.\r\n *\r\n * In Node.js, this is undefined.\r\n */\r\nconst origin = isNode || typeof location === 'undefined' ? undefined : location.origin;\r\n\r\n/**\r\n * Some bundlers (eg. Webpack) will rewrite `import.meta.url` to a file URL at compile time.\r\n *\r\n * This function checks if `import.meta.url` starts with `file:`, but using the `>` and `<` operators instead of\r\n * `startsWith` function so that code minimizers can remove the dead code correctly.\r\n *\r\n * For example, if we use terser to minify the following code:\r\n * ```js\r\n * if (\"file://hard-coded-filename\".startsWith(\"file:\")) {\r\n *   console.log(1)\r\n * } else {\r\n *   console.log(2)\r\n * }\r\n *\r\n * if (\"file://hard-coded-filename\" > \"file:\" && \"file://hard-coded-filename\" < \"file;\") {\r\n *   console.log(3)\r\n * } else {\r\n *   console.log(4)\r\n * }\r\n * ```\r\n *\r\n * The minified code will be:\r\n * ```js\r\n * \"file://hard-coded-filename\".startsWith(\"file:\")?console.log(1):console.log(2),console.log(3);\r\n * ```\r\n *\r\n * (use Terser 5.39.0 with default options, https://try.terser.org/)\r\n *\r\n * @returns true if the import.meta.url is hardcoded as a file URI.\r\n */\r\nexport const isEsmImportMetaUrlHardcodedAsFileUri =\r\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ESM_IMPORT_META_URL! > 'file:' && BUILD_DEFS.ESM_IMPORT_META_URL! < 'file;';\r\n\r\nconst getScriptSrc = (): string | undefined => {\r\n  // if Nodejs, return undefined\r\n  if (isNode) {\r\n    return undefined;\r\n  }\r\n  // if It's ESM, use import.meta.url\r\n  if (BUILD_DEFS.IS_ESM) {\r\n    // For ESM, if the import.meta.url is a file URL, this usually means the bundler rewrites `import.meta.url` to\r\n    // the file path at compile time. In this case, this file path cannot be used to determine the runtime URL.\r\n    //\r\n    // We need to use the URL constructor like this:\r\n    // ```js\r\n    // new URL('actual-bundle-name.js', import.meta.url).href\r\n    // ```\r\n    // So that bundler can preprocess the URL correctly.\r\n    if (isEsmImportMetaUrlHardcodedAsFileUri) {\r\n      // if the rewritten URL is a relative path, we need to use the origin to resolve the URL.\r\n\r\n      // The following is a workaround for Vite.\r\n      //\r\n      // Vite uses a bundler(rollup/rolldown) that does not rewrite `import.meta.url` to a file URL. So in theory, this\r\n      // code path should not be executed in Vite. However, the bundler does not know it and it still try to load the\r\n      // following pattern:\r\n      // - `return new URL('filename', import.meta.url).href`\r\n      //\r\n      // By replacing the pattern above with the following code, we can skip the resource loading behavior:\r\n      // - `const URL2 = URL; return new URL2('filename', import.meta.url).href;`\r\n      //\r\n      // And it still works in Webpack.\r\n      const URL2 = URL;\r\n      return new URL(new URL2(BUILD_DEFS.BUNDLE_FILENAME, BUILD_DEFS.ESM_IMPORT_META_URL).href, origin).href;\r\n    }\r\n\r\n    return BUILD_DEFS.ESM_IMPORT_META_URL;\r\n  }\r\n\r\n  return typeof document !== 'undefined'\r\n    ? (document.currentScript as HTMLScriptElement)?.src\r\n    : // use `self.location.href` if available\r\n      typeof self !== 'undefined'\r\n      ? self.location?.href\r\n      : undefined;\r\n};\r\n\r\n/**\r\n * The classic script source URL. This is not always available in non ESModule environments.\r\n *\r\n * In Node.js, this is undefined.\r\n */\r\nexport const scriptSrc = getScriptSrc();\r\n\r\n/**\r\n * Infer the wasm path prefix from the script source URL.\r\n *\r\n * @returns The inferred wasm path prefix, or undefined if the script source URL is not available or is a blob URL.\r\n */\r\nexport const inferWasmPathPrefixFromScriptSrc = (): string | undefined => {\r\n  if (scriptSrc && !scriptSrc.startsWith('blob:')) {\r\n    return scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);\r\n  }\r\n  return undefined;\r\n};\r\n\r\n/**\r\n * Check if the given filename with prefix is from the same origin.\r\n */\r\nconst isSameOrigin = (filename: string, prefixOverride?: string) => {\r\n  try {\r\n    const baseUrl = prefixOverride ?? scriptSrc;\r\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\r\n    return url.origin === origin;\r\n  } catch {\r\n    return false;\r\n  }\r\n};\r\n\r\n/**\r\n * Normalize the inputs to an absolute URL with the given prefix override. If failed, return undefined.\r\n */\r\nconst normalizeUrl = (filename: string, prefixOverride?: string) => {\r\n  const baseUrl = prefixOverride ?? scriptSrc;\r\n  try {\r\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\r\n    return url.href;\r\n  } catch {\r\n    return undefined;\r\n  }\r\n};\r\n\r\n/**\r\n * Create a fallback URL if an absolute URL cannot be created by the normalizeUrl function.\r\n */\r\nconst fallbackUrl = (filename: string, prefixOverride?: string) => `${prefixOverride ?? './'}${filename}`;\r\n\r\n/**\r\n * This helper function is used to preload a module from a URL.\r\n *\r\n * If the origin of the worker URL is different from the current origin, the worker cannot be loaded directly.\r\n * See discussions in https://github.com/webpack-contrib/worker-loader/issues/154\r\n *\r\n * In this case, we will fetch the worker URL and create a new Blob URL with the same origin as a workaround.\r\n *\r\n * @param absoluteUrl - The absolute URL to preload.\r\n *\r\n * @returns - A promise that resolves to a new Blob URL\r\n */\r\nconst preload = async (absoluteUrl: string): Promise<string> => {\r\n  const response = await fetch(absoluteUrl, { credentials: 'same-origin' });\r\n  const blob = await response.blob();\r\n  return URL.createObjectURL(blob);\r\n};\r\n\r\n/**\r\n * This helper function is used to dynamically import a module from a URL.\r\n *\r\n * The build script has special handling for this function to ensure that the URL is not bundled into the final output.\r\n *\r\n * @param url - The URL to import.\r\n *\r\n * @returns - A promise that resolves to the default export of the module.\r\n */\r\nconst dynamicImportDefault = async <T>(url: string): Promise<T> =>\r\n  (await import(/* webpackIgnore: true */ url)).default;\r\n\r\n/**\r\n * The proxy worker factory imported from the proxy worker module.\r\n *\r\n * This is only available when the WebAssembly proxy is not disabled.\r\n */\r\nconst createProxyWorker: ((urlOverride?: string) => Worker) | undefined =\r\n  // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n  BUILD_DEFS.DISABLE_WASM_PROXY ? undefined : require('./proxy-worker/main').default;\r\n\r\n/**\r\n * Import the proxy worker.\r\n *\r\n * This function will perform the following steps:\r\n * 1. If a preload is needed, it will preload the module and return the object URL.\r\n * 2. Use the proxy worker factory to create the proxy worker.\r\n *\r\n * @returns - A promise that resolves to a tuple of 2 elements:\r\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\r\n *            - The proxy worker.\r\n */\r\nexport const importProxyWorker = async (): Promise<[undefined | string, Worker]> => {\r\n  if (!scriptSrc) {\r\n    throw new Error('Failed to load proxy worker: cannot determine the script source URL.');\r\n  }\r\n\r\n  // If the script source is from the same origin, we can use the embedded proxy module directly.\r\n  if (isSameOrigin(scriptSrc)) {\r\n    return [undefined, createProxyWorker!()];\r\n  }\r\n\r\n  // Otherwise, need to preload\r\n  const url = await preload(scriptSrc);\r\n  return [url, createProxyWorker!(url)];\r\n};\r\n\r\n/**\r\n * The embedded WebAssembly module.\r\n *\r\n * This is only available in ESM and when embedding is not disabled.\r\n */\r\nconst embeddedWasmModule: EmscriptenModuleFactory<OrtWasmModule> | undefined =\r\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ENABLE_BUNDLE_WASM_JS\r\n    ? // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n      require(\r\n        !BUILD_DEFS.DISABLE_JSEP\r\n          ? '../../dist/ort-wasm-simd-threaded.jsep.mjs'\r\n          : !BUILD_DEFS.DISABLE_WEBGPU\r\n            ? '../../dist/ort-wasm-simd-threaded.asyncify.mjs'\r\n            : '../../dist/ort-wasm-simd-threaded.mjs',\r\n      ).default\r\n    : undefined;\r\n\r\n/**\r\n * Import the WebAssembly module.\r\n *\r\n * This function will perform the following steps:\r\n * 1. If the embedded module exists and no custom URL is specified, use the embedded module.\r\n * 2. If a preload is needed, it will preload the module and return the object URL.\r\n * 3. Otherwise, it will perform a dynamic import of the module.\r\n *\r\n * @returns - A promise that resolves to a tuple of 2 elements:\r\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\r\n *            - The default export of the module, which is a factory function to create the WebAssembly module.\r\n */\r\nexport const importWasmModule = async (\r\n  urlOverride: string | undefined,\r\n  prefixOverride: string | undefined,\r\n  isMultiThreaded: boolean,\r\n  isWasmOverridden: boolean,\r\n): Promise<[undefined | string, EmscriptenModuleFactory<OrtWasmModule>]> => {\r\n  //\r\n  // Check if we should use the embedded module.\r\n  //\r\n\r\n  // To use the embedded module, it should be available, and no URL override or prefix override should be specified.\r\n  let useEmbeddedModule = embeddedWasmModule && !(urlOverride || prefixOverride);\r\n  if (useEmbeddedModule) {\r\n    if (!scriptSrc) {\r\n      // no URL info available.\r\n      //\r\n      // Note: when the embedded module is available, it means the current script is ESM. Usually, in ESM, the\r\n      // `import.meta.url` is available. But in some cases (eg. Cloudflare Workers), the value of `import.meta.url`\r\n      // can be `null` or `undefined`. In this case, we can only load the embedded module when:\r\n      //\r\n      // 1. The WebAssembly module binary is overridden:\r\n      //    ```js\r\n      //    env.wasm.wasmPaths = undefined;  // or not specified\r\n      //    env.wasm.wasmBinary = /* a Uint8Array containing the WebAssembly binary */;\r\n      //    ```\r\n      //\r\n      // 2. The \".wasm\" only is overridden.\r\n      //    ```js\r\n      //    env.wasm.wasmPaths = { wasm: /* URL of the .wasm file */ };\r\n      //    ```\r\n      //\r\n      if (isWasmOverridden && !isMultiThreaded) {\r\n        useEmbeddedModule = true;\r\n      } else {\r\n        throw new Error('cannot determine the script source URL.');\r\n      }\r\n    } else {\r\n      // if the script source is available, we can check if it is from the same origin.\r\n      useEmbeddedModule = isSameOrigin(scriptSrc);\r\n    }\r\n  }\r\n  if (useEmbeddedModule) {\r\n    return [undefined, embeddedWasmModule!];\r\n  } else {\r\n    const wasmModuleFilename = !BUILD_DEFS.DISABLE_JSEP\r\n      ? 'ort-wasm-simd-threaded.jsep.mjs'\r\n      : !BUILD_DEFS.DISABLE_WEBGPU\r\n        ? 'ort-wasm-simd-threaded.asyncify.mjs'\r\n        : 'ort-wasm-simd-threaded.mjs';\r\n    const wasmModuleUrl = urlOverride ?? normalizeUrl(wasmModuleFilename, prefixOverride);\r\n    // need to preload if all of the following conditions are met:\r\n    // 1. not in Node.js.\r\n    //    - Node.js does not have the same origin policy for creating workers.\r\n    // 2. multi-threaded is enabled.\r\n    //    - If multi-threaded is disabled, no worker will be created. So we don't need to preload the module.\r\n    // 3. the absolute URL is available.\r\n    //    - If the absolute URL is failed to be created, the origin cannot be determined. In this case, we will not\r\n    //    preload the module.\r\n    // 4. the worker URL is not from the same origin.\r\n    //    - If the worker URL is from the same origin, we can create the worker directly.\r\n    const needPreload = !isNode && isMultiThreaded && wasmModuleUrl && !isSameOrigin(wasmModuleUrl, prefixOverride);\r\n    const url = needPreload\r\n      ? await preload(wasmModuleUrl)\r\n      : (wasmModuleUrl ?? fallbackUrl(wasmModuleFilename, prefixOverride));\r\n    return [needPreload ? url : undefined, await dynamicImportDefault<EmscriptenModuleFactory<OrtWasmModule>>(url)];\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Env } from 'onnxruntime-common';\r\n\r\nimport type { OrtWasmModule } from './wasm-types';\r\nimport { importWasmModule, inferWasmPathPrefixFromScriptSrc } from './wasm-utils-import';\r\n\r\nlet wasm: OrtWasmModule | undefined;\r\nlet initialized = false;\r\nlet initializing = false;\r\nlet aborted = false;\r\n\r\nconst isMultiThreadSupported = (): boolean => {\r\n  // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\r\n  if (typeof SharedArrayBuffer === 'undefined') {\r\n    return false;\r\n  }\r\n\r\n  try {\r\n    // Test for transferability of SABs (for browsers. needed for Firefox)\r\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\r\n    if (typeof MessageChannel !== 'undefined') {\r\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\r\n    }\r\n\r\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing threaded instructions.\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16,\r\n        2, 0, 26, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nconst isSimdSupported = (): boolean => {\r\n  try {\r\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing SIMD instructions.\r\n\r\n    // The binary data is generated from the following code by wat2wasm:\r\n    //\r\n    // (module\r\n    //   (type $t0 (func))\r\n    //   (func $f0 (type $t0)\r\n    //     (drop\r\n    //       (i32x4.dot_i16x8_s\r\n    //         (i8x16.splat\r\n    //           (i32.const 0))\r\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\r\n\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nconst isRelaxedSimdSupported = (): boolean => {\r\n  try {\r\n    // Test for WebAssembly Relaxed SIMD capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing Relaxed SIMD instructions.\r\n\r\n    // The binary data is generated from the following code by wat2wasm:\r\n    // (module\r\n    //   (func (result v128)\r\n    //      i32.const 1\r\n    //      i8x16.splat\r\n    //      i32.const 2\r\n    //      i8x16.splat\r\n    //      i32.const 3\r\n    //      i8x16.splat\r\n    //      i32x4.relaxed_dot_i8x16_i7x16_add_s\r\n    //   )\r\n    //  )\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 19, 1, 17, 0, 65, 1, 253, 15, 65, 2, 253,\r\n        15, 65, 3, 253, 15, 253, 147, 2, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nexport const initializeWebAssembly = async (flags: Env.WebAssemblyFlags): Promise<void> => {\r\n  if (initialized) {\r\n    return Promise.resolve();\r\n  }\r\n  if (initializing) {\r\n    throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");\r\n  }\r\n  if (aborted) {\r\n    throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");\r\n  }\r\n\r\n  initializing = true;\r\n\r\n  // wasm flags are already initialized\r\n  const timeout = flags.initTimeout!;\r\n  let numThreads = flags.numThreads!;\r\n\r\n  // ensure SIMD is supported\r\n  if (flags.simd === false) {\r\n    // skip SIMD feature checking as it is disabled explicitly by user\r\n  } else if (flags.simd === 'relaxed') {\r\n    // check if relaxed SIMD is supported\r\n    if (!isRelaxedSimdSupported()) {\r\n      throw new Error('Relaxed WebAssembly SIMD is not supported in the current environment.');\r\n    }\r\n  } else if (!isSimdSupported()) {\r\n    throw new Error('WebAssembly SIMD is not supported in the current environment.');\r\n  }\r\n\r\n  // check if multi-threading is supported\r\n  const multiThreadSupported = isMultiThreadSupported();\r\n  if (numThreads > 1 && !multiThreadSupported) {\r\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\r\n      // eslint-disable-next-line no-console\r\n      console.warn(\r\n        'env.wasm.numThreads is set to ' +\r\n          numThreads +\r\n          ', but this will not work unless you enable crossOriginIsolated mode. ' +\r\n          'See https://web.dev/cross-origin-isolation-guide/ for more info.',\r\n      );\r\n    }\r\n\r\n    // eslint-disable-next-line no-console\r\n    console.warn(\r\n      'WebAssembly multi-threading is not supported in the current environment. ' + 'Falling back to single-threading.',\r\n    );\r\n\r\n    // set flags.numThreads to 1 so that OrtInit() will not create a global thread pool.\r\n    flags.numThreads = numThreads = 1;\r\n  }\r\n\r\n  const wasmPaths = flags.wasmPaths;\r\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\r\n  const mjsPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.mjs;\r\n  const mjsPathOverride = (mjsPathOverrideFlag as URL)?.href ?? mjsPathOverrideFlag;\r\n  const wasmPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.wasm;\r\n  const wasmPathOverride = (wasmPathOverrideFlag as URL)?.href ?? wasmPathOverrideFlag;\r\n  const wasmBinaryOverride = flags.wasmBinary;\r\n\r\n  const [objectUrl, ortWasmFactory] = await importWasmModule(\r\n    mjsPathOverride,\r\n    wasmPrefixOverride,\r\n    numThreads > 1,\r\n    !!wasmBinaryOverride || !!wasmPathOverride,\r\n  );\r\n\r\n  let isTimeout = false;\r\n\r\n  const tasks: Array<Promise<void>> = [];\r\n\r\n  // promise for timeout\r\n  if (timeout > 0) {\r\n    tasks.push(\r\n      new Promise((resolve) => {\r\n        setTimeout(() => {\r\n          isTimeout = true;\r\n          resolve();\r\n        }, timeout);\r\n      }),\r\n    );\r\n  }\r\n\r\n  // promise for module initialization\r\n  tasks.push(\r\n    new Promise((resolve, reject) => {\r\n      const config: Partial<OrtWasmModule> = {\r\n        /**\r\n         * The number of threads. WebAssembly will create (Module.numThreads - 1) workers. If it is 1, no worker will be\r\n         * created.\r\n         */\r\n        numThreads,\r\n      };\r\n\r\n      if (wasmBinaryOverride) {\r\n        // Set a custom buffer which contains the WebAssembly binary. This will skip the wasm file fetching.\r\n        config.wasmBinary = wasmBinaryOverride;\r\n      } else if (wasmPathOverride || wasmPrefixOverride) {\r\n        // A callback function to locate the WebAssembly file. The function should return the full path of the file.\r\n        //\r\n        // Since Emscripten 3.1.58, this function is only called for the .wasm file.\r\n        config.locateFile = (fileName) => wasmPathOverride ?? wasmPrefixOverride + fileName;\r\n      } else if (mjsPathOverride && mjsPathOverride.indexOf('blob:') !== 0) {\r\n        // if mjs path is specified, use it as the base path for the .wasm file.\r\n        config.locateFile = (fileName) => new URL(fileName, mjsPathOverride).href;\r\n      } else if (objectUrl) {\r\n        const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\r\n        if (inferredWasmPathPrefix) {\r\n          // if the wasm module is preloaded, use the inferred wasm path as the base path for the .wasm file.\r\n          config.locateFile = (fileName) => inferredWasmPathPrefix + fileName;\r\n        }\r\n      }\r\n\r\n      ortWasmFactory(config).then(\r\n        // wasm module initialized successfully\r\n        (module) => {\r\n          initializing = false;\r\n          initialized = true;\r\n          wasm = module;\r\n          resolve();\r\n          if (objectUrl) {\r\n            URL.revokeObjectURL(objectUrl);\r\n          }\r\n        },\r\n        // wasm module failed to initialize\r\n        (what) => {\r\n          initializing = false;\r\n          aborted = true;\r\n          reject(what);\r\n        },\r\n      );\r\n    }),\r\n  );\r\n\r\n  await Promise.race(tasks);\r\n\r\n  if (isTimeout) {\r\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\r\n  }\r\n};\r\n\r\nexport const getInstance = (): OrtWasmModule => {\r\n  if (initialized && wasm) {\r\n    return wasm;\r\n  }\r\n\r\n  throw new Error('WebAssembly is not initialized yet.');\r\n};\r\n\r\nexport const dispose = (): void => {\r\n  if (initialized && !initializing && !aborted) {\r\n    // TODO: currently \"PThread.terminateAllThreads()\" is not exposed in the wasm module.\r\n    //       And this function is not yet called by any code.\r\n    //       If it is needed in the future, we should expose it in the wasm module and uncomment the following line.\r\n\r\n    // wasm?.PThread?.terminateAllThreads();\r\n    wasm = undefined;\r\n\r\n    initializing = false;\r\n    initialized = false;\r\n    aborted = true;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { getInstance } from './wasm-factory';\r\n\r\nexport const allocWasmString = (data: string, allocs: number[]): number => {\r\n  const wasm = getInstance();\r\n\r\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\r\n  const dataOffset = wasm._malloc(dataLength);\r\n  wasm.stringToUTF8(data, dataOffset, dataLength);\r\n  allocs.push(dataOffset);\r\n\r\n  return dataOffset;\r\n};\r\n\r\ninterface ExtraOptionsHandler {\r\n  (name: string, value: string): void;\r\n}\r\n\r\nexport const iterateExtraOptions = (\r\n  options: Record<string, unknown>,\r\n  prefix: string,\r\n  seen: WeakSet<Record<string, unknown>>,\r\n  handler: ExtraOptionsHandler,\r\n): void => {\r\n  if (typeof options == 'object' && options !== null) {\r\n    if (seen.has(options)) {\r\n      throw new Error('Circular reference in options');\r\n    } else {\r\n      seen.add(options);\r\n    }\r\n  }\r\n\r\n  Object.entries(options).forEach(([key, value]) => {\r\n    const name = prefix ? prefix + key : key;\r\n    if (typeof value === 'object') {\r\n      iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\r\n    } else if (typeof value === 'string' || typeof value === 'number') {\r\n      handler(name, value.toString());\r\n    } else if (typeof value === 'boolean') {\r\n      handler(name, value ? '1' : '0');\r\n    } else {\r\n      throw new Error(`Can't handle extra config type: ${typeof value}`);\r\n    }\r\n  });\r\n};\r\n\r\n/**\r\n * check web assembly API's last error and throw error if any error occurred.\r\n * @param message a message used when an error occurred.\r\n */\r\nexport const checkLastError = (message: string): void => {\r\n  const wasm = getInstance();\r\n\r\n  const stack = wasm.stackSave();\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const paramsOffset = wasm.stackAlloc(2 * ptrSize);\r\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + ptrSize);\r\n    const errorCode = Number(wasm.getValue(paramsOffset, ptrSize === 4 ? 'i32' : 'i64'));\r\n    const errorMessagePointer = wasm.getValue(paramsOffset + ptrSize, '*');\r\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\r\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession } from 'onnxruntime-common';\r\n\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\r\n\r\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\r\n  const wasm = getInstance();\r\n  let runOptionsHandle = 0;\r\n  const allocs: number[] = [];\r\n\r\n  const runOptions: InferenceSession.RunOptions = options || {};\r\n\r\n  try {\r\n    if (options?.logSeverityLevel === undefined) {\r\n      runOptions.logSeverityLevel = 2; // Default to warning\r\n    } else if (\r\n      typeof options.logSeverityLevel !== 'number' ||\r\n      !Number.isInteger(options.logSeverityLevel) ||\r\n      options.logSeverityLevel < 0 ||\r\n      options.logSeverityLevel > 4\r\n    ) {\r\n      throw new Error(`log severity level is not valid: ${options.logSeverityLevel}`);\r\n    }\r\n\r\n    if (options?.logVerbosityLevel === undefined) {\r\n      runOptions.logVerbosityLevel = 0; // Default to 0\r\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\r\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\r\n    }\r\n\r\n    if (options?.terminate === undefined) {\r\n      runOptions.terminate = false;\r\n    }\r\n\r\n    let tagDataOffset = 0;\r\n    if (options?.tag !== undefined) {\r\n      tagDataOffset = allocWasmString(options.tag, allocs);\r\n    }\r\n\r\n    runOptionsHandle = wasm._OrtCreateRunOptions(\r\n      runOptions.logSeverityLevel!,\r\n      runOptions.logVerbosityLevel!,\r\n      !!runOptions.terminate!,\r\n      tagDataOffset,\r\n    );\r\n    if (runOptionsHandle === 0) {\r\n      checkLastError(\"Can't create run options.\");\r\n    }\r\n\r\n    if (options?.extra !== undefined) {\r\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\r\n        const keyDataOffset = allocWasmString(key, allocs);\r\n        const valueDataOffset = allocWasmString(value, allocs);\r\n\r\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\r\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\r\n        }\r\n      });\r\n    }\r\n\r\n    return [runOptionsHandle, allocs];\r\n  } catch (e) {\r\n    if (runOptionsHandle !== 0) {\r\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n    throw e;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport type { InferenceSession } from 'onnxruntime-common';\r\n\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\r\n\r\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string | unknown): number => {\r\n  switch (graphOptimizationLevel) {\r\n    case 'disabled':\r\n      return 0;\r\n    case 'basic':\r\n      return 1;\r\n    case 'extended':\r\n      return 2;\r\n    case 'layout':\r\n      return 3;\r\n    case 'all':\r\n      return 99;\r\n    default:\r\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\r\n  }\r\n};\r\n\r\nconst getExecutionMode = (executionMode: 'sequential' | 'parallel'): number => {\r\n  switch (executionMode) {\r\n    case 'sequential':\r\n      return 0;\r\n    case 'parallel':\r\n      return 1;\r\n    default:\r\n      throw new Error(`unsupported execution mode: ${executionMode}`);\r\n  }\r\n};\r\n\r\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\r\n  if (!options.extra) {\r\n    options.extra = {};\r\n  }\r\n  if (!options.extra.session) {\r\n    options.extra.session = {};\r\n  }\r\n  const session = options.extra.session as Record<string, string>;\r\n  if (!session.use_ort_model_bytes_directly) {\r\n    // eslint-disable-next-line camelcase\r\n    session.use_ort_model_bytes_directly = '1';\r\n  }\r\n\r\n  // if using JSEP with WebGPU, always disable memory pattern\r\n  if (\r\n    options.executionProviders &&\r\n    options.executionProviders.some((ep) => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')\r\n  ) {\r\n    options.enableMemPattern = false;\r\n  }\r\n};\r\n\r\nconst appendSessionConfig = (sessionOptionsHandle: number, key: string, value: string, allocs: number[]): void => {\r\n  const keyDataOffset = allocWasmString(key, allocs);\r\n  const valueDataOffset = allocWasmString(value, allocs);\r\n  if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\r\n    checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\r\n  }\r\n};\r\n\r\nconst appendEpOption = (epOptions: Array<[number, number]>, key: string, value: string, allocs: number[]): void => {\r\n  const keyDataOffset = allocWasmString(key, allocs);\r\n  const valueDataOffset = allocWasmString(value, allocs);\r\n  epOptions.push([keyDataOffset, valueDataOffset]);\r\n};\r\n\r\nconst setExecutionProviders = async (\r\n  sessionOptionsHandle: number,\r\n  executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\r\n  allocs: number[],\r\n): Promise<void> => {\r\n  for (const ep of executionProviders) {\r\n    let epName = typeof ep === 'string' ? ep : ep.name;\r\n    const epOptions: Array<[number, number]> = [];\r\n\r\n    // check EP name\r\n    switch (epName) {\r\n      case 'webnn':\r\n        epName = 'WEBNN';\r\n        if (typeof ep !== 'string') {\r\n          const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\r\n          // const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\r\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\r\n          if (deviceType) {\r\n            appendSessionConfig(sessionOptionsHandle, 'deviceType', deviceType, allocs);\r\n          }\r\n        }\r\n        break;\r\n      case 'webgpu':\r\n        if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n          epName = 'WebGPU';\r\n          let customDevice: GPUDevice | undefined;\r\n\r\n          if (typeof ep !== 'string') {\r\n            const customOptions = ep as unknown as { device: GPUDevice };\r\n            if (customOptions.device) {\r\n              if (typeof GPUDevice !== 'undefined' && customOptions.device instanceof GPUDevice) {\r\n                customDevice = customOptions.device;\r\n              } else {\r\n                throw new Error('Invalid GPU device set in WebGPU EP options.');\r\n              }\r\n            }\r\n\r\n            // TODO: handle more options\r\n          }\r\n\r\n          const info = getInstance().webgpuRegisterDevice!(customDevice);\r\n          if (info) {\r\n            const [deviceId, instanceHandle, deviceHandle] = info;\r\n            appendEpOption(epOptions, 'deviceId', deviceId.toString(), allocs);\r\n            appendEpOption(epOptions, 'webgpuInstance', instanceHandle.toString(), allocs);\r\n            appendEpOption(epOptions, 'webgpuDevice', deviceHandle.toString(), allocs);\r\n          }\r\n        } else {\r\n          epName = 'JS';\r\n          if (typeof ep !== 'string') {\r\n            const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\r\n            if (webgpuOptions?.preferredLayout) {\r\n              if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\r\n                throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\r\n              }\r\n              appendSessionConfig(sessionOptionsHandle, 'preferredLayout', webgpuOptions.preferredLayout, allocs);\r\n            }\r\n          }\r\n        }\r\n        break;\r\n      case 'wasm':\r\n      case 'cpu':\r\n        continue;\r\n      default:\r\n        throw new Error(`not supported execution provider: ${epName}`);\r\n    }\r\n\r\n    const epNameDataOffset = allocWasmString(epName, allocs);\r\n    const epOptionsCount = epOptions.length;\r\n    let keysOffset = 0;\r\n    let valuesOffset = 0;\r\n    if (epOptionsCount > 0) {\r\n      keysOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\r\n      allocs.push(keysOffset);\r\n      valuesOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\r\n      allocs.push(valuesOffset);\r\n      for (let i = 0; i < epOptionsCount; i++) {\r\n        getInstance().setValue(keysOffset + i * getInstance().PTR_SIZE, epOptions[i][0], '*');\r\n        getInstance().setValue(valuesOffset + i * getInstance().PTR_SIZE, epOptions[i][1], '*');\r\n      }\r\n    }\r\n    if (\r\n      (await getInstance()._OrtAppendExecutionProvider(\r\n        sessionOptionsHandle,\r\n        epNameDataOffset,\r\n        keysOffset,\r\n        valuesOffset,\r\n        epOptionsCount,\r\n      )) !== 0\r\n    ) {\r\n      checkLastError(`Can't append execution provider: ${epName}.`);\r\n    }\r\n  }\r\n};\r\n\r\nexport const setSessionOptions = async (options?: InferenceSession.SessionOptions): Promise<[number, number[]]> => {\r\n  const wasm = getInstance();\r\n  let sessionOptionsHandle = 0;\r\n  const allocs: number[] = [];\r\n\r\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\r\n  appendDefaultOptions(sessionOptions);\r\n\r\n  try {\r\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\r\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\r\n    const logIdDataOffset =\r\n      typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\r\n\r\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2; // Default to 2 - warning\r\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\r\n      throw new Error(`log severity level is not valid: ${logSeverityLevel}`);\r\n    }\r\n\r\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0; // Default to 0 - verbose\r\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\r\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\r\n    }\r\n\r\n    const optimizedModelFilePathOffset =\r\n      typeof sessionOptions.optimizedModelFilePath === 'string'\r\n        ? allocWasmString(sessionOptions.optimizedModelFilePath, allocs)\r\n        : 0;\r\n\r\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\r\n      graphOptimizationLevel,\r\n      !!sessionOptions.enableCpuMemArena,\r\n      !!sessionOptions.enableMemPattern,\r\n      executionMode,\r\n      !!sessionOptions.enableProfiling,\r\n      0,\r\n      logIdDataOffset,\r\n      logSeverityLevel,\r\n      logVerbosityLevel,\r\n      optimizedModelFilePathOffset,\r\n    );\r\n    if (sessionOptionsHandle === 0) {\r\n      checkLastError(\"Can't create session options.\");\r\n    }\r\n\r\n    if (sessionOptions.executionProviders) {\r\n      await setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\r\n    }\r\n\r\n    if (sessionOptions.enableGraphCapture !== undefined) {\r\n      if (typeof sessionOptions.enableGraphCapture !== 'boolean') {\r\n        throw new Error(`enableGraphCapture must be a boolean value: ${sessionOptions.enableGraphCapture}`);\r\n      }\r\n      appendSessionConfig(\r\n        sessionOptionsHandle,\r\n        'enableGraphCapture',\r\n        sessionOptions.enableGraphCapture.toString(),\r\n        allocs,\r\n      );\r\n    }\r\n\r\n    if (sessionOptions.freeDimensionOverrides) {\r\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\r\n        if (typeof name !== 'string') {\r\n          throw new Error(`free dimension override name must be a string: ${name}`);\r\n        }\r\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\r\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\r\n        }\r\n        const nameOffset = allocWasmString(name, allocs);\r\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\r\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\r\n        }\r\n      }\r\n    }\r\n\r\n    if (sessionOptions.extra !== undefined) {\r\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\r\n        appendSessionConfig(sessionOptionsHandle, key, value, allocs);\r\n      });\r\n    }\r\n\r\n    return [sessionOptionsHandle, allocs];\r\n  } catch (e) {\r\n    if (sessionOptionsHandle !== 0) {\r\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\r\n        checkLastError(\"Can't release session options.\");\r\n      }\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n    throw e;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from 'onnxruntime-common';\r\n\r\n// a dummy type declaration for Float16Array in case any polyfill is available.\r\ndeclare global {\r\n  // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\r\n  const Float16Array: any;\r\n}\r\n\r\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\r\n\r\n/**\r\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\r\n */\r\nexport const enum DataType {\r\n  undefined = 0,\r\n  float = 1,\r\n  uint8 = 2,\r\n  int8 = 3,\r\n  uint16 = 4,\r\n  int16 = 5,\r\n  int32 = 6,\r\n  int64 = 7,\r\n  string = 8,\r\n  bool = 9,\r\n  float16 = 10,\r\n  double = 11,\r\n  uint32 = 12,\r\n  uint64 = 13,\r\n  complex64 = 14,\r\n  complex128 = 15,\r\n  bfloat16 = 16,\r\n\r\n  // 4-bit data-types\r\n  uint4 = 21,\r\n  int4 = 22,\r\n}\r\n\r\n/**\r\n * Map string tensor data to enum value\r\n */\r\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\r\n  switch (type) {\r\n    case 'int8':\r\n      return DataType.int8;\r\n    case 'uint8':\r\n      return DataType.uint8;\r\n    case 'bool':\r\n      return DataType.bool;\r\n    case 'int16':\r\n      return DataType.int16;\r\n    case 'uint16':\r\n      return DataType.uint16;\r\n    case 'int32':\r\n      return DataType.int32;\r\n    case 'uint32':\r\n      return DataType.uint32;\r\n    case 'float16':\r\n      return DataType.float16;\r\n    case 'float32':\r\n      return DataType.float;\r\n    case 'float64':\r\n      return DataType.double;\r\n    case 'string':\r\n      return DataType.string;\r\n    case 'int64':\r\n      return DataType.int64;\r\n    case 'uint64':\r\n      return DataType.uint64;\r\n    case 'int4':\r\n      return DataType.int4;\r\n    case 'uint4':\r\n      return DataType.uint4;\r\n\r\n    default:\r\n      throw new Error(`unsupported data type: ${type}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map enum value to string tensor data\r\n */\r\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\r\n  switch (typeProto) {\r\n    case DataType.int8:\r\n      return 'int8';\r\n    case DataType.uint8:\r\n      return 'uint8';\r\n    case DataType.bool:\r\n      return 'bool';\r\n    case DataType.int16:\r\n      return 'int16';\r\n    case DataType.uint16:\r\n      return 'uint16';\r\n    case DataType.int32:\r\n      return 'int32';\r\n    case DataType.uint32:\r\n      return 'uint32';\r\n    case DataType.float16:\r\n      return 'float16';\r\n    case DataType.float:\r\n      return 'float32';\r\n    case DataType.double:\r\n      return 'float64';\r\n    case DataType.string:\r\n      return 'string';\r\n    case DataType.int64:\r\n      return 'int64';\r\n    case DataType.uint64:\r\n      return 'uint64';\r\n    case DataType.int4:\r\n      return 'int4';\r\n    case DataType.uint4:\r\n      return 'uint4';\r\n\r\n    default:\r\n      throw new Error(`unsupported data type: ${typeProto}`);\r\n  }\r\n};\r\n\r\n/**\r\n * get tensor size in bytes by the given data type and dimensions\r\n * @returns size in integer or undefined if the data type is not supported\r\n */\r\nexport const calculateTensorSizeInBytes = (\r\n  dateType: number,\r\n  dimsOrSize: readonly number[] | number,\r\n): number | undefined => {\r\n  const elementSize = [\r\n    -1, // undefined = 0\r\n    4, // float = 1\r\n    1, // uint8 = 2\r\n    1, // int8 = 3\r\n    2, // uint16 = 4\r\n    2, // int16 = 5\r\n    4, // int32 = 6\r\n    8, // int64 = 7\r\n    -1, // string = 8\r\n    1, // bool = 9\r\n    2, // float16 = 10\r\n    8, // double = 11\r\n    4, // uint32 = 12\r\n    8, // uint64 = 13\r\n    -1, // complex64 = 14\r\n    -1, // complex128 = 15\r\n    -1, // bfloat16 = 16\r\n    -1, // FLOAT8E4M3FN = 17\r\n    -1, // FLOAT8E4M3FNUZ = 18\r\n    -1, // FLOAT8E5M2 = 19\r\n    -1, // FLOAT8E5M2FNUZ = 20\r\n    0.5, // uint4 = 21\r\n    0.5, // int4 = 22\r\n  ][dateType];\r\n\r\n  const size = typeof dimsOrSize === 'number' ? dimsOrSize : dimsOrSize.reduce((a, b) => a * b, 1);\r\n  return elementSize > 0 ? Math.ceil(size * elementSize) : undefined;\r\n};\r\n\r\n/**\r\n * get typed array constructor by the given tensor type\r\n */\r\nexport const tensorTypeToTypedArrayConstructor = (\r\n  type: Tensor.Type,\r\n):\r\n  | Float32ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Int8ArrayConstructor\r\n  | Uint16ArrayConstructor\r\n  | Int16ArrayConstructor\r\n  | Int32ArrayConstructor\r\n  | BigInt64ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Float64ArrayConstructor\r\n  | Uint32ArrayConstructor\r\n  | BigUint64ArrayConstructor => {\r\n  switch (type) {\r\n    case 'float16':\r\n      // allow Float16Array polyfill.\r\n      return typeof Float16Array !== 'undefined' && Float16Array.from ? Float16Array : Uint16Array;\r\n    case 'float32':\r\n      return Float32Array;\r\n    case 'uint8':\r\n      return Uint8Array;\r\n    case 'int8':\r\n      return Int8Array;\r\n    case 'uint16':\r\n      return Uint16Array;\r\n    case 'int16':\r\n      return Int16Array;\r\n    case 'int32':\r\n      return Int32Array;\r\n    case 'bool':\r\n      return Uint8Array;\r\n    case 'float64':\r\n      return Float64Array;\r\n    case 'uint32':\r\n      return Uint32Array;\r\n    case 'int64':\r\n      return BigInt64Array;\r\n    case 'uint64':\r\n      return BigUint64Array;\r\n    default:\r\n      throw new Error(`unsupported type: ${type}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map string log level to integer value\r\n */\r\nexport const logLevelStringToEnum = (logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal'): number => {\r\n  switch (logLevel) {\r\n    case 'verbose':\r\n      return 0;\r\n    case 'info':\r\n      return 1;\r\n    case 'warning':\r\n      return 2;\r\n    case 'error':\r\n      return 3;\r\n    case 'fatal':\r\n      return 4;\r\n    default:\r\n      throw new Error(`unsupported logging level: ${logLevel}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Check whether the given tensor type is supported by GPU buffer\r\n */\r\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes =>\r\n  type === 'float32' ||\r\n  type === 'float16' ||\r\n  type === 'int32' ||\r\n  type === 'int64' ||\r\n  type === 'uint32' ||\r\n  type === 'uint8' ||\r\n  type === 'bool' ||\r\n  type === 'uint4' ||\r\n  type === 'int4';\r\n\r\n/**\r\n * Check whether the given tensor type is supported by WebNN MLTensor\r\n */\r\nexport const isMLTensorSupportedType = (type: Tensor.Type): type is Tensor.MLTensorDataTypes =>\r\n  type === 'float32' ||\r\n  type === 'float16' ||\r\n  type === 'int32' ||\r\n  type === 'int64' ||\r\n  type === 'uint32' ||\r\n  type === 'uint64' ||\r\n  type === 'int8' ||\r\n  type === 'uint8' ||\r\n  type === 'bool' ||\r\n  type === 'uint4' ||\r\n  type === 'int4';\r\n\r\n/**\r\n * Map string data location to integer value\r\n */\r\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\r\n  switch (location) {\r\n    case 'none':\r\n      return 0;\r\n    case 'cpu':\r\n      return 1;\r\n    case 'cpu-pinned':\r\n      return 2;\r\n    case 'texture':\r\n      return 3;\r\n    case 'gpu-buffer':\r\n      return 4;\r\n    case 'ml-tensor':\r\n      return 5;\r\n    default:\r\n      throw new Error(`unsupported data location: ${location}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map integer data location to string value\r\n */\r\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation | undefined =>\r\n  (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer', 'ml-tensor'] as const)[location];\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { isNode } from './wasm-utils-env';\r\n\r\n/**\r\n * Load a file into a Uint8Array.\r\n *\r\n * @param file - the file to load. Can be a URL/path, a Blob, an ArrayBuffer, or a Uint8Array.\r\n * @returns a Uint8Array containing the file data.\r\n */\r\nexport const loadFile = async (file: string | Blob | ArrayBufferLike | Uint8Array): Promise<Uint8Array> => {\r\n  if (typeof file === 'string') {\r\n    if (isNode) {\r\n      // load file into ArrayBuffer in Node.js\r\n      try {\r\n        const { readFile } = require('node:fs/promises');\r\n        return new Uint8Array(await readFile(file));\r\n      } catch (e) {\r\n        if (e.code === 'ERR_FS_FILE_TOO_LARGE') {\r\n          // file is too large, use fs.createReadStream instead\r\n          const { createReadStream } = require('node:fs');\r\n          const stream = createReadStream(file);\r\n          const chunks: Uint8Array[] = [];\r\n          for await (const chunk of stream) {\r\n            chunks.push(chunk);\r\n          }\r\n          return new Uint8Array(Buffer.concat(chunks));\r\n        }\r\n        throw e;\r\n      }\r\n    } else {\r\n      // load file into ArrayBuffer in browsers\r\n      const response = await fetch(file);\r\n      if (!response.ok) {\r\n        throw new Error(`failed to load external data file: ${file}`);\r\n      }\r\n      const contentLengthHeader = response.headers.get('Content-Length');\r\n      const fileSize = contentLengthHeader ? parseInt(contentLengthHeader, 10) : 0;\r\n      if (fileSize < 1073741824 /* 1GB */) {\r\n        // when Content-Length header is not set, we cannot determine the file size. We assume it is small enough to\r\n        // load into memory.\r\n        return new Uint8Array(await response.arrayBuffer());\r\n      } else {\r\n        // file is too large, use stream instead\r\n        if (!response.body) {\r\n          throw new Error(`failed to load external data file: ${file}, no response body.`);\r\n        }\r\n        const reader = response.body.getReader();\r\n\r\n        let buffer;\r\n        try {\r\n          // try to create ArrayBuffer directly\r\n          buffer = new ArrayBuffer(fileSize);\r\n        } catch (e) {\r\n          if (e instanceof RangeError) {\r\n            // use WebAssembly Memory to allocate larger ArrayBuffer\r\n            const pages = Math.ceil(fileSize / 65536);\r\n            buffer = new WebAssembly.Memory({ initial: pages, maximum: pages }).buffer;\r\n          } else {\r\n            throw e;\r\n          }\r\n        }\r\n\r\n        let offset = 0;\r\n        // eslint-disable-next-line no-constant-condition\r\n        while (true) {\r\n          const { done, value } = await reader.read();\r\n          if (done) {\r\n            break;\r\n          }\r\n          const chunkSize = value.byteLength;\r\n          const chunk = new Uint8Array(buffer, offset, chunkSize);\r\n          chunk.set(value);\r\n          offset += chunkSize;\r\n        }\r\n        return new Uint8Array(buffer, 0, fileSize);\r\n      }\r\n    }\r\n  } else if (file instanceof Blob) {\r\n    return new Uint8Array(await file.arrayBuffer());\r\n  } else if (file instanceof Uint8Array) {\r\n    return file;\r\n  } else {\r\n    return new Uint8Array(file);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\r\n// WebNN API specification.\r\n// https://github.com/webmachinelearning/webnn/issues/677\r\n/// <reference path=\"jsep/webnn/webnn.d.ts\" />\r\n\r\nimport { Env, InferenceSession, Tensor, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from 'onnxruntime-common';\r\n\r\nimport {\r\n  SerializableInternalBuffer,\r\n  SerializableSessionMetadata,\r\n  SerializableTensorMetadata,\r\n  TensorMetadata,\r\n} from './proxy-messages';\r\nimport { setRunOptions } from './run-options';\r\nimport { setSessionOptions } from './session-options';\r\nimport {\r\n  calculateTensorSizeInBytes,\r\n  dataLocationStringToEnum,\r\n  isGpuBufferSupportedType,\r\n  isMLTensorSupportedType,\r\n  logLevelStringToEnum,\r\n  tensorDataTypeEnumToString,\r\n  tensorDataTypeStringToEnum,\r\n  tensorTypeToTypedArrayConstructor,\r\n} from './wasm-common';\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError } from './wasm-utils';\r\nimport { loadFile } from './wasm-utils-load-file';\r\n\r\n// #region Initializations\r\n\r\n/**\r\n * There are 4 different \"initialization\" steps for ORT. They happen in different places and different time.\r\n *\r\n * 1. JavaScript initialization for onnxruntime-common and onnxruntime-web.\r\n *    This is the first initialization step. In this step, onnxruntime-web calls onnxruntime-common's registerBackend()\r\n * function multiple times to register all the available backends. The backend registration is very fast. It only\r\n * registers the backend name with the uninitialized backend object. No heavy initialization is done in this step.\r\n *    Refer to web/lib/index.ts for the backend registration.\r\n *\r\n * 2. WebAssembly artifact initialization.\r\n *    This happens when any registered wasm backend is used for the first time (ie. `ort.InferenceSession.create()` is\r\n * called). In this step, onnxruntime-web does the followings:\r\n *     - create a proxy worker and make sure the proxy worker is ready to receive messages, if proxy is enabled.\r\n *     - perform feature detection, locate correct WebAssembly artifact path and call the Emscripten generated\r\n * JavaScript code to initialize the WebAssembly runtime.\r\n *         - if proxy is enabled, this step happens in the proxy worker using message 'init-wasm'.\r\n *         - downloading the 'ort-wasm{...}.wasm' file is done in this step.\r\n *         - if multi-thread is enabled, one or more webworker will be created to initialize the PThread threadpool.\r\n *\r\n * 3. ORT environment initialization.\r\n *    This happens after step 2. In this step, onnxruntime-web performs ONNX Runtime environment initialization.\r\n * Function `_OrtInit()` is called in this step.\r\n *     - if proxy is enabled, this step happens in the proxy worker using message 'init-ort'.\r\n *     - logging level (ort.env.logLevel) and thread number (ort.env.wasm.numThreads) are set in this step.\r\n *\r\n * 4. Session initialization.\r\n *    This happens when `ort.InferenceSession.create()` is called. Unlike the first 3 steps (they only called once),\r\n * this step will be done for each session. In this step, onnxruntime-web does the followings:\r\n *    If the parameter is a URL:\r\n *    - download the model data from the URL.\r\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\r\n *    - dereference the model buffer. This step allows the original ArrayBuffer to be garbage collected.\r\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\r\n *\r\n *    If the parameter is a Uint8Array object:\r\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\r\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\r\n *\r\n *\r\n */\r\n\r\n/**\r\n * initialize ORT environment.\r\n *\r\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\r\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\r\n */\r\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\r\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\r\n  if (errorCode !== 0) {\r\n    checkLastError(\"Can't initialize onnxruntime.\");\r\n  }\r\n};\r\n\r\n/**\r\n * initialize runtime environment.\r\n * @param env passed in the environment config object.\r\n */\r\nexport const initRuntime = async (env: Env): Promise<void> => {\r\n  // init ORT\r\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\r\n};\r\n\r\n/**\r\n * perform EP specific initialization.\r\n *\r\n * @param env\r\n * @param epName\r\n */\r\nexport const initEp = async (env: Env, epName: string): Promise<void> => {\r\n  // initialize ASYNCIFY support\r\n  getInstance().asyncInit?.();\r\n\r\n  // perform WebGPU availability check ( either JSEP or WebGPU EP )\r\n  let webgpuAdapter = env.webgpu.adapter as GPUAdapter | null;\r\n  if (epName === 'webgpu') {\r\n    if (typeof navigator === 'undefined' || !navigator.gpu) {\r\n      throw new Error('WebGPU is not supported in current environment');\r\n    }\r\n    if (!webgpuAdapter) {\r\n      // if adapter is not set, request a new adapter.\r\n      const powerPreference = env.webgpu.powerPreference;\r\n      if (powerPreference !== undefined && powerPreference !== 'low-power' && powerPreference !== 'high-performance') {\r\n        throw new Error(`Invalid powerPreference setting: \"${powerPreference}\"`);\r\n      }\r\n      const forceFallbackAdapter = env.webgpu.forceFallbackAdapter;\r\n      if (forceFallbackAdapter !== undefined && typeof forceFallbackAdapter !== 'boolean') {\r\n        throw new Error(`Invalid forceFallbackAdapter setting: \"${forceFallbackAdapter}\"`);\r\n      }\r\n      webgpuAdapter = await navigator.gpu.requestAdapter({ powerPreference, forceFallbackAdapter });\r\n      if (!webgpuAdapter) {\r\n        throw new Error(\r\n          'Failed to get GPU adapter. ' +\r\n            'You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.',\r\n        );\r\n      }\r\n    } else {\r\n      // if adapter is set, validate it.\r\n      if (\r\n        typeof webgpuAdapter.limits !== 'object' ||\r\n        typeof webgpuAdapter.features !== 'object' ||\r\n        typeof webgpuAdapter.requestDevice !== 'function'\r\n      ) {\r\n        throw new Error('Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.');\r\n      }\r\n    }\r\n  }\r\n\r\n  // perform WebNN availability check ( either JSEP or WebNN EP )\r\n  if (epName === 'webnn') {\r\n    if (typeof navigator === 'undefined' || !(navigator as unknown as { ml: unknown }).ml) {\r\n      throw new Error('WebNN is not supported in current environment');\r\n    }\r\n  }\r\n\r\n  if (!BUILD_DEFS.DISABLE_JSEP) {\r\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n    const initJsep = require('./jsep/init').init;\r\n\r\n    if (epName === 'webgpu') {\r\n      await initJsep('webgpu', getInstance(), env, webgpuAdapter);\r\n    }\r\n    if (epName === 'webnn') {\r\n      await initJsep('webnn', getInstance(), env);\r\n    }\r\n  } else {\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU && epName === 'webgpu') {\r\n      getInstance().webgpuInit!((device) => {\r\n        env.webgpu.device = device;\r\n      });\r\n    }\r\n    if (!BUILD_DEFS.DISABLE_WEBNN && epName === 'webnn') {\r\n      // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n      const backend = new (require('./jsep/backend-webnn').WebNNBackend)(env);\r\n      getInstance().webnnInit!([\r\n        backend,\r\n        // webnnReserveTensorId\r\n        () => backend.reserveTensorId(),\r\n        // webnnReleaseTensorId,\r\n        (tensorId: number) => backend.releaseTensorId(tensorId),\r\n        // webnnEnsureTensor\r\n        async (sessionId: number | undefined, tensorId: number, onnxDataType: number, shape: number[], copyOld) =>\r\n          backend.ensureTensor(sessionId, tensorId, onnxDataType, shape, copyOld),\r\n        // webnnUploadTensor\r\n        (tensorId: number, data: Uint8Array) => {\r\n          backend.uploadTensor(tensorId, data);\r\n        },\r\n        // webnnDownloadTensor\r\n        async (tensorId: number, dstBuffer: ArrayBufferView | ArrayBuffer) =>\r\n          backend.downloadTensor(tensorId, dstBuffer),\r\n        // webnnRegisterMLContext\r\n        (sessionId: number, mlContext: MLContext) => backend.registerMLContext(sessionId, mlContext),\r\n        // webnnEnableTraceEvent\r\n        !!env.trace,\r\n      ]);\r\n    }\r\n  }\r\n};\r\n\r\n// #endregion Initializations\r\n\r\n/**\r\n * valid data locations for input/output tensors.\r\n */\r\ntype SupportedTensorDataLocationForInputOutput =\r\n  | 'cpu'\r\n  | 'cpu-pinned'\r\n  | 'gpu-buffer'\r\n  | 'ml-tensor'\r\n  // Use 'ml-tensor' during inference, but output a tensor located on the CPU.\r\n  | 'ml-tensor-cpu-output';\r\n\r\ntype IOBindingState = {\r\n  /**\r\n   * the handle of IO binding.\r\n   */\r\n  readonly handle: number;\r\n\r\n  /**\r\n   * the preferred location for each output tensor.\r\n   *\r\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer', 'ml-tensor'.\r\n   */\r\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\r\n\r\n  /**\r\n   * enum value of the preferred location for each output tensor.\r\n   */\r\n  readonly outputPreferredLocationsEncoded: readonly number[];\r\n};\r\n\r\n/**\r\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\r\n */\r\ntype SessionMetadata = [\r\n  inferenceSessionId: number,\r\n  inputNamesUTF8Encoded: number[],\r\n  outputNamesUTF8Encoded: number[],\r\n  bindingState: IOBindingState | null,\r\n  enableGraphCapture: boolean,\r\n  inputOutputBound: boolean,\r\n];\r\n\r\nconst activeSessions = new Map<number, SessionMetadata>();\r\n\r\n/**\r\n * get the input/output count of the session.\r\n * @param sessionHandle the handle representing the session. should be non-zero.\r\n * @returns a tuple including 2 numbers, representing the input count and output count.\r\n */\r\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\r\n  const wasm = getInstance();\r\n  const stack = wasm.stackSave();\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\r\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + ptrSize);\r\n    if (errorCode !== 0) {\r\n      checkLastError(\"Can't get session input/output count.\");\r\n    }\r\n    const type = ptrSize === 4 ? 'i32' : 'i64';\r\n    return [Number(wasm.getValue(dataOffset, type)), Number(wasm.getValue(dataOffset + ptrSize, type))];\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n\r\nconst getSessionInputOutputMetadata = (\r\n  sessionHandle: number,\r\n  index: number,\r\n): [nameOffset: number, elementType: number, dims?: Array<number | string>] => {\r\n  const wasm = getInstance();\r\n  const stack = wasm.stackSave();\r\n  let metadataOffset = 0;\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\r\n    const errorCode = wasm._OrtGetInputOutputMetadata(sessionHandle, index, dataOffset, dataOffset + ptrSize);\r\n    if (errorCode !== 0) {\r\n      checkLastError(\"Can't get session input/output metadata.\");\r\n    }\r\n    const nameOffset = Number(wasm.getValue(dataOffset, '*'));\r\n    metadataOffset = Number(wasm.getValue(dataOffset + ptrSize, '*'));\r\n    // get element type\r\n    const elementType = wasm.HEAP32[metadataOffset / 4];\r\n    if (elementType === 0) {\r\n      return [nameOffset, 0]; // non-tensor\r\n    }\r\n\r\n    // get dims count\r\n    const dimsCount = wasm.HEAPU32[metadataOffset / 4 + 1];\r\n    // get dims\r\n    const dims: Array<number | string> = [];\r\n    for (let i = 0; i < dimsCount; i++) {\r\n      const symbolicDimNameOffset = Number(wasm.getValue(metadataOffset + 8 + i * ptrSize, '*'));\r\n      dims.push(\r\n        symbolicDimNameOffset !== 0\r\n          ? wasm.UTF8ToString(symbolicDimNameOffset)\r\n          : Number(wasm.getValue(metadataOffset + 8 + (i + dimsCount) * ptrSize, '*')),\r\n      );\r\n    }\r\n    return [nameOffset, elementType, dims];\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n    if (metadataOffset !== 0) {\r\n      wasm._OrtFree(metadataOffset);\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * allocate the memory and memcpy the external buffer.\r\n *\r\n * @param model - the external buffer containing the model data. Must not be the same buffer as the WASM heap.\r\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\r\n */\r\nexport const copyFromExternalBuffer = (model: Uint8Array): [number, number] => {\r\n  const wasm = getInstance();\r\n  const modelDataOffset = wasm._malloc(model.byteLength);\r\n  if (modelDataOffset === 0) {\r\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\r\n  }\r\n  wasm.HEAPU8.set(model, modelDataOffset);\r\n  return [modelDataOffset, model.byteLength];\r\n};\r\n\r\n/**\r\n * create an inference session from a model data buffer.\r\n *\r\n * @param modelData - either a Uint8Array object representing the model data, or a 2-elements tuple containing the\r\n *     pointer and size of the model data buffer.\r\n * @param options an optional session options object.\r\n * @returns a 3-elements tuple containing [session handle, input names, output names]\r\n */\r\nexport const createSession = async (\r\n  modelData: Uint8Array | SerializableInternalBuffer,\r\n  options?: InferenceSession.SessionOptions,\r\n): Promise<SerializableSessionMetadata> => {\r\n  let modelDataOffset: number, modelDataLength: number;\r\n  const wasm = getInstance();\r\n\r\n  if (Array.isArray(modelData)) {\r\n    // if model data is an array, it must be a 2-elements tuple containing the pointer and size of the model data\r\n    [modelDataOffset, modelDataLength] = modelData;\r\n  } else if (modelData.buffer === wasm.HEAPU8.buffer) {\r\n    // if model data uses the same buffer as the WASM heap, we don't need to copy it.\r\n    [modelDataOffset, modelDataLength] = [modelData.byteOffset, modelData.byteLength];\r\n  } else {\r\n    // otherwise, copy the model data to the WASM heap.\r\n    [modelDataOffset, modelDataLength] = copyFromExternalBuffer(modelData);\r\n  }\r\n\r\n  let sessionHandle = 0;\r\n  let sessionOptionsHandle = 0;\r\n  let ioBindingHandle = 0;\r\n  let allocs: number[] = [];\r\n  const inputNamesUTF8Encoded = [];\r\n  const outputNamesUTF8Encoded = [];\r\n\r\n  try {\r\n    [sessionOptionsHandle, allocs] = await setSessionOptions(options);\r\n\r\n    if (options?.externalData && wasm.mountExternalData) {\r\n      const loadingPromises = [];\r\n      for (const file of options.externalData) {\r\n        const path = typeof file === 'string' ? file : file.path;\r\n        loadingPromises.push(\r\n          loadFile(typeof file === 'string' ? file : file.data).then((data) => {\r\n            wasm.mountExternalData(path, data);\r\n          }),\r\n        );\r\n      }\r\n\r\n      // wait for all external data files to be loaded\r\n      await Promise.all(loadingPromises);\r\n    }\r\n\r\n    for (const provider of options?.executionProviders ?? []) {\r\n      const providerName = typeof provider === 'string' ? provider : provider.name;\r\n      if (providerName === 'webnn') {\r\n        wasm.shouldTransferToMLTensor = false;\r\n        if (typeof provider !== 'string') {\r\n          const webnnOptions = provider as InferenceSession.WebNNExecutionProviderOption;\r\n          const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\r\n          const gpuDevice = (webnnOptions as InferenceSession.WebNNOptionsWebGpu)?.gpuDevice;\r\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\r\n          const powerPreference = (webnnOptions as InferenceSession.WebNNContextOptions)?.powerPreference;\r\n          if (context) {\r\n            wasm.currentContext = context as MLContext;\r\n          } else if (gpuDevice) {\r\n            wasm.currentContext = await wasm.webnnCreateMLContext!(gpuDevice);\r\n          } else {\r\n            wasm.currentContext = await wasm.webnnCreateMLContext!({ deviceType, powerPreference });\r\n          }\r\n        } else {\r\n          wasm.currentContext = await wasm.webnnCreateMLContext!();\r\n        }\r\n        break;\r\n      }\r\n    }\r\n\r\n    sessionHandle = await wasm._OrtCreateSession(modelDataOffset, modelDataLength, sessionOptionsHandle);\r\n    wasm.webgpuOnCreateSession?.(sessionHandle);\r\n    if (sessionHandle === 0) {\r\n      checkLastError(\"Can't create a session.\");\r\n    }\r\n\r\n    wasm.jsepOnCreateSession?.();\r\n\r\n    // clear current MLContext after session creation\r\n    if (wasm.currentContext) {\r\n      wasm.webnnRegisterMLContext!(sessionHandle, wasm.currentContext);\r\n      wasm.currentContext = undefined;\r\n      wasm.shouldTransferToMLTensor = true;\r\n    }\r\n\r\n    const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\r\n\r\n    const enableGraphCapture = !!options?.enableGraphCapture;\r\n\r\n    const inputNames = [];\r\n    const outputNames = [];\r\n    const inputMetadata: InferenceSession.ValueMetadata[] = [];\r\n    const outputMetadata: InferenceSession.ValueMetadata[] = [];\r\n    const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\r\n    for (let i = 0; i < inputCount; i++) {\r\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i);\r\n      if (nameOffset === 0) {\r\n        checkLastError(\"Can't get an input name.\");\r\n      }\r\n      inputNamesUTF8Encoded.push(nameOffset);\r\n      const name = wasm.UTF8ToString(nameOffset);\r\n      inputNames.push(name);\r\n      inputMetadata.push(\r\n        elementType === 0\r\n          ? { name, isTensor: false }\r\n          : { name, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\r\n      );\r\n    }\r\n    for (let i = 0; i < outputCount; i++) {\r\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i + inputCount);\r\n      if (nameOffset === 0) {\r\n        checkLastError(\"Can't get an output name.\");\r\n      }\r\n      outputNamesUTF8Encoded.push(nameOffset);\r\n      const nameString = wasm.UTF8ToString(nameOffset);\r\n      outputNames.push(nameString);\r\n      outputMetadata.push(\r\n        elementType === 0\r\n          ? { name: nameString, isTensor: false }\r\n          : { name: nameString, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\r\n      );\r\n\r\n      if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\r\n        if (enableGraphCapture && options?.preferredOutputLocation === undefined) {\r\n          outputPreferredLocations.push('gpu-buffer');\r\n          continue;\r\n        }\r\n        const location =\r\n          typeof options?.preferredOutputLocation === 'string'\r\n            ? options.preferredOutputLocation\r\n            : (options?.preferredOutputLocation?.[nameString] ?? 'cpu');\r\n        const isGraphOutput = wasm.webnnIsGraphOutput;\r\n        if (location === 'cpu' && isGraphOutput && isGraphOutput(sessionHandle, nameString)) {\r\n          outputPreferredLocations.push('ml-tensor-cpu-output');\r\n          continue;\r\n        }\r\n        if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer' && location !== 'ml-tensor') {\r\n          throw new Error(`Not supported preferred output location: ${location}.`);\r\n        }\r\n        if (enableGraphCapture && location !== 'gpu-buffer') {\r\n          throw new Error(\r\n            `Not supported preferred output location: ${location}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`,\r\n          );\r\n        }\r\n        outputPreferredLocations.push(location);\r\n      }\r\n    }\r\n\r\n    // use IO binding only when at least one output is preferred to be on GPU.\r\n    let bindingState: IOBindingState | null = null;\r\n    if (\r\n      (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) &&\r\n      outputPreferredLocations.some((l) => l === 'gpu-buffer' || l === 'ml-tensor' || l === 'ml-tensor-cpu-output')\r\n    ) {\r\n      ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\r\n      if (ioBindingHandle === 0) {\r\n        checkLastError(\"Can't create IO binding.\");\r\n      }\r\n\r\n      bindingState = {\r\n        handle: ioBindingHandle,\r\n        outputPreferredLocations,\r\n        outputPreferredLocationsEncoded: outputPreferredLocations\r\n          // 'ml-tensor-cpu-output' is treated as 'ml-tensor' for the purpose of IO binding.\r\n          .map((l) => (l === 'ml-tensor-cpu-output' ? 'ml-tensor' : l))\r\n          .map((l) => dataLocationStringToEnum(l)),\r\n      };\r\n    }\r\n\r\n    activeSessions.set(sessionHandle, [\r\n      sessionHandle,\r\n      inputNamesUTF8Encoded,\r\n      outputNamesUTF8Encoded,\r\n      bindingState,\r\n      enableGraphCapture,\r\n      false,\r\n    ]);\r\n    return [sessionHandle, inputNames, outputNames, inputMetadata, outputMetadata];\r\n  } catch (e) {\r\n    inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n    outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n\r\n    if (ioBindingHandle !== 0) {\r\n      if (wasm._OrtReleaseBinding(ioBindingHandle) !== 0) {\r\n        checkLastError(\"Can't release IO binding.\");\r\n      }\r\n    }\r\n\r\n    if (sessionHandle !== 0) {\r\n      if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\r\n        checkLastError(\"Can't release session.\");\r\n      }\r\n    }\r\n    throw e;\r\n  } finally {\r\n    wasm._free(modelDataOffset);\r\n    if (sessionOptionsHandle !== 0) {\r\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\r\n        checkLastError(\"Can't release session options.\");\r\n      }\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n\r\n    // unmount external data if necessary\r\n    wasm.unmountExternalData?.();\r\n  }\r\n};\r\n\r\nexport const releaseSession = (sessionId: number): void => {\r\n  const wasm = getInstance();\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\r\n  }\r\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState, enableGraphCapture] = session;\r\n\r\n  if (ioBindingState) {\r\n    if (enableGraphCapture) {\r\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\r\n        checkLastError(\"Can't clear bound outputs.\");\r\n      }\r\n    }\r\n    if (wasm._OrtReleaseBinding(ioBindingState.handle) !== 0) {\r\n      checkLastError(\"Can't release IO binding.\");\r\n    }\r\n  }\r\n\r\n  wasm.jsepOnReleaseSession?.(sessionId);\r\n  wasm.webnnOnReleaseSession?.(sessionId);\r\n  wasm.webgpuOnReleaseSession?.(sessionId);\r\n\r\n  inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n  outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n  if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\r\n    checkLastError(\"Can't release session.\");\r\n  }\r\n  activeSessions.delete(sessionId);\r\n};\r\n\r\nexport const prepareInputOutputTensor = async (\r\n  tensor: TensorMetadata | null,\r\n  tensorHandles: number[],\r\n  allocs: number[],\r\n  sessionId: number,\r\n  tensorNameUTF8Encoded: number,\r\n  index: number,\r\n  enableGraphCapture = false,\r\n): Promise<void> => {\r\n  if (!tensor) {\r\n    tensorHandles.push(0);\r\n    return;\r\n  }\r\n\r\n  const wasm = getInstance();\r\n  const ptrSize = wasm.PTR_SIZE;\r\n\r\n  const dataType = tensor[0];\r\n  const dims = tensor[1];\r\n  const location = tensor[3];\r\n  let actualLocation = location;\r\n\r\n  let rawData: number;\r\n  let dataByteLength: number;\r\n\r\n  if (dataType === 'string' && (location === 'gpu-buffer' || location === 'ml-tensor')) {\r\n    throw new Error('String tensor is not supported on GPU.');\r\n  }\r\n\r\n  if (enableGraphCapture && location !== 'gpu-buffer') {\r\n    throw new Error(\r\n      `External buffer must be provided for input/output index ${index} when enableGraphCapture is true.`,\r\n    );\r\n  }\r\n\r\n  if (location === 'gpu-buffer') {\r\n    const gpuBuffer = tensor[2].gpuBuffer;\r\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\r\n\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n      const registerBuffer = wasm.webgpuRegisterBuffer;\r\n      if (!registerBuffer) {\r\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\r\n      }\r\n\r\n      rawData = registerBuffer(gpuBuffer, sessionId);\r\n    } else {\r\n      const registerBuffer = wasm.jsepRegisterBuffer;\r\n      if (!registerBuffer) {\r\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\r\n      }\r\n      rawData = registerBuffer(sessionId, index, gpuBuffer, dataByteLength);\r\n    }\r\n  } else if (location === 'ml-tensor') {\r\n    const mlTensor = tensor[2].mlTensor as MLTensor;\r\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\r\n\r\n    const registerMLTensor = wasm.webnnRegisterMLTensor;\r\n    if (!registerMLTensor) {\r\n      throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\r\n    }\r\n    rawData = registerMLTensor(sessionId, mlTensor, tensorDataTypeStringToEnum(dataType), dims);\r\n  } else {\r\n    const data = tensor[2];\r\n\r\n    if (Array.isArray(data)) {\r\n      // string tensor\r\n      dataByteLength = ptrSize * data.length;\r\n      rawData = wasm._malloc(dataByteLength);\r\n      allocs.push(rawData);\r\n      for (let i = 0; i < data.length; i++) {\r\n        if (typeof data[i] !== 'string') {\r\n          throw new TypeError(`tensor data at index ${i} is not a string`);\r\n        }\r\n        wasm.setValue(rawData + i * ptrSize, allocWasmString(data[i], allocs), '*');\r\n      }\r\n    } else {\r\n      const isGraphInput = wasm.webnnIsGraphInput;\r\n      const isGraphOutput = wasm.webnnIsGraphOutput;\r\n      if (dataType !== 'string' && isGraphInput && isGraphOutput) {\r\n        const tensorName = wasm.UTF8ToString(tensorNameUTF8Encoded);\r\n        // Promote the tensor to 'ml-tensor' if it is a graph input.\r\n        if (isGraphInput(sessionId, tensorName) || isGraphOutput(sessionId, tensorName)) {\r\n          const dataTypeEnum = tensorDataTypeStringToEnum(dataType);\r\n          dataByteLength = calculateTensorSizeInBytes(dataTypeEnum, dims)!;\r\n          actualLocation = 'ml-tensor';\r\n          const createTemporaryTensor = wasm.webnnCreateTemporaryTensor;\r\n          const uploadTensor = wasm.webnnUploadTensor;\r\n          if (!createTemporaryTensor || !uploadTensor) {\r\n            throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\r\n          }\r\n          const tensorId = await createTemporaryTensor(sessionId, dataTypeEnum, dims as number[]);\r\n          uploadTensor(tensorId, new Uint8Array(data.buffer, data.byteOffset, data.byteLength));\r\n          rawData = tensorId;\r\n        } else {\r\n          dataByteLength = data.byteLength;\r\n          rawData = wasm._malloc(dataByteLength);\r\n          allocs.push(rawData);\r\n          wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\r\n        }\r\n      } else {\r\n        dataByteLength = data.byteLength;\r\n        rawData = wasm._malloc(dataByteLength);\r\n        allocs.push(rawData);\r\n        wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\r\n      }\r\n    }\r\n  }\r\n\r\n  const stack = wasm.stackSave();\r\n  const dimsOffset = wasm.stackAlloc(4 * dims.length);\r\n  try {\r\n    dims.forEach((d, index) => wasm.setValue(dimsOffset + index * ptrSize, d, ptrSize === 4 ? 'i32' : 'i64'));\r\n    const tensor = wasm._OrtCreateTensor(\r\n      tensorDataTypeStringToEnum(dataType),\r\n      rawData,\r\n      dataByteLength,\r\n      dimsOffset,\r\n      dims.length,\r\n      dataLocationStringToEnum(actualLocation),\r\n    );\r\n    if (tensor === 0) {\r\n      checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\r\n    }\r\n    tensorHandles.push(tensor);\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n\r\n/**\r\n * perform inference run\r\n */\r\nexport const run = async (\r\n  sessionId: number,\r\n  inputIndices: number[],\r\n  inputTensors: TensorMetadata[],\r\n  outputIndices: number[],\r\n  outputTensors: Array<TensorMetadata | null>,\r\n  options: InferenceSession.RunOptions,\r\n): Promise<TensorMetadata[]> => {\r\n  const wasm = getInstance();\r\n  const ptrSize = wasm.PTR_SIZE;\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\r\n  }\r\n  const sessionHandle = session[0];\r\n  const inputNamesUTF8Encoded = session[1];\r\n  const outputNamesUTF8Encoded = session[2];\r\n  const ioBindingState = session[3];\r\n  const enableGraphCapture = session[4];\r\n  const inputOutputBound = session[5];\r\n\r\n  const inputCount = inputIndices.length;\r\n  const outputCount = outputIndices.length;\r\n\r\n  let runOptionsHandle = 0;\r\n  let runOptionsAllocs: number[] = [];\r\n\r\n  const inputTensorHandles: number[] = [];\r\n  const outputTensorHandles: number[] = [];\r\n  const inputOutputAllocs: number[] = [];\r\n  const preAllocatedOutputs: number[] = [];\r\n\r\n  const beforeRunStack = wasm.stackSave();\r\n  const inputValuesOffset = wasm.stackAlloc(inputCount * ptrSize);\r\n  const inputNamesOffset = wasm.stackAlloc(inputCount * ptrSize);\r\n  const outputValuesOffset = wasm.stackAlloc(outputCount * ptrSize);\r\n  const outputNamesOffset = wasm.stackAlloc(outputCount * ptrSize);\r\n\r\n  try {\r\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\r\n\r\n    TRACE_EVENT_BEGIN('wasm prepareInputOutputTensor');\r\n    // create input tensors\r\n    for (let i = 0; i < inputCount; i++) {\r\n      await prepareInputOutputTensor(\r\n        inputTensors[i],\r\n        inputTensorHandles,\r\n        inputOutputAllocs,\r\n        sessionId,\r\n        inputNamesUTF8Encoded[inputIndices[i]],\r\n        inputIndices[i],\r\n        enableGraphCapture,\r\n      );\r\n    }\r\n\r\n    // create output tensors\r\n    for (let i = 0; i < outputCount; i++) {\r\n      await prepareInputOutputTensor(\r\n        outputTensors[i],\r\n        outputTensorHandles,\r\n        inputOutputAllocs,\r\n        sessionId,\r\n        outputNamesUTF8Encoded[outputIndices[i]],\r\n        inputCount + outputIndices[i],\r\n        enableGraphCapture,\r\n      );\r\n    }\r\n    TRACE_EVENT_END('wasm prepareInputOutputTensor');\r\n\r\n    for (let i = 0; i < inputCount; i++) {\r\n      wasm.setValue(inputValuesOffset + i * ptrSize, inputTensorHandles[i], '*');\r\n      wasm.setValue(inputNamesOffset + i * ptrSize, inputNamesUTF8Encoded[inputIndices[i]], '*');\r\n    }\r\n    for (let i = 0; i < outputCount; i++) {\r\n      wasm.setValue(outputValuesOffset + i * ptrSize, outputTensorHandles[i], '*');\r\n      wasm.setValue(outputNamesOffset + i * ptrSize, outputNamesUTF8Encoded[outputIndices[i]], '*');\r\n    }\r\n\r\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState && !inputOutputBound) {\r\n      const { handle, outputPreferredLocations, outputPreferredLocationsEncoded } = ioBindingState;\r\n\r\n      if (inputNamesUTF8Encoded.length !== inputCount) {\r\n        throw new Error(\r\n          `input count from feeds (${inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`,\r\n        );\r\n      }\r\n\r\n      TRACE_EVENT_BEGIN('wasm bindInputsOutputs');\r\n      // process inputs\r\n      for (let i = 0; i < inputCount; i++) {\r\n        const index = inputIndices[i];\r\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\r\n        if (errorCode !== 0) {\r\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\r\n        }\r\n      }\r\n\r\n      // process pre-allocated outputs\r\n      for (let i = 0; i < outputCount; i++) {\r\n        const index = outputIndices[i];\r\n        const location = outputTensors[i]?.[3]; // undefined means output is not pre-allocated.\r\n\r\n        if (location) {\r\n          // output is pre-allocated, store and bind the tensor.\r\n          preAllocatedOutputs.push(outputTensorHandles[i]);\r\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\r\n          if (errorCode !== 0) {\r\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\r\n          }\r\n        } else {\r\n          // output is not pre-allocated. reset preferred location.\r\n          const errorCode = wasm._OrtBindOutput(\r\n            handle,\r\n            outputNamesUTF8Encoded[index],\r\n            0,\r\n            outputPreferredLocationsEncoded[index],\r\n          );\r\n          if (errorCode !== 0) {\r\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\r\n          }\r\n        }\r\n      }\r\n      TRACE_EVENT_END('wasm bindInputsOutputs');\r\n      activeSessions.set(sessionId, [\r\n        sessionHandle,\r\n        inputNamesUTF8Encoded,\r\n        outputNamesUTF8Encoded,\r\n        ioBindingState,\r\n        enableGraphCapture,\r\n        true,\r\n      ]);\r\n    }\r\n\r\n    wasm.jsepOnRunStart?.(sessionHandle);\r\n    wasm.webnnOnRunStart?.(sessionHandle);\r\n\r\n    let errorCode: number;\r\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState) {\r\n      errorCode = await wasm._OrtRunWithBinding(\r\n        sessionHandle,\r\n        ioBindingState.handle,\r\n        outputCount,\r\n        outputValuesOffset,\r\n        runOptionsHandle,\r\n      );\r\n    } else {\r\n      errorCode = await wasm._OrtRun(\r\n        sessionHandle,\r\n        inputNamesOffset,\r\n        inputValuesOffset,\r\n        inputCount,\r\n        outputNamesOffset,\r\n        outputCount,\r\n        outputValuesOffset,\r\n        runOptionsHandle,\r\n      );\r\n    }\r\n\r\n    if (errorCode !== 0) {\r\n      checkLastError('failed to call OrtRun().');\r\n    }\r\n\r\n    const output: TensorMetadata[] = [];\r\n    const outputPromises: Array<Promise<[number, Tensor.DataType]>> = [];\r\n\r\n    TRACE_EVENT_BEGIN('wasm ProcessOutputTensor');\r\n    for (let i = 0; i < outputCount; i++) {\r\n      const tensor = Number(wasm.getValue(outputValuesOffset + i * ptrSize, '*'));\r\n      // TODO: revisit this part to ensure it works for WebGPU when both pre-allocated outputs and\r\n      // preferred location are specified.\r\n      // Certain pre-allocated tensors may already be bound in the IO binding. e.g. the WebNN backend\r\n      // always binds its tensor to 'ml-tensor'. In such cases, the tensor ID might change after binding,\r\n      // but copying data for these tensors should still be avoided.\r\n      if (tensor === outputTensorHandles[i] || preAllocatedOutputs.includes(outputTensorHandles[i])) {\r\n        // output tensor is pre-allocated. no need to copy data.\r\n        output.push(outputTensors[i]!);\r\n        if (tensor !== outputTensorHandles[i]) {\r\n          // release redundant tensor earlier.\r\n          if (wasm._OrtReleaseTensor(tensor) !== 0) {\r\n            checkLastError(\"Can't release tensor.\");\r\n          }\r\n        }\r\n        continue;\r\n      }\r\n\r\n      const beforeGetTensorDataStack = wasm.stackSave();\r\n      // stack allocate 4 pointer value\r\n      const tensorDataOffset = wasm.stackAlloc(4 * ptrSize);\r\n\r\n      let keepOutputTensor = false;\r\n      let type: Tensor.Type | undefined,\r\n        dataOffset = 0;\r\n      try {\r\n        const errorCode = wasm._OrtGetTensorData(\r\n          tensor,\r\n          tensorDataOffset,\r\n          tensorDataOffset + ptrSize,\r\n          tensorDataOffset + 2 * ptrSize,\r\n\r\n          tensorDataOffset + 3 * ptrSize,\r\n        );\r\n        if (errorCode !== 0) {\r\n          checkLastError(`Can't access output tensor data on index ${i}.`);\r\n        }\r\n        const valueType = ptrSize === 4 ? 'i32' : 'i64';\r\n        const dataType = Number(wasm.getValue(tensorDataOffset, valueType));\r\n        dataOffset = wasm.getValue(tensorDataOffset + ptrSize, '*');\r\n        const dimsOffset = wasm.getValue(tensorDataOffset + ptrSize * 2, '*');\r\n        const dimsLength = Number(wasm.getValue(tensorDataOffset + ptrSize * 3, valueType));\r\n        const dims = [];\r\n        for (let i = 0; i < dimsLength; i++) {\r\n          dims.push(Number(wasm.getValue(dimsOffset + i * ptrSize, valueType)));\r\n        }\r\n        if (wasm._OrtFree(dimsOffset) !== 0) {\r\n          checkLastError(\"Can't free memory for tensor dims.\");\r\n        }\r\n        const size = dims.reduce((a, b) => a * b, 1);\r\n        type = tensorDataTypeEnumToString(dataType);\r\n\r\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\r\n\r\n        if (type === 'string') {\r\n          if (preferredLocation === 'gpu-buffer' || preferredLocation === 'ml-tensor') {\r\n            throw new Error('String tensor is not supported on GPU.');\r\n          }\r\n          const stringData: string[] = [];\r\n          for (let i = 0; i < size; i++) {\r\n            const offset = wasm.getValue(dataOffset + i * ptrSize, '*');\r\n            const nextOffset = wasm.getValue(dataOffset + (i + 1) * ptrSize, '*');\r\n            const maxBytesToRead = i === size - 1 ? undefined : nextOffset - offset;\r\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\r\n          }\r\n          output.push([type, dims, stringData, 'cpu']);\r\n        } else {\r\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\r\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\r\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\r\n            const getBuffer = !BUILD_DEFS.DISABLE_WEBGPU ? wasm.webgpuGetBuffer : wasm.jsepGetBuffer;\r\n            if (!getBuffer) {\r\n              throw new Error('preferredLocation \"gpu-buffer\" is not supported without using WebGPU.');\r\n            }\r\n            const gpuBuffer = getBuffer(dataOffset);\r\n            const bufferSize = calculateTensorSizeInBytes(dataType, size);\r\n            if (bufferSize === undefined || !isGpuBufferSupportedType(type)) {\r\n              throw new Error(`Unsupported data type: ${type}`);\r\n            }\r\n\r\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\r\n            keepOutputTensor = true;\r\n\r\n            if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n              wasm.webgpuRegisterBuffer!(gpuBuffer, sessionId, dataOffset);\r\n              const downloadDataFunction = wasm.webgpuCreateDownloader!(gpuBuffer, bufferSize, sessionId);\r\n              output.push([\r\n                type,\r\n                dims,\r\n                {\r\n                  gpuBuffer,\r\n                  download: async () => {\r\n                    const arrayBuffer = await downloadDataFunction();\r\n                    const data = new (tensorTypeToTypedArrayConstructor(type!))(arrayBuffer);\r\n                    return data as Tensor.DataTypeMap[Tensor.GpuBufferDataTypes];\r\n                  },\r\n                  dispose: () => {\r\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\r\n                      checkLastError(\"Can't release tensor.\");\r\n                    }\r\n                  },\r\n                },\r\n                'gpu-buffer',\r\n              ]);\r\n            } else {\r\n              output.push([\r\n                type,\r\n                dims,\r\n                {\r\n                  gpuBuffer,\r\n                  download: wasm.jsepCreateDownloader!(gpuBuffer, bufferSize, type),\r\n                  dispose: () => {\r\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\r\n                      checkLastError(\"Can't release tensor.\");\r\n                    }\r\n                  },\r\n                },\r\n                'gpu-buffer',\r\n              ]);\r\n            }\r\n          } else if (preferredLocation === 'ml-tensor' && size > 0) {\r\n            const ensureTensor = wasm.webnnEnsureTensor;\r\n            const isGraphInputOutputTypeSupported = wasm.webnnIsGraphInputOutputTypeSupported;\r\n            if (!ensureTensor || !isGraphInputOutputTypeSupported) {\r\n              throw new Error('preferredLocation \"ml-tensor\" is not supported without using WebNN.');\r\n            }\r\n            const tensorSize = calculateTensorSizeInBytes(dataType, size);\r\n            if (tensorSize === undefined || !isMLTensorSupportedType(type)) {\r\n              throw new Error(`Unsupported data type: ${type}`);\r\n            }\r\n            if (!isGraphInputOutputTypeSupported(sessionId, type, false)) {\r\n              throw new Error(\r\n                `preferredLocation \"ml-tensor\" for ${type} output is not supported by current WebNN Context.`,\r\n              );\r\n            }\r\n\r\n            // If the graph has been partitioned, the output tensor may have not been created. For this reason, we use\r\n            // ensureTensor to get/create the MLTensor. In which case, we don't need to copy the data if a new tensor\r\n            // has been created.\r\n            const mlTensor = await ensureTensor(sessionId, dataOffset, dataType, dims, false);\r\n\r\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\r\n            keepOutputTensor = true;\r\n\r\n            output.push([\r\n              type,\r\n              dims,\r\n              {\r\n                mlTensor,\r\n                download: wasm.webnnCreateMLTensorDownloader!(dataOffset, type),\r\n                dispose: () => {\r\n                  wasm.webnnReleaseTensorId!(dataOffset);\r\n                  wasm._OrtReleaseTensor(tensor);\r\n                },\r\n              },\r\n              'ml-tensor',\r\n            ]);\r\n          } else if (preferredLocation === 'ml-tensor-cpu-output' && size > 0) {\r\n            const data = wasm.webnnCreateMLTensorDownloader!(dataOffset, type as Tensor.MLTensorDataTypes)();\r\n            const index = output.length;\r\n            // Delay the data download and releasing the tensor until we can wait for all output tensors to be downloaded.\r\n            keepOutputTensor = true;\r\n            outputPromises.push(\r\n              (async () => {\r\n                const result: [number, Tensor.DataType] = [index, await data];\r\n                wasm.webnnReleaseTensorId!(dataOffset);\r\n                wasm._OrtReleaseTensor(tensor);\r\n                return result;\r\n              })(),\r\n            );\r\n            output.push([type, dims, [], 'cpu']);\r\n          } else {\r\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\r\n            const data = new typedArrayConstructor(size);\r\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength).set(\r\n              wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength),\r\n            );\r\n            output.push([type, dims, data, 'cpu']);\r\n          }\r\n        }\r\n      } finally {\r\n        wasm.stackRestore(beforeGetTensorDataStack);\r\n        if (type === 'string' && dataOffset) {\r\n          wasm._free(dataOffset);\r\n        }\r\n        if (!keepOutputTensor) {\r\n          wasm._OrtReleaseTensor(tensor);\r\n        }\r\n      }\r\n    }\r\n\r\n    if (ioBindingState && !enableGraphCapture) {\r\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\r\n        checkLastError(\"Can't clear bound outputs.\");\r\n      }\r\n      activeSessions.set(sessionId, [\r\n        sessionHandle,\r\n        inputNamesUTF8Encoded,\r\n        outputNamesUTF8Encoded,\r\n        ioBindingState,\r\n        enableGraphCapture,\r\n        false,\r\n      ]);\r\n    }\r\n    // Wait for all output tensor data to be downloaded.\r\n    for (const [index, data] of await Promise.all(outputPromises)) {\r\n      output[index][2] = data;\r\n    }\r\n    TRACE_EVENT_END('wasm ProcessOutputTensor');\r\n    return output;\r\n  } finally {\r\n    wasm.webnnOnRunEnd?.(sessionHandle);\r\n\r\n    wasm.stackRestore(beforeRunStack);\r\n\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n      inputTensors.forEach((t) => {\r\n        if (t && t[3] === 'gpu-buffer') {\r\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\r\n        }\r\n      });\r\n      outputTensors.forEach((t) => {\r\n        if (t && t[3] === 'gpu-buffer') {\r\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\r\n        }\r\n      });\r\n    }\r\n    inputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\r\n    outputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\r\n    inputOutputAllocs.forEach((p) => wasm._free(p));\r\n\r\n    if (runOptionsHandle !== 0) {\r\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\r\n    }\r\n    runOptionsAllocs.forEach((p) => wasm._free(p));\r\n  }\r\n};\r\n\r\n/**\r\n * end profiling\r\n */\r\nexport const endProfiling = (sessionId: number): void => {\r\n  const wasm = getInstance();\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error('invalid session id');\r\n  }\r\n  const sessionHandle = session[0];\r\n\r\n  // profile file name is not used yet, but it must be freed.\r\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\r\n  if (profileFileName === 0) {\r\n    checkLastError(\"Can't get an profile file name.\");\r\n  }\r\n  wasm._OrtFree(profileFileName);\r\n};\r\n\r\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\r\n  const buffers: ArrayBufferLike[] = [];\r\n  for (const tensor of tensors) {\r\n    const data = tensor[2];\r\n    if (!Array.isArray(data) && 'buffer' in data) {\r\n      buffers.push(data.buffer);\r\n    }\r\n  }\r\n  return buffers;\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env, InferenceSession } from 'onnxruntime-common';\r\n\r\nimport {\r\n  OrtWasmMessage,\r\n  SerializableInternalBuffer,\r\n  SerializableSessionMetadata,\r\n  SerializableTensorMetadata,\r\n  TensorMetadata,\r\n} from './proxy-messages';\r\nimport * as core from './wasm-core-impl';\r\nimport { initializeWebAssembly } from './wasm-factory';\r\nimport {\r\n  importProxyWorker,\r\n  inferWasmPathPrefixFromScriptSrc,\r\n  isEsmImportMetaUrlHardcodedAsFileUri,\r\n} from './wasm-utils-import';\r\n\r\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\r\nlet proxyWorker: Worker | undefined;\r\nlet initializing = false;\r\nlet initialized = false;\r\nlet aborted = false;\r\nlet temporaryObjectUrl: string | undefined;\r\n\r\ntype PromiseCallbacks<T = void> = [resolve: (result: T) => void, reject: (reason: unknown) => void];\r\nlet initWasmCallbacks: PromiseCallbacks;\r\nconst queuedCallbacks: Map<OrtWasmMessage['type'], Array<PromiseCallbacks<unknown>>> = new Map();\r\n\r\nconst enqueueCallbacks = (type: OrtWasmMessage['type'], callbacks: PromiseCallbacks<unknown>): void => {\r\n  const queue = queuedCallbacks.get(type);\r\n  if (queue) {\r\n    queue.push(callbacks);\r\n  } else {\r\n    queuedCallbacks.set(type, [callbacks]);\r\n  }\r\n};\r\n\r\nconst ensureWorker = (): void => {\r\n  if (initializing || !initialized || aborted || !proxyWorker) {\r\n    throw new Error('worker not ready');\r\n  }\r\n};\r\n\r\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\r\n  switch (ev.data.type) {\r\n    case 'init-wasm':\r\n      initializing = false;\r\n      if (ev.data.err) {\r\n        aborted = true;\r\n        initWasmCallbacks[1](ev.data.err);\r\n      } else {\r\n        initialized = true;\r\n        initWasmCallbacks[0]();\r\n      }\r\n      if (temporaryObjectUrl) {\r\n        URL.revokeObjectURL(temporaryObjectUrl);\r\n        temporaryObjectUrl = undefined;\r\n      }\r\n      break;\r\n    case 'init-ep':\r\n    case 'copy-from':\r\n    case 'create':\r\n    case 'release':\r\n    case 'run':\r\n    case 'end-profiling': {\r\n      const callbacks = queuedCallbacks.get(ev.data.type)!;\r\n      if (ev.data.err) {\r\n        callbacks.shift()![1](ev.data.err);\r\n      } else {\r\n        callbacks.shift()![0](ev.data.out!);\r\n      }\r\n      break;\r\n    }\r\n    default:\r\n  }\r\n};\r\n\r\nexport const initializeWebAssemblyAndOrtRuntime = async (): Promise<void> => {\r\n  if (initialized) {\r\n    return;\r\n  }\r\n  if (initializing) {\r\n    throw new Error(\"multiple calls to 'initWasm()' detected.\");\r\n  }\r\n  if (aborted) {\r\n    throw new Error(\"previous call to 'initWasm()' failed.\");\r\n  }\r\n\r\n  initializing = true;\r\n\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    return new Promise<void>((resolve, reject) => {\r\n      proxyWorker?.terminate();\r\n\r\n      void importProxyWorker().then(([objectUrl, worker]) => {\r\n        try {\r\n          proxyWorker = worker;\r\n          proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\r\n          proxyWorker.onmessage = onProxyWorkerMessage;\r\n          initWasmCallbacks = [resolve, reject];\r\n          const message: OrtWasmMessage = { type: 'init-wasm', in: env };\r\n\r\n          // if the proxy worker is loaded from a blob URL, we need to make sure the path information is not lost.\r\n          //\r\n          // when `env.wasm.wasmPaths` is not set, we need to pass the path information to the worker.\r\n          //\r\n          if (!BUILD_DEFS.ENABLE_BUNDLE_WASM_JS && !message.in!.wasm.wasmPaths && objectUrl) {\r\n            // for a build not bundled the wasm JS, we need to pass the path prefix to the worker.\r\n            // the path prefix will be used to resolve the path to both the wasm JS and the wasm file.\r\n            const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\r\n            if (inferredWasmPathPrefix) {\r\n              message.in!.wasm.wasmPaths = inferredWasmPathPrefix;\r\n            }\r\n          }\r\n\r\n          if (\r\n            BUILD_DEFS.IS_ESM &&\r\n            BUILD_DEFS.ENABLE_BUNDLE_WASM_JS &&\r\n            !message.in!.wasm.wasmPaths &&\r\n            (objectUrl || isEsmImportMetaUrlHardcodedAsFileUri)\r\n          ) {\r\n            // for a build bundled the wasm JS, if either of the following conditions is met:\r\n            // - the proxy worker is loaded from a blob URL\r\n            // - `import.meta.url` is a file URL, it means it is overwritten by the bundler.\r\n            //\r\n            // in either case, the path information is lost, we need to pass the path of the .wasm file to the worker.\r\n            // we need to use the bundler preferred URL format:\r\n            // new URL('filename', import.meta.url)\r\n            // so that the bundler can handle the file using corresponding loaders.\r\n            message.in!.wasm.wasmPaths = {\r\n              wasm: !BUILD_DEFS.DISABLE_JSEP\r\n                ? new URL('ort-wasm-simd-threaded.jsep.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\r\n                : !BUILD_DEFS.DISABLE_WEBGPU\r\n                  ? new URL('ort-wasm-simd-threaded.asyncify.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\r\n                  : new URL('ort-wasm-simd-threaded.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href,\r\n            };\r\n          }\r\n          proxyWorker.postMessage(message);\r\n          temporaryObjectUrl = objectUrl;\r\n        } catch (e) {\r\n          reject(e);\r\n        }\r\n      }, reject);\r\n    });\r\n  } else {\r\n    try {\r\n      await initializeWebAssembly(env.wasm);\r\n      await core.initRuntime(env);\r\n      initialized = true;\r\n    } catch (e) {\r\n      aborted = true;\r\n      throw e;\r\n    } finally {\r\n      initializing = false;\r\n    }\r\n  }\r\n};\r\n\r\nexport const initializeOrtEp = async (epName: string): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('init-ep', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'init-ep', in: { epName, env } };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    await core.initEp(env, epName);\r\n  }\r\n};\r\n\r\nexport const copyFromExternalBuffer = async (buffer: Uint8Array): Promise<SerializableInternalBuffer> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<SerializableInternalBuffer>((resolve, reject) => {\r\n      enqueueCallbacks('copy-from', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'copy-from', in: { buffer } };\r\n      proxyWorker!.postMessage(message, [buffer.buffer]);\r\n    });\r\n  } else {\r\n    return core.copyFromExternalBuffer(buffer);\r\n  }\r\n};\r\n\r\nexport const createSession = async (\r\n  model: SerializableInternalBuffer | Uint8Array,\r\n  options?: InferenceSession.SessionOptions,\r\n): Promise<SerializableSessionMetadata> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    // check unsupported options\r\n    if (options?.preferredOutputLocation) {\r\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\r\n    }\r\n    ensureWorker();\r\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\r\n      enqueueCallbacks('create', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'create', in: { model, options: { ...options } } };\r\n      const transferable: Transferable[] = [];\r\n      if (model instanceof Uint8Array) {\r\n        transferable.push(model.buffer);\r\n      }\r\n      proxyWorker!.postMessage(message, transferable);\r\n    });\r\n  } else {\r\n    return core.createSession(model, options);\r\n  }\r\n};\r\n\r\nexport const releaseSession = async (sessionId: number): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('release', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'release', in: sessionId };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    core.releaseSession(sessionId);\r\n  }\r\n};\r\n\r\nexport const run = async (\r\n  sessionId: number,\r\n  inputIndices: number[],\r\n  inputs: TensorMetadata[],\r\n  outputIndices: number[],\r\n  outputs: Array<TensorMetadata | null>,\r\n  options: InferenceSession.RunOptions,\r\n): Promise<TensorMetadata[]> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    // check inputs location\r\n    if (inputs.some((t) => t[3] !== 'cpu')) {\r\n      throw new Error('input tensor on GPU is not supported for proxy.');\r\n    }\r\n    // check outputs location\r\n    if (outputs.some((t) => t)) {\r\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\r\n    }\r\n    ensureWorker();\r\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\r\n      enqueueCallbacks('run', [resolve, reject]);\r\n      const serializableInputs = inputs as SerializableTensorMetadata[]; // every input is on CPU.\r\n      const message: OrtWasmMessage = {\r\n        type: 'run',\r\n        in: { sessionId, inputIndices, inputs: serializableInputs, outputIndices, options },\r\n      };\r\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\r\n    });\r\n  } else {\r\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\r\n  }\r\n};\r\n\r\nexport const endProfiling = async (sessionId: number): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('end-profiling', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'end-profiling', in: sessionId };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    core.endProfiling(sessionId);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  InferenceSession,\r\n  InferenceSessionHandler,\r\n  SessionHandler,\r\n  Tensor,\r\n  TRACE_FUNC_BEGIN,\r\n  TRACE_FUNC_END,\r\n} from 'onnxruntime-common';\r\n\r\nimport { SerializableInternalBuffer, TensorMetadata } from './proxy-messages';\r\nimport { copyFromExternalBuffer, createSession, endProfiling, releaseSession, run } from './proxy-wrapper';\r\nimport { isGpuBufferSupportedType, isMLTensorSupportedType } from './wasm-common';\r\nimport { isNode } from './wasm-utils-env';\r\nimport { loadFile } from './wasm-utils-load-file';\r\n\r\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\r\n  switch (tensor.location) {\r\n    case 'cpu':\r\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\r\n    case 'gpu-buffer':\r\n      return [tensor.type, tensor.dims, { gpuBuffer: tensor.gpuBuffer }, 'gpu-buffer'];\r\n    case 'ml-tensor':\r\n      return [tensor.type, tensor.dims, { mlTensor: tensor.mlTensor }, 'ml-tensor'];\r\n    default:\r\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\r\n  }\r\n};\r\n\r\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\r\n  switch (tensor[3]) {\r\n    case 'cpu':\r\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\r\n    case 'gpu-buffer': {\r\n      const dataType = tensor[0];\r\n      if (!isGpuBufferSupportedType(dataType)) {\r\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\r\n      }\r\n      const { gpuBuffer, download, dispose } = tensor[2];\r\n      return Tensor.fromGpuBuffer(gpuBuffer, { dataType, dims: tensor[1], download, dispose });\r\n    }\r\n    case 'ml-tensor': {\r\n      const dataType = tensor[0];\r\n      if (!isMLTensorSupportedType(dataType)) {\r\n        throw new Error(`not supported data type: ${dataType} for deserializing MLTensor tensor`);\r\n      }\r\n      const { mlTensor, download, dispose } = tensor[2];\r\n      return Tensor.fromMLTensor(mlTensor, { dataType, dims: tensor[1], download, dispose });\r\n    }\r\n    default:\r\n      throw new Error(`invalid data location: ${tensor[3]}`);\r\n  }\r\n};\r\n\r\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\r\n  private sessionId: number;\r\n\r\n  inputNames: readonly string[];\r\n  outputNames: readonly string[];\r\n  inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n  outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  async fetchModelAndCopyToWasmMemory(path: string): Promise<SerializableInternalBuffer> {\r\n    // fetch model from url and move to wasm heap.\r\n    return copyFromExternalBuffer(await loadFile(path));\r\n  }\r\n\r\n  async loadModel(pathOrBuffer: string | Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\r\n    TRACE_FUNC_BEGIN();\r\n    let model: Parameters<typeof createSession>[0];\r\n\r\n    if (typeof pathOrBuffer === 'string') {\r\n      if (isNode) {\r\n        // node\r\n        model = await loadFile(pathOrBuffer);\r\n      } else {\r\n        // browser\r\n        // fetch model and copy to wasm heap.\r\n        model = await this.fetchModelAndCopyToWasmMemory(pathOrBuffer);\r\n      }\r\n    } else {\r\n      model = pathOrBuffer;\r\n    }\r\n\r\n    [this.sessionId, this.inputNames, this.outputNames, this.inputMetadata, this.outputMetadata] = await createSession(\r\n      model,\r\n      options,\r\n    );\r\n    TRACE_FUNC_END();\r\n  }\r\n\r\n  async dispose(): Promise<void> {\r\n    return releaseSession(this.sessionId);\r\n  }\r\n\r\n  async run(\r\n    feeds: SessionHandler.FeedsType,\r\n    fetches: SessionHandler.FetchesType,\r\n    options: InferenceSession.RunOptions,\r\n  ): Promise<SessionHandler.ReturnType> {\r\n    TRACE_FUNC_BEGIN();\r\n    const inputArray: Tensor[] = [];\r\n    const inputIndices: number[] = [];\r\n    Object.entries(feeds).forEach((kvp) => {\r\n      const name = kvp[0];\r\n      const tensor = kvp[1];\r\n      const index = this.inputNames.indexOf(name);\r\n      if (index === -1) {\r\n        throw new Error(`invalid input '${name}'`);\r\n      }\r\n      inputArray.push(tensor);\r\n      inputIndices.push(index);\r\n    });\r\n\r\n    const outputArray: Array<Tensor | null> = [];\r\n    const outputIndices: number[] = [];\r\n    Object.entries(fetches).forEach((kvp) => {\r\n      const name = kvp[0];\r\n      const tensor = kvp[1];\r\n      const index = this.outputNames.indexOf(name);\r\n      if (index === -1) {\r\n        throw new Error(`invalid output '${name}'`);\r\n      }\r\n      outputArray.push(tensor);\r\n      outputIndices.push(index);\r\n    });\r\n\r\n    const inputs = inputArray.map((t, i) =>\r\n      encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`),\r\n    );\r\n    const outputs = outputArray.map((t, i) =>\r\n      t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null,\r\n    );\r\n\r\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\r\n\r\n    const resultMap: SessionHandler.ReturnType = {};\r\n    for (let i = 0; i < results.length; i++) {\r\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\r\n    }\r\n    TRACE_FUNC_END();\r\n    return resultMap;\r\n  }\r\n\r\n  startProfiling(): void {\r\n    // TODO: implement profiling\r\n  }\r\n\r\n  endProfiling(): void {\r\n    void endProfiling(this.sessionId);\r\n  }\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Backend, env, InferenceSession, InferenceSessionHandler } from 'onnxruntime-common';\r\n\r\nimport { initializeOrtEp, initializeWebAssemblyAndOrtRuntime } from './wasm/proxy-wrapper';\r\nimport { OnnxruntimeWebAssemblySessionHandler } from './wasm/session-handler-inference';\r\n\r\n/**\r\n * This function initializes all flags for WebAssembly.\r\n *\r\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\r\n * being created, to override default value.\r\n */\r\nexport const initializeFlags = (): void => {\r\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\r\n    env.wasm.initTimeout = 0;\r\n  }\r\n\r\n  const simd = env.wasm.simd;\r\n  if (typeof simd !== 'boolean' && simd !== undefined && simd !== 'fixed' && simd !== 'relaxed') {\r\n    // eslint-disable-next-line no-console\r\n    console.warn(\r\n      `Property \"env.wasm.simd\" is set to unknown value \"${simd}\". Reset it to \\`false\\` and ignore SIMD feature checking.`,\r\n    );\r\n    env.wasm.simd = false;\r\n  }\r\n\r\n  if (typeof env.wasm.proxy !== 'boolean') {\r\n    env.wasm.proxy = false;\r\n  }\r\n\r\n  if (typeof env.wasm.trace !== 'boolean') {\r\n    env.wasm.trace = false;\r\n  }\r\n\r\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\r\n    // The following logic only applies when `ort.env.wasm.numThreads` is not set by user. We will always honor user's\r\n    // setting if it is provided.\r\n\r\n    // Browser: when crossOriginIsolated is false, SharedArrayBuffer is not available so WebAssembly threads will not\r\n    // work. In this case, we will set numThreads to 1.\r\n    //\r\n    // There is an exception: when the browser is configured to force-enable SharedArrayBuffer (e.g. Chromuim with\r\n    // --enable-features=SharedArrayBuffer), it is possible that `self.crossOriginIsolated` is false and\r\n    // SharedArrayBuffer is available at the same time. This is usually for testing. In this case,  we will still set\r\n    // numThreads to 1 here. If we want to enable multi-threading in test, we should set `ort.env.wasm.numThreads` to a\r\n    // value greater than 1.\r\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\r\n      env.wasm.numThreads = 1;\r\n    } else {\r\n      const numCpuLogicalCores =\r\n        typeof navigator === 'undefined' ? require('node:os').cpus().length : navigator.hardwareConcurrency;\r\n      env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\r\n    }\r\n  }\r\n};\r\n\r\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\r\n  /**\r\n   * This function initializes the WebAssembly backend.\r\n   *\r\n   * This function will be called only once for each backend name. It will be called the first time when\r\n   * `ort.InferenceSession.create()` is called with a registered backend name.\r\n   *\r\n   * @param backendName - the registered backend name.\r\n   */\r\n  async init(backendName: string): Promise<void> {\r\n    // populate wasm flags\r\n    initializeFlags();\r\n\r\n    // init wasm\r\n    await initializeWebAssemblyAndOrtRuntime();\r\n\r\n    // performe EP specific initialization\r\n    await initializeOrtEp(backendName);\r\n  }\r\n  createInferenceSessionHandler(\r\n    path: string,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n  createInferenceSessionHandler(\r\n    buffer: Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n  async createInferenceSessionHandler(\r\n    pathOrBuffer: string | Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler> {\r\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\r\n    await handler.loadModel(pathOrBuffer, options);\r\n    return handler;\r\n  }\r\n}\r\n\r\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\r\n\r\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\r\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\r\n// So we import code inside the if-clause to allow bundler remove the code safely.\r\n\r\nexport * from 'onnxruntime-common';\r\nimport * as ort from 'onnxruntime-common';\r\nexport default ort;\r\n\r\nimport { registerBackend, env } from 'onnxruntime-common';\r\nimport { version } from './version';\r\n\r\nif (!BUILD_DEFS.DISABLE_WEBGL) {\r\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\r\n  registerBackend('webgl', onnxjsBackend, -10);\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_JSEP && !BUILD_DEFS.DISABLE_WEBGPU) {\r\n  throw new Error(\r\n    'The current build is specified to enable both JSEP and WebGPU EP. This is not a valid configuration. ' +\r\n      'JSEP and WebGPU EPs cannot be enabled at the same time.',\r\n  );\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_WEBNN && BUILD_DEFS.DISABLE_JSEP && BUILD_DEFS.DISABLE_WEBGPU) {\r\n  throw new Error(\r\n    'The current build is specified to enable WebNN EP without JSEP or WebGPU EP. This is not a valid configuration. ' +\r\n      'WebNN EP requires either JSEP or WebGPU EP to be enabled.',\r\n  );\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_WASM) {\r\n  const wasmBackend = require('./backend-wasm').wasmBackend;\r\n  if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\r\n    registerBackend('webgpu', wasmBackend, 5);\r\n  }\r\n  if (!BUILD_DEFS.DISABLE_WEBNN) {\r\n    registerBackend('webnn', wasmBackend, 5);\r\n  }\r\n  registerBackend('cpu', wasmBackend, 10);\r\n  registerBackend('wasm', wasmBackend, 10);\r\n}\r\n\r\nObject.defineProperty(env.versions, 'web', { value: version, enumerable: true });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// This file is generated by /js/scripts/update-version.ts\r\n// Do not modify file content manually.\r\n\r\nexport const version = '1.23.0';\r\n"]}