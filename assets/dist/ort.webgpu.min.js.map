{"version":3,"sources":["../../common/lib/backend-impl.ts","../../common/lib/backend.ts","../../common/lib/version.ts","../../common/lib/env-impl.ts","../../common/lib/env.ts","../../common/lib/tensor-conversion-impl.ts","../../common/lib/tensor-factory-impl.ts","../../common/lib/tensor-impl-type-mapping.ts","../../common/lib/tensor-utils-impl.ts","../../common/lib/tensor-impl.ts","../../common/lib/tensor.ts","../../common/lib/trace.ts","../../common/lib/inference-session-impl.ts","../../common/lib/inference-session.ts","../../common/lib/tensor-conversion.ts","../../common/lib/tensor-factory.ts","../../common/lib/onnx-model.ts","../../common/lib/onnx-value.ts","../../common/lib/index.ts","../lib/wasm/wasm-utils-env.ts","../lib/wasm/proxy-worker/main.ts","../lib/wasm/wasm-utils-import.ts","../lib/wasm/wasm-factory.ts","../lib/wasm/wasm-utils.ts","../lib/wasm/run-options.ts","../lib/wasm/session-options.ts","../lib/wasm/wasm-common.ts","../lib/wasm/wasm-utils-load-file.ts","../lib/wasm/jsep/tensor-view.ts","../lib/wasm/jsep/log.ts","../lib/wasm/jsep/webnn/tensor-manager.ts","../lib/wasm/jsep/backend-webnn.ts","../lib/wasm/wasm-core-impl.ts","../lib/wasm/proxy-wrapper.ts","../lib/wasm/session-handler-inference.ts","../lib/backend-wasm.ts","../lib/index.ts","../lib/version.ts"],"names":["backends","backendsSortedByPriority","registerBackend","tryResolveAndInitializeBackend","resolveBackendAndExecutionProviders","init_backend_impl","__esmMin","name","backend","priority","currentBackend","i","backendName","backendInfo","isInitializing","e","options","eps","backendHints","backendNames","errors","availableBackendNames","resolveResult","err","filteredEps","target","prop","init_backend","version","init_version","logLevelValue","env","init_env_impl","value","init_env","tensorToDataURL","tensorToImageData","init_tensor_conversion_impl","tensor","canvas","pixels2DContext","width","height","inputformat","norm","normMean","normBias","stride","rTensorPointer","gTensorPointer","bTensorPointer","aTensorPointer","j","R","G","B","A","image","channels","step","rImagePointer","gImagePointer","bImagePointer","aImagePointer","bufferToTensor","tensorFromImage","tensorFromTexture","tensorFromGpuBuffer","tensorFromMLTensor","tensorFromPinnedBuffer","init_tensor_factory_impl","init_tensor_impl","buffer","outputformat","float32Data","Tensor","isHTMLImageEle","isImageDataEle","isImageBitmap","isString","data","bufferToTensorOptions","createCanvas","createCanvasContext","tempCanvas","resolve","reject","context","newImage","img","texture","download","dispose","dims","gpuBuffer","dataType","mlTensor","type","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","isTypedArrayChecked","checkTypedArray","init_tensor_impl_type_mapping","isBigInt64ArrayAvailable","isBigUint64ArrayAvailable","Float16Array","isFloat16ArrayAvailable","calculateSize","tensorReshape","init_tensor_utils_impl","size","dim","arg0","arg1","arg2","expectedTypedArrayConstructor","maybeDims","typedArrayConstructor","firstElementType","mappedType","releaseData","init_tensor","TRACE","TRACE_FUNC","TRACE_FUNC_BEGIN","TRACE_FUNC_END","TRACE_EVENT_BEGIN","TRACE_EVENT_END","init_trace","deviceType","label","msg","extraMsg","stack","hasTraceFunc","InferenceSession","init_inference_session_impl","_InferenceSession","handler","feeds","fetches","isFetchesEmpty","isFetches","arg1Keys","v","results","returnValue","key","result","arg3","filePathOrUint8Array","byteOffset","byteLength","optionsWithValidatedEPs","init_inference_session","init_tensor_conversion","init_tensor_factory","init_onnx_model","init_onnx_value","esm_exports","__export","init_esm","init_wasm_utils_env","main_exports","main_default","WORKER_NAME","isProxyWorker","init_main","init_wasm_core_impl","init_wasm_factory","init_wasm_utils_import","ev","message","initializeWebAssembly","initRuntime","epName","initEp","bufferData","copyFromExternalBuffer","model","createSession","sessionMetadata","releaseSession","sessionId","inputIndices","inputs","outputIndices","run","outputs","o","extractTransferableBuffers","endProfiling","urlOverride","scriptSrc","origin","getScriptSrc","inferWasmPathPrefixFromScriptSrc","isSameOrigin","normalizeUrl","fallbackUrl","preload","dynamicImportDefault","createProxyWorker","importProxyWorker","embeddedWasmModule","importWasmModule","filename","prefixOverride","baseUrl","absoluteUrl","blob","url","isMultiThreaded","isWasmOverridden","useEmbeddedModule","wasmModuleFilename","wasmModuleUrl","needPreload","wasm","initialized","initializing","aborted","isMultiThreadSupported","isSimdSupported","isRelaxedSimdSupported","getInstance","flags","timeout","numThreads","multiThreadSupported","wasmPaths","wasmPrefixOverride","mjsPathOverrideFlag","mjsPathOverride","wasmPathOverrideFlag","wasmPathOverride","wasmBinaryOverride","objectUrl","ortWasmFactory","isTimeout","tasks","config","fileName","inferredWasmPathPrefix","module","what","allocWasmString","iterateExtraOptions","checkLastError","init_wasm_utils","allocs","dataLength","dataOffset","prefix","seen","ptrSize","paramsOffset","errorCode","errorMessagePointer","errorMessage","setRunOptions","init_run_options","runOptionsHandle","runOptions","tagDataOffset","keyDataOffset","valueDataOffset","alloc","getGraphOptimzationLevel","getExecutionMode","appendDefaultOptions","appendSessionConfig","appendEpOption","setExecutionProviders","setSessionOptions","init_session_options","graphOptimizationLevel","executionMode","session","ep","sessionOptionsHandle","epOptions","executionProviders","customDevice","customOptions","info","deviceId","instanceHandle","deviceHandle","epNameDataOffset","epOptionsCount","keysOffset","valuesOffset","sessionOptions","logIdDataOffset","logSeverityLevel","logVerbosityLevel","optimizedModelFilePathOffset","nameOffset","tensorDataTypeStringToEnum","tensorDataTypeEnumToString","calculateTensorSizeInBytes","tensorTypeToTypedArrayConstructor","logLevelStringToEnum","isGpuBufferSupportedType","isMLTensorSupportedType","dataLocationStringToEnum","init_wasm_common","typeProto","dateType","dimsOrSize","elementSize","a","b","logLevel","location","loadFile","init_wasm_utils_load_file","file","readFile","createReadStream","stream","chunks","chunk","response","contentLengthHeader","fileSize","reader","pages","offset","done","chunkSize","createView","init_tensor_view","dataBuffer","logLevelPrefix","doLog","configLogLevel","debug","configureLogger","LOG","LOG_DEBUG","init_log","level","$configLogLevel","$debug","messageLevel","configLevel","args","webnnDataTypeToSize","convertDataToInt32","convertInt32ToData","tensorGuid","createNewTensorId","webnnDataTypeToFallback","calculateByteLength","TensorWrapper","TensorIdTracker","TensorManagerImpl","createTensorManager","init_tensor_manager","dataTypeSize","bytesPerElement","numElements","originalArray","int32Array","bigInt64Array","bigUint64Array","int8Array","uint32Array","shape","descriptor","fallbackDataType","dstBuffer","originalData","isConverted","tensorManager","wrapper","copyOld","usage","newData","dstData","tensorId","tensorTracker","writable","readable","index","tensorWrapper","backend_webnn_exports","WebNNBackend","onnxDataTypeToWebnnDataType","compareMLContextOptions","init_backend_webnn","aKeys","bKeys","tensorIds","optionsOrDevice","mlContextIndex","entry","mlContext","sessionIds","onnxDataType","dimensions","webnnDataType","id","externalFilePath","builder","desc","mountedFiles","shouldConvertInt64ToInt32","filePath","fileData","bufferView","int32Buffer","inputName","outputName","inputNames","outputNames","isInput","initOrt","activeSessions","getSessionInputOutputCount","getSessionInputOutputMetadata","prepareInputOutputTensor","loggingLevel","webgpuAdapter","powerPreference","forceFallbackAdapter","device","sessionHandle","metadataOffset","elementType","dimsCount","symbolicDimNameOffset","modelDataOffset","modelData","modelDataLength","ioBindingHandle","inputNamesUTF8Encoded","outputNamesUTF8Encoded","loadingPromises","path","provider","webnnOptions","gpuDevice","inputCount","outputCount","enableGraphCapture","inputMetadata","outputMetadata","outputPreferredLocations","nameString","isGraphOutput","bindingState","l","buf","ioBindingState","tensorHandles","tensorNameUTF8Encoded","actualLocation","rawData","dataByteLength","registerBuffer","registerMLTensor","isGraphInput","tensorName","dataTypeEnum","createTemporaryTensor","uploadTensor","dimsOffset","d","inputTensors","outputTensors","inputOutputBound","runOptionsAllocs","inputTensorHandles","outputTensorHandles","inputOutputAllocs","beforeRunStack","inputValuesOffset","inputNamesOffset","outputValuesOffset","outputNamesOffset","handle","outputPreferredLocationsEncoded","output","outputPromises","beforeGetTensorDataStack","tensorDataOffset","keepOutputTensor","valueType","dimsLength","preferredLocation","stringData","nextOffset","maxBytesToRead","getBuffer","bufferSize","downloadDataFunction","arrayBuffer","ensureTensor","isGraphInputOutputTypeSupported","t","p","profileFileName","tensors","buffers","isProxy","proxyWorker","temporaryObjectUrl","initWasmCallbacks","queuedCallbacks","enqueueCallbacks","ensureWorker","onProxyWorkerMessage","initializeWebAssemblyAndOrtRuntime","initializeOrtEp","init_proxy_wrapper","callbacks","queue","worker","transferable","serializableInputs","encodeTensorMetadata","decodeTensorMetadata","OnnxruntimeWebAssemblySessionHandler","init_session_handler_inference","getName","pathOrBuffer","inputArray","kvp","outputArray","resultMap","backend_wasm_exports","OnnxruntimeWebAssemblyBackend","initializeFlags","wasmBackend","init_backend_wasm","simd","numCpuLogicalCores","index_exports","index_default"],"mappings":";;;;;kuBAAA,IAgBMA,GACAC,GAYOC,EAwCPC,GAwCOC,GA7GbC,GAAAC,EAAA,kBAgBMN,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,EAAkB,CAACK,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBV,GAAS,IAAIO,CAAI,EACxC,GAAIG,IAAmB,OACrBV,GAAS,IAAIO,EAAM,CAAE,QAAAC,EAAS,SAAAC,CAAQ,CAAE,MACnC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIV,GAAyB,QAAQM,CAAI,EAC3CI,IAAM,IACRV,GAAyB,OAAOU,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIV,GAAyB,OAAQU,IACnD,GAAIX,GAAS,IAAIC,GAAyBU,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnER,GAAyB,OAAOU,EAAG,EAAGJ,CAAI,EAC1C,OAGJN,GAAyB,KAAKM,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAQMJ,GAAiC,MAAOS,GAAkD,CAC9F,IAAMC,EAAcb,GAAS,IAAIY,CAAW,EAC5C,GAAI,CAACC,EACH,MAAO,qBAGT,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,OAAOA,EAAY,MACd,CACL,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAKD,CAAW,GAEhE,MAAMC,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACV,OAAKD,IACHD,EAAY,MAAQ,GAAGE,CAAC,GACxBF,EAAY,QAAU,IAEjBA,EAAY,cAEnB,OAAOA,EAAY,aAGzB,EAWaT,GAAsC,MACjDY,GACyE,CAEzE,IAAMC,EAAMD,EAAQ,oBAAsB,CAAA,EACpCE,EAAeD,EAAI,IAAKN,GAAO,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAK,EAClEQ,EAAeD,EAAa,SAAW,EAAIjB,GAA2BiB,EAGxEV,EACEY,EAAS,CAAA,EACTC,EAAwB,IAAI,IAClC,QAAWT,KAAeO,EAAc,CACtC,IAAMG,EAAgB,MAAMnB,GAA+BS,CAAW,EAClE,OAAOU,GAAkB,SAC3BF,EAAO,KAAK,CAAE,KAAMR,EAAa,IAAKU,CAAa,CAAE,GAEhDd,IACHA,EAAUc,GAERd,IAAYc,GACdD,EAAsB,IAAIT,CAAW,GAM3C,GAAI,CAACJ,EACH,MAAM,IAAI,MAAM,oCAAoCY,EAAO,IAAKL,GAAM,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,EAI5G,OAAW,CAAE,KAAAR,EAAM,IAAAgB,CAAG,IAAMH,EACtBF,EAAa,SAASX,CAAI,GAE5B,QAAQ,KACN,0CAA0CA,CAAI,uDAAuDgB,CAAG,EAAE,EAKhH,IAAMC,EAAcP,EAAI,OAAQN,GAAMU,EAAsB,IAAI,OAAOV,GAAM,SAAWA,EAAIA,EAAE,IAAI,CAAC,EAEnG,MAAO,CACLH,EACA,IAAI,MAAMQ,EAAS,CACjB,IAAK,CAACS,EAAQC,IACRA,IAAS,qBACJF,EAEF,QAAQ,IAAIC,EAAQC,CAAI,EAElC,EAEL,ICnKA,IAAAC,GAAArB,EAAA,kBA+DAD,OC/DA,IAMauB,GANbC,GAAAvB,EAAA,kBAMasB,GAAU,WCNvB,IAQIE,GAESC,EAVbC,GAAA1B,EAAA,kBAIAuB,KAIIC,GAAwC,UAE/BC,EAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAE,OAAQH,EAAO,EAE3B,IAAI,SAASK,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDH,GAAgBG,EAClB,EACA,IAAI,UAAQ,CACV,OAAOH,EACT,GAIF,OAAO,eAAeC,EAAK,WAAY,CAAE,WAAY,EAAI,CAAE,IC/B3D,IA2SaA,EA3SbG,GAAA5B,EAAA,kBAGA0B,KAwSaD,EAAWA,IC3SxB,IASaI,GAmGAC,GA5GbC,GAAA/B,EAAA,kBASa6B,GAAkB,CAACG,EAAgBtB,IAA4C,CAC1F,IAAMuB,EAAS,OAAO,SAAa,IAAc,SAAS,cAAc,QAAQ,EAAI,IAAI,gBAAgB,EAAG,CAAC,EAC5GA,EAAO,MAAQD,EAAO,KAAK,CAAC,EAC5BC,EAAO,OAASD,EAAO,KAAK,CAAC,EAC7B,IAAME,EAAkBD,EAAO,WAAW,IAAI,EAK9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACA1B,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,IAGtBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,GAGxB,IAAMK,EAAc3B,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/D4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASpC,EAAI,EAAGA,EAAI+B,EAAQ/B,IAC1B,QAASyC,EAAI,EAAGA,EAAIX,EAAOW,IAAK,CAC9B,IAAMC,GAAMf,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1ES,GAAMhB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMjB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,EAAIL,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE9GL,EAAgB,UAAY,QAAUa,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEhB,EAAgB,SAASY,EAAGzC,EAAG,EAAG,CAAC,EAGvC,GAAI,cAAe4B,EACjB,OAAOA,EAAO,UAAS,EAEvB,MAAM,IAAI,MAAM,4BAA4B,MAG9C,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaH,GAAoB,CAACE,EAAgBtB,IAAiD,CACjG,IAAMwB,EACJ,OAAO,SAAa,IAChB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EAC/C,IAAI,gBAAgB,EAAG,CAAC,EAAE,WAAW,IAAI,EAC5CiB,EACJ,GAAIjB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAgB,EACA1C,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,IAGxBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,GAE1B,IAAMK,EAAc3B,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhG4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIzB,IAAY,SAEXA,EAAQ,SAAW,QAAa0C,IAAa,GAAK1C,EAAQ,SAAW,QACrE0C,IAAa,GAAK1C,EAAQ,SAAW,OAASA,EAAQ,SAAW,OAElE,MAAM,IAAI,MAAM,+CAA+C,EAKnE,IAAM2C,EAAO,EACTC,EAAgB,EAClBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BU,EAAQjB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QACM/B,EAAI,EACRA,EAAI+B,EAASD,EACbmB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMhD,IAE5F8C,EAAM,KAAKG,CAAa,GAAMtB,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKI,CAAa,GAAMvB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKK,CAAa,GAAMxB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKM,CAAa,EACtBZ,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAGxG,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOY,CACT,ICrNA,IAkCaO,GA8FAC,GAoKAC,GAaAC,GAWAC,GAWAC,GAvUbC,GAAAhE,EAAA,kBAiBAiE,KAiBaP,GAAiB,CAACQ,EAAuCxD,IAA0C,CAC9G,GAAIwD,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIxD,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAE,OAAA0B,EAAQ,MAAAD,CAAK,EAAKzB,EAEpB4B,EAAO5B,EAAQ,MAAQ,CAAE,KAAM,IAAK,KAAM,CAAC,EAC7C6B,EACAC,EAEA,OAAOF,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAOA,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMD,EAAc3B,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DyD,EACJzD,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACvG+B,EAASL,EAASD,EAClBiC,EAAcD,IAAiB,OAAS,IAAI,aAAa1B,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGY,EAAO,EACTC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBgB,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdU,IAAiB,OACnBtB,EAAiBJ,EAAS,EACjB0B,IAAiB,OAC1BzB,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GACjB0B,IAAiB,QAC1BvB,EAAiB,EACjBD,EAAiBF,EACjBC,EAAiBD,EAAS,GAG5B,QACMpC,EAAI,EACRA,EAAIoC,EACJpC,IAAKiD,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAE3Fe,EAAY1B,GAAgB,GAAKwB,EAAOZ,CAAa,EAAId,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYzB,GAAgB,GAAKuB,EAAOX,CAAa,EAAIf,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYxB,GAAgB,GAAKsB,EAAOV,CAAa,EAAIhB,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9EM,IAAmB,IAAMY,IAAkB,KAC7CW,EAAYvB,GAAgB,GAAKqB,EAAOT,CAAa,EAAIjB,EAAS,CAAC,GAAKD,EAAS,CAAC,GAStF,OAHE4B,IAAiB,OACb,IAAIE,EAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,EACxD,IAAIkC,EAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,CAEhE,EAKawB,GAAkB,MAC7BR,EACAzC,IAKmB,CAEnB,IAAM4D,EAAiB,OAAO,iBAAqB,KAAenB,aAAiB,iBAC7EoB,EAAiB,OAAO,UAAc,KAAepB,aAAiB,UACtEqB,EAAgB,OAAO,YAAgB,KAAerB,aAAiB,YACvEsB,EAAW,OAAOtB,GAAU,SAE9BuB,EACAC,EAA+CjE,GAAW,CAAA,EAExDkE,EAAe,IAAK,CACxB,GAAI,OAAO,SAAa,IACtB,OAAO,SAAS,cAAc,QAAQ,EACjC,GAAI,OAAO,gBAAoB,IACpC,OAAO,IAAI,gBAAgB,EAAG,CAAC,EAE/B,MAAM,IAAI,MAAM,yBAAyB,CAE7C,EACMC,EAAuB5C,GACvB,OAAO,kBAAsB,KAAeA,aAAkB,mBAEvDA,aAAkB,gBADpBA,EAAO,WAAW,IAAI,EAItB,KAIX,GAAIqC,EAAgB,CAElB,IAAMrC,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAIE,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MAMlB,GALIzC,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADAiE,EAAwBjE,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7EiE,EAAsB,aAAe,OAEvCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,OAE9BwC,EAAsB,aAAe,OACrCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAGhCD,EAAgB,UAAUiB,EAAO,EAAG,CAAC,EACrCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCmC,EAAgB,CACzB,IAAInC,EACAD,EAiBJ,GAfIzB,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,eAEhB0B,EAASe,EAAM,OACfhB,EAAQgB,EAAM,OAGZzC,IAAY,SACdiE,EAAwBjE,GAE1BiE,EAAsB,OAAS,OAC/BA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAE1BzB,IAAY,OAAW,CACzB,IAAMoE,EAAaF,EAAY,EAE/BE,EAAW,MAAQ3C,EACnB2C,EAAW,OAAS1C,EAEpB,IAAMF,EAAkB2C,EAAoBC,CAAU,EAEtD,GAAI5C,GAAmB,KACrBA,EAAgB,aAAaiB,EAAO,EAAG,CAAC,EACxCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CsC,EAAOvB,EAAM,aAENqB,EAAe,CAExB,GAAI9D,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAMuB,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAME,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MACpB,OAAAjB,EAAgB,UAAUiB,EAAO,EAAG,EAAGhB,EAAOC,CAAM,EACpDsC,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,KACzDuC,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EACvBuB,GAAegB,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAM/C,EAAS2C,EAAY,EACrBK,EAAUJ,EAAoB5C,CAAM,EAC1C,GAAI,CAACkB,GAAS,CAAC8B,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAM/B,EACf+B,EAAS,OAAS,IAAK,CACrBjD,EAAO,MAAQiD,EAAS,MACxBjD,EAAO,OAASiD,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGjD,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMkD,EAAMF,EAAQ,aAAa,EAAG,EAAGhD,EAAO,MAAOA,EAAO,MAAM,EAElE0C,EAAsB,OAAS1C,EAAO,OACtC0C,EAAsB,MAAQ1C,EAAO,MACrC8C,EAAQrB,GAAeyB,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOhB,GAAegB,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKaf,GAAoB,CAC/BwB,EACA1E,IACU,CACV,GAAM,CAAE,MAAAyB,EAAO,OAAAC,EAAQ,SAAAiD,EAAU,QAAAC,CAAO,EAAK5E,EAEvC6E,EAAO,CAAC,EAAGnD,EAAQD,EAAO,CAAC,EACjC,OAAO,IAAIkC,EAAO,CAAE,SAAU,UAAW,KAAM,UAAW,QAAAe,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC9F,EAKazB,GAAsB,CACjC2B,EACA9E,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,EAAO,CAAE,SAAU,aAAc,KAAMoB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC/G,EAKaxB,GAAqB,CAChC4B,EACAhF,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,EAAO,CAAE,SAAU,YAAa,KAAMoB,GAAY,UAAW,SAAAC,EAAU,KAAAH,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC7G,EAKavB,GAAyB,CACpC4B,EACAzB,EACAqB,IACW,IAAIlB,EAAO,CAAE,SAAU,aAAc,KAAAsB,EAAM,KAAMzB,EAAQ,KAAMqB,GAAQ,CAACrB,EAAO,MAAM,CAAC,CAAE,IC3UrG,IAoBa0B,GAeAC,GAcTC,GACSC,GAlDbC,GAAAhG,EAAA,kBAoBa4F,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACtB,CAAC,OAAQ,UAAU,EACnB,CAAC,QAAS,UAAU,EACrB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAsB,GACbC,GAAkB,IAAK,CAClC,GAAI,CAACD,GAAqB,CACxBA,GAAsB,GACtB,IAAMG,EAA2B,OAAO,cAAkB,KAAe,cAAc,KACjFC,EAA4B,OAAO,eAAmB,KAAe,eAAe,KAGpFC,EAAgB,WAAmB,aACnCC,EAA0B,OAAOD,EAAiB,KAAeA,EAAa,KAEhFF,IACFL,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DK,IACFN,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAEhEO,GACFR,GAAsC,IAAI,UAAWO,CAAY,EACjEN,GAAsC,IAAIM,EAAc,SAAS,GAGjEP,GAAsC,IAAI,UAAW,WAAW,EAGtE,IC5EA,IAgBaS,GAkBAC,GAlCbC,GAAAvG,EAAA,kBASAiE,KAOaoC,GAAiBd,GAAoC,CAChE,IAAIiB,EAAO,EACX,QAASnG,EAAI,EAAGA,EAAIkF,EAAK,OAAQlF,IAAK,CACpC,IAAMoG,EAAMlB,EAAKlF,CAAC,EAClB,GAAI,OAAOoG,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQpG,CAAC,8BAA8BoG,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQpG,CAAC,0CAA0CoG,CAAG,EAAE,EAE/ED,GAAQC,EAEV,OAAOD,CACT,EAKaF,GAAgB,CAACtE,EAAgBuD,IAAmC,CAC/E,OAAQvD,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIqC,EAAOrC,EAAO,KAAMA,EAAO,KAAMuD,CAAI,EAClD,IAAK,aACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,aACV,KAAMrC,EAAO,KACb,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,UACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,UACV,QAASrC,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,aACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,aACV,UAAWrC,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,YACH,OAAO,IAAIlB,EAAO,CAChB,SAAU,YACV,SAAUrC,EAAO,SACjB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCvD,EAAO,QAAQ,mBAAmB,EAE1F,ICrEA,IAiDaqC,EAjDbJ,GAAAjE,EAAA,kBAGA+B,KAEAiC,KAoBAgC,KAOAO,KAiBalC,EAAP,KAAa,CAuDjB,YACEqC,EAUAC,EACAC,EAAwB,CAGxBb,GAAe,EAEf,IAAIJ,EACAJ,EAEJ,GAAI,OAAOmB,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBf,EAAOe,EAAK,KACZnB,EAAOmB,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMG,EAAgCjB,GAAsC,IAAID,CAAI,EACpF,GAAI,CAACkB,EACH,MAAM,IAAI,UAAU,qBAAqBlB,CAAI,uCAAuC,EAEtF,GAAI,EAAEe,EAAK,gBAAgBG,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUH,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAIf,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBe,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBe,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,YAAa,CAChB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,kCAAkC,EAEjF,KAAK,aAAee,EAAK,SACzB,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIhC,EACAoC,EAEJ,GAAI,OAAOJ,GAAS,SAMlB,GAFAf,EAAOe,EACPI,EAAYF,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAgD,EAItEjC,EAAOiC,MACF,CAEL,IAAMI,EAAwBnB,GAAsC,IAAIc,CAAI,EAC5E,GAAIK,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BL,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAKD,IAAS,WAAaK,IAA0B,aAAgBL,IAAS,SAAWA,IAAS,OAWhG,MAAM,IAAI,UACR,cAAcA,CAAI,0DAA0DK,EAAsB,IAAI,WAAW,EAE1GL,IAAS,UAAYA,IAAS,QAYvChC,EAAQqC,EAA8B,KAAKJ,EAAM,MAAM,EAIvDjC,EAAQqC,EAA8B,KAAKJ,CAAI,UAExCA,aAAgBI,EACzBrC,EAAOiC,UACEA,aAAgB,kBACzB,GAAID,IAAS,QACXhC,EAAO,WAAW,KAAKiC,CAAI,MAE3B,OAAM,IAAI,UAAU,yDAAyD,UAEtED,IAAS,WAAaC,aAAgB,aAAeI,IAA0B,YAMxFrC,EAAO,IAAK,WAAmB,aAAaiC,EAAK,OAAQA,EAAK,WAAYA,EAAK,MAAM,MAErF,OAAM,IAAI,UAAU,KAAKhB,CAAI,kCAAkCoB,CAAqB,EAAE,UAO1FD,EAAYH,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMM,EAAmB,OAAON,EAAK,CAAC,EACtC,GAAIM,IAAqB,SACvBrB,EAAO,SACPjB,EAAOgC,UACEM,IAAqB,UAC9BrB,EAAO,OAIPjB,EAAO,WAAW,KAAKgC,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCM,CAAgB,GAAG,UAEvEN,aAAgB,kBACzBf,EAAO,QACPjB,EAAO,WAAW,KAAKgC,CAAI,MACtB,CAEL,IAAMO,EAAapB,GAAsC,IACvDa,EAAK,WAA8C,EAErD,GAAIO,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCP,EAAK,WAAW,GAAG,EAE9Ef,EAAOsB,EACPvC,EAAOgC,EAKX,GAAII,IAAc,OAEhBA,EAAY,CAACpC,EAAK,MAAM,UACf,CAAC,MAAM,QAAQoC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAwC,EAE9DvB,EAAOuB,EAEP,KAAK,QAAUpC,EACf,KAAK,aAAe,MAItB,IAAM8B,EAAOH,GAAcd,CAAI,EAE/B,GAAI,KAAK,SAAWiB,IAAS,KAAK,QAAQ,QACnC,GAAAb,IAAS,SAAWA,IAAS,SAAW,KAAK,KAAKa,EAAO,CAAC,IAAM,KAAK,QAAQ,QAGhF,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAIhG,KAAK,KAAOb,EACZ,KAAK,KAAOJ,EACZ,KAAK,KAAOiB,CACd,CAIA,aAAa,UACXrD,EACAzC,EAIwB,CAExB,OAAOiD,GAAgBR,EAAOzC,CAAO,CACvC,CAEA,OAAO,YACL0E,EACA1E,EAAoC,CAEpC,OAAOkD,GAAkBwB,EAAS1E,CAAO,CAC3C,CAEA,OAAO,cACL8E,EACA9E,EAAsC,CAEtC,OAAOmD,GAAoB2B,EAAW9E,CAAO,CAC/C,CAEA,OAAO,aACLgF,EACAhF,EAAqC,CAErC,OAAOoD,GAAmB4B,EAAUhF,CAAO,CAC7C,CAEA,OAAO,iBACLiF,EACAzB,EACAqB,EAAwB,CAExB,OAAOxB,GAAuB4B,EAAMzB,EAAQqB,CAAI,CAClD,CAKA,UAAU7E,EAAgC,CACxC,OAAOmB,GAAgB,KAAMnB,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOoB,GAAkB,KAAMpB,CAAO,CACxC,CAqDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACR,gJAC6E,EAGjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAEA,IAAI,UAAQ,CAEV,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,aACR,MAAM,IAAI,MAAM,6CAA6C,EAE/D,OAAO,KAAK,YACd,CAKA,MAAM,QAAQwG,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aACL,IAAK,YAAa,CAChB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMxC,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXwC,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXxC,UAEP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,aAAe,OACpB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQa,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOe,GAAc,KAAMf,CAAI,CACjC,KC/iBF,IAsYalB,EAtYb8C,GAAAnH,EAAA,kBAIAiE,KAkYaI,EAASA,ICtYtB,IAQa+C,GAQPC,GAqBOC,EAUAC,GAUAC,EAWAC,EApEbC,GAAA1H,EAAA,kBAGA0B,KAKa0F,GAAQ,CAACO,EAAoBC,IAAiB,EACrD,OAAOnG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,UAAU,GAAGkG,CAAU,UAAUC,CAAK,EAAE,CAClD,EAEMP,GAAa,CAACQ,EAAaC,IAAqB,CACpD,IAAMC,EAAQ,IAAI,MAAK,EAAG,OAAO,MAAM,aAAa,GAAK,CAAA,EACrDC,EAAe,GACnB,QAAS3H,EAAI,EAAGA,EAAI0H,EAAM,OAAQ1H,IAAK,CACrC,GAAI2H,GAAgB,CAACD,EAAM1H,CAAC,EAAE,SAAS,YAAY,EAAG,CACpD,IAAIuH,EAAQ,QAAQC,CAAG,KAAKE,EAAM1H,CAAC,EAAE,KAAI,EAAG,MAAM,GAAG,EAAE,CAAC,CAAC,GACrDyH,IACFF,GAAS,KAAKE,CAAQ,IAExBV,GAAM,MAAOQ,CAAK,EAClB,OAEEG,EAAM1H,CAAC,EAAE,SAAS,YAAY,IAChC2H,EAAe,IAGrB,EAKaV,EAAoBQ,GAAqB,EAChD,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAG9D4F,GAAW,QAASS,CAAQ,CAC9B,EAKaP,GAAkBO,GAAqB,EAC9C,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAG9D4F,GAAW,MAAOS,CAAQ,CAC5B,EAKaN,EAAqBM,GAAqB,EACjD,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,KAAK,QAAQqG,CAAQ,EAAE,CACjC,EAKaL,EAAmBK,GAAqB,EAC/C,OAAOrG,EAAI,MAAU,IAAc,CAACA,EAAI,KAAK,MAAQ,CAACA,EAAI,QAI9D,QAAQ,QAAQ,QAAQqG,CAAQ,EAAE,CACpC,IC1EA,IAgBaG,GAhBbC,GAAAlI,EAAA,kBAGAD,KAIAoH,KACAO,KAQaO,GAAP,MAAOE,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkB1B,EAAiCC,EAAiB,CAC5EU,EAAgB,EAChBE,EAAkB,sBAAsB,EACxC,IAAMc,EAAgD,CAAA,EAClD5H,EAAsB,CAAA,EAE1B,GAAI,OAAO2H,GAAU,UAAYA,IAAU,MAAQA,aAAiBhE,GAAU,MAAM,QAAQgE,CAAK,EAC/F,MAAM,IAAI,UACR,+FAA+F,EAInG,IAAIE,EAAiB,GAErB,GAAI,OAAO5B,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBtC,EAClB,MAAM,IAAI,UAAU,8BAA8B,EAGpD,GAAI,MAAM,QAAQsC,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAqC,EAE3D4B,EAAiB,GAEjB,QAAWtI,KAAQ0G,EAAM,CACvB,GAAI,OAAO1G,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAgD,EAEtE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEqI,EAAQrI,CAAI,EAAI,KAGlB,GAAI,OAAO2G,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,MAE/C,CAGL,IAAI4B,EAAY,GACVC,EAAW,OAAO,oBAAoB9B,CAAI,EAChD,QAAW1G,KAAQ,KAAK,YACtB,GAAIwI,EAAS,QAAQxI,CAAI,IAAM,GAAI,CACjC,IAAMyI,EAAK/B,EAA4D1G,CAAI,GACvEyI,IAAM,MAAQA,aAAarE,KAC7BmE,EAAY,GACZD,EAAiB,GACjBD,EAAQrI,CAAI,EAAIyI,GAKtB,GAAIF,GACF,GAAI,OAAO5B,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,OAGpDlG,EAAUiG,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAAyD,EAI/E,QAAW1G,KAAQ,KAAK,WACtB,GAAI,OAAOoI,EAAMpI,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAIsI,EACF,QAAWtI,KAAQ,KAAK,YACtBqI,EAAQrI,CAAI,EAAI,KAMpB,IAAM0I,EAAU,MAAM,KAAK,QAAQ,IAAIN,EAAOC,EAAS5H,CAAO,EACxDkI,EAA6C,CAAA,EACnD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBzE,EACpBuE,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIxE,EAAOyE,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAArB,EAAgB,sBAAsB,EACtCF,GAAc,EACPqB,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAWA,aAAa,OACXlC,EACAC,EACAC,EACAmC,EAAqB,CAErBzB,EAAgB,EAChBE,EAAkB,yBAAyB,EAE3C,IAAIwB,EACAtI,EAA0B,CAAA,EAE9B,GAAI,OAAOgG,GAAS,UAElB,GADAsC,EAAuBtC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3CD,aAAgB,YAEzB,GADAsC,EAAuBtC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAGpDD,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAC7D,CACA,IAAMxC,EAASwC,EACXuC,EAAa,EACbC,EAAaxC,EAAK,WACtB,GAAI,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAsC,EAAatC,EACT,CAAC,OAAO,cAAcsC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,EAAa,GAAKA,GAAc/E,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAgF,EAAaxC,EAAK,WAAauC,EAC3B,OAAOrC,GAAS,SAAU,CAE5B,GADAsC,EAAatC,EACT,CAAC,OAAO,cAAcsC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,GAAc,GAAKD,EAAaC,EAAahF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAa+E,CAAU,IAAI,EAE7F,GAAI,OAAOF,GAAS,UAAYA,IAAS,KACvCrI,EAAUqI,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3C,OAAOnC,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAgC,UAE7C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,EAEpDqC,EAAuB,IAAI,WAAW9E,EAAQ+E,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAqD,EAI3E,GAAM,CAAChJ,EAASiJ,CAAuB,EAAI,MAAMrJ,GAAoCY,CAAO,EACtF0H,EAAU,MAAMlI,EAAQ,8BAA8B8I,EAAsBG,CAAuB,EACzG,OAAA1B,EAAgB,yBAAyB,EACzCF,GAAc,EACP,IAAIY,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,IAAI,eAAa,CACf,OAAO,KAAK,QAAQ,aACtB,CAEA,IAAI,gBAAc,CAChB,OAAO,KAAK,QAAQ,cACtB,KC7OF,IA2mBaH,GA3mBbmB,GAAApJ,EAAA,kBAGAkI,KAwmBaD,GAA4CA,KC3mBzD,IAAAoB,GAAArJ,EAAA,oBCAA,IAAAsJ,GAAAtJ,EAAA,oBCAA,IAAAuJ,GAAAvJ,EAAA,oBCAA,IAAAwJ,GAAAxJ,EAAA,oBCAA,IAAAyJ,GAAA,GAAAC,GAAAD,GAAA,sBAAAxB,GAAA,UAAAb,GAAA,sBAAAI,EAAA,oBAAAC,EAAA,qBAAAH,EAAA,mBAAAC,GAAA,WAAAlD,EAAA,QAAA5C,EAAA,oBAAA7B,IAAA,IAAA+J,GAAA3J,EAAA,kBAmBAqB,KACAO,KACAwH,KACAjC,KACAkC,KACAC,KACA5B,KACA6B,KACAC,OC3BA,IAAAI,GAAA5J,EAAA,oBCAA,IAAA6J,GAAA,GAAAH,GAAAG,GAAA,aAAAC,KAAA,IAmGMC,GACAC,GA0FCF,GA9LPG,GAAAjK,EAAA,kBAsFAkK,KAUAC,KACAC,KAEML,GAAc,wBACdC,GAAgB,WAAW,MAAM,OAASD,GAE5CC,KAEF,KAAK,UAAaK,GAA2C,CAC3D,GAAM,CAAE,KAAA1E,EAAM,GAAI2E,CAAQ,EAAID,EAAG,KACjC,GAAI,CACF,OAAQ1E,EAAM,CACZ,IAAK,YACH4E,GAAsBD,EAAS,IAAI,EAAE,KACnC,IAAM,CACJE,GAAYF,CAAQ,EAAE,KACpB,IAAM,CACJ,YAAY,CAAE,KAAA3E,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,CACF,EACCA,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,MACF,IAAK,UAAW,CACd,GAAM,CAAE,OAAAwJ,EAAQ,IAAAhJ,CAAI,EAAI6I,EACxBI,GAAOjJ,EAAKgJ,CAAM,EAAE,KAClB,IAAM,CACJ,YAAY,CAAE,KAAA9E,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,YAAa,CAChB,GAAM,CAAE,OAAAiD,CAAO,EAAIoG,EACbK,EAAaC,GAAuB1G,CAAM,EAChD,YAAY,CAAE,KAAAyB,EAAM,IAAKgF,CAAW,CAAmB,EACvD,KACF,CACA,IAAK,SAAU,CACb,GAAM,CAAE,MAAAE,EAAO,QAAAnK,CAAQ,EAAI4J,EAC3BQ,GAAcD,EAAOnK,CAAO,EAAE,KAC3BqK,GAAoB,CACnB,YAAY,CAAE,KAAApF,EAAM,IAAKoF,CAAgB,CAAmB,CAC9D,EACC9J,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,UACH+J,GAAeV,CAAQ,EACvB,YAAY,CAAE,KAAA3E,CAAK,CAAC,EACpB,MACF,IAAK,MAAO,CACV,GAAM,CAAE,UAAAsF,EAAW,aAAAC,EAAc,OAAAC,EAAQ,cAAAC,EAAe,QAAA1K,CAAQ,EAAI4J,EACpEe,GAAIJ,EAAWC,EAAcC,EAAQC,EAAe,IAAI,MAAMA,EAAc,MAAM,EAAE,KAAK,IAAI,EAAG1K,CAAO,EAAE,KACtG4K,GAAY,CACPA,EAAQ,KAAMC,GAAMA,EAAE,CAAC,IAAM,KAAK,EACpC,YAAY,CAAE,KAAA5F,EAAM,IAAK,iDAAkD,CAAC,EAE5E,YACE,CAAE,KAAAA,EAAM,IAAK2F,CAAQ,EACrBE,GAA2B,CAAC,GAAGL,EAAQ,GAAGG,CAAO,CAAiC,CACpF,CAEJ,EACCrK,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,gBACHwK,GAAanB,CAAQ,EACrB,YAAY,CAAE,KAAA3E,CAAK,CAAC,EACpB,MACF,QACF,CACF,OAAS1E,EAAK,CACZ,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAmB,CAC7C,CACF,GAGK6I,GAAQE,GACX,KACC0B,GACC,IAAI,OAAOA,GAAeC,EAAY,CAAE,KAAqC,UAAW,KAAM5B,EAAY,CAAC,ICjMjH,IAWM6B,GAmCAC,GAiDOF,EAOAG,GAUPC,GAaAC,GAaAC,GAcAC,GAeAC,GAQAC,GAeOC,GAoBPC,GAwBOC,GA1ObnC,GAAApK,EAAA,kBAIA4J,KAOMgC,GAAmB,OAAO,SAAa,IAAc,OAAY,SAAS,OAmC1EC,GAAe,IAA0B,CAE7C,GAAI,IAkCJ,OAAO,OAAO,SAAa,IACtB,SAAS,eAAqC,IAE/C,OAAO,KAAS,IACd,KAAK,UAAU,KACf,MACR,EAOaF,EAAYE,GAAa,EAOzBC,GAAmC,IAA0B,CACxE,GAAIH,GAAa,CAACA,EAAU,WAAW,OAAO,EAC5C,OAAOA,EAAU,UAAU,EAAGA,EAAU,YAAY,GAAG,EAAI,CAAC,CAGhE,EAKMI,GAAe,CAACS,EAAkBC,IAA4B,CAClE,GAAI,CACF,IAAMC,EAAUD,GAAkBd,EAElC,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,SAAWZ,EACxB,MAAQ,CACN,MAAO,EACT,CACF,EAKMI,GAAe,CAACQ,EAAkBC,IAA4B,CAClE,IAAMC,EAAUD,GAAkBd,EAClC,GAAI,CAEF,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,IACb,MAAQ,CACN,MACF,CACF,EAKMP,GAAc,CAACO,EAAkBC,IAA4B,GAAGA,GAAkB,IAAI,GAAGD,CAAQ,GAcjGN,GAAU,MAAOS,GAAyC,CAE9D,IAAMC,EAAO,MADI,MAAM,MAAMD,EAAa,CAAE,YAAa,aAAc,CAAC,GAC5C,KAAK,EACjC,OAAO,IAAI,gBAAgBC,CAAI,CACjC,EAWMT,GAAuB,MAAUU,IACpC,MAAM,6BAAiCA,IAAM,QAO1CT,GAEwC,cAA+B,QAahEC,GAAoB,SAAmD,CAClF,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,sEAAsE,EAIxF,GAAII,GAAaJ,CAAS,EACxB,MAAO,CAAC,OAAWS,GAAmB,CAAC,EAIzC,IAAMS,EAAM,MAAMX,GAAQP,CAAS,EACnC,MAAO,CAACkB,EAAKT,GAAmBS,CAAG,CAAC,CACtC,EAOMP,GAUA,OAcOC,GAAmB,MAC9Bb,EACAe,EACAK,EACAC,IAC0E,CAM1E,IAAIC,EAAoBV,IAAsB,EAAEZ,GAAee,GAC/D,GAAIO,EACF,GAAKrB,EAyBHqB,EAAoBjB,GAAaJ,CAAS,UAPtCoB,GAAoB,CAACD,EACvBE,EAAoB,OAEpB,OAAM,IAAI,MAAM,yCAAyC,EAO/D,GAAIA,EACF,MAAO,CAAC,OAAWV,EAAmB,EACjC,CACL,IAAMW,EAGA,sCAEAC,EAAgBxB,GAAeM,GAAaiB,EAAoBR,CAAc,EAW9EU,EAAc,CAAC,IAAUL,GAAmBI,GAAiB,CAACnB,GAAamB,EAAeT,CAAc,EACxGI,EAAMM,EACR,MAAMjB,GAAQgB,CAAa,EAC1BA,GAAiBjB,GAAYgB,EAAoBR,CAAc,EACpE,MAAO,CAACU,EAAcN,EAAM,OAAW,MAAMV,GAA6DU,CAAG,CAAC,CAChH,CACF,IC5SA,IAQIO,GACAC,GACAC,GACAC,GAEEC,GA0BAC,GA2BAC,GA4BOnD,GA4IAoD,EA1ObxD,GAAAnK,EAAA,kBAMAoK,KAGIiD,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAE5C,GAAI,OAAO,kBAAsB,IAC/B,MAAO,GAGT,GAAI,CAGF,OAAI,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAG,IAAK,GAC3G,EAAG,EAAG,GAAI,EACZ,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,GAAI,EAAG,GAAI,EAAG,IAAK,GAAI,IAAK,GAAI,EAAG,EAAG,EAC7G,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,IAAK,IAAK,EAAG,GAAI,EAC1D,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAyB,IAAe,CAC5C,GAAI,CAgBF,OAAO,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,IAAK,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,GAAI,EAAG,GAAI,EAAG,IAAK,GAAI,GAAI,EAAG,IAC1G,GAAI,GAAI,EAAG,IAAK,GAAI,IAAK,IAAK,EAAG,EACnC,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEanD,GAAwB,MAAOqD,GAA+C,CACzF,GAAIP,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAoD,EAGtED,GAAe,GAGf,IAAMO,EAAUD,EAAM,YAClBE,EAAaF,EAAM,WAGvB,GAAIA,EAAM,OAAS,IAEZ,GAAIA,EAAM,OAAS,WAExB,GAAI,CAACF,GAAuB,EAC1B,MAAM,IAAI,MAAM,uEAAuE,UAEhF,CAACD,GAAgB,EAC1B,MAAM,IAAI,MAAM,+DAA+D,EAIjF,IAAMM,EAAuBP,GAAuB,EAChDM,EAAa,GAAK,CAACC,IACjB,OAAO,KAAS,KAAe,CAAC,KAAK,qBAEvC,QAAQ,KACN,iCACED,EACA,uIAEJ,EAIF,QAAQ,KACN,4GACF,EAGAF,EAAM,WAAaE,EAAa,GAGlC,IAAME,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAuBF,GAAiC,IACxDG,EAAmBD,GAA6B,MAAQA,EACxDE,EAAwBJ,GAAiC,KACzDK,EAAoBD,GAA8B,MAAQA,EAC1DE,EAAqBV,EAAM,WAE3B,CAACW,EAAWC,CAAc,EAAI,MAAMjC,GACxC4B,EACAF,EACAH,EAAa,EACb,CAAC,CAACQ,GAAsB,CAAC,CAACD,CAC5B,EAEII,EAAY,GAEVC,EAA8B,CAAC,EAmErC,GAhEIb,EAAU,GACZa,EAAM,KACJ,IAAI,QAAS3J,GAAY,CACvB,WAAW,IAAM,CACf0J,EAAY,GACZ1J,EAAQ,CACV,EAAG8I,CAAO,CACZ,CAAC,CACH,EAIFa,EAAM,KACJ,IAAI,QAAQ,CAAC3J,EAASC,IAAW,CAC/B,IAAM2J,EAAiC,CAKrC,WAAAb,CACF,EAEA,GAAIQ,EAEFK,EAAO,WAAaL,UACXD,GAAoBJ,EAI7BU,EAAO,WAAcC,GAAaP,GAAoBJ,EAAqBW,UAClET,GAAmBA,EAAgB,QAAQ,OAAO,IAAM,EAEjEQ,EAAO,WAAcC,GAAa,IAAI,IAAIA,EAAUT,CAAe,EAAE,aAC5DI,EAAW,CACpB,IAAMM,EAAyB/C,GAAiC,EAC5D+C,IAEFF,EAAO,WAAcC,GAAaC,EAAyBD,EAE/D,CAEAJ,EAAeG,CAAM,EAAE,KAEpBG,GAAW,CACVxB,GAAe,GACfD,GAAc,GACdD,GAAO0B,EACP/J,EAAQ,EACJwJ,GACF,IAAI,gBAAgBA,CAAS,CAEjC,EAECQ,GAAS,CACRzB,GAAe,GACfC,GAAU,GACVvI,EAAO+J,CAAI,CACb,CACF,CACF,CAAC,CACH,EAEA,MAAM,QAAQ,KAAKL,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DZ,CAAO,IAAI,CAE1F,EAEaF,EAAc,IAAqB,CAC9C,GAAIN,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IChPA,IAKa4B,EAeAC,GAgCAC,EApDbC,GAAAnP,EAAA,kBAGAmK,KAEa6E,EAAkB,CAACtK,EAAc0K,IAA6B,CACzE,IAAMhC,EAAOO,EAAY,EAEnB0B,EAAajC,EAAK,gBAAgB1I,CAAI,EAAI,EAC1C4K,EAAalC,EAAK,QAAQiC,CAAU,EAC1C,OAAAjC,EAAK,aAAa1I,EAAM4K,EAAYD,CAAU,EAC9CD,EAAO,KAAKE,CAAU,EAEfA,CACT,EAMaL,GAAsB,CACjCvO,EACA6O,EACAC,EACApH,IACS,CACT,GAAI,OAAO1H,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAI8O,EAAK,IAAI9O,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/C8O,EAAK,IAAI9O,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACmI,EAAKlH,CAAK,IAAM,CAChD,IAAM1B,EAAOsP,EAASA,EAAS1G,EAAMA,EACrC,GAAI,OAAOlH,GAAU,SACnBsN,GAAoBtN,EAAkC1B,EAAO,IAAKuP,EAAMpH,CAAO,UACtE,OAAOzG,GAAU,UAAY,OAAOA,GAAU,SACvDyG,EAAQnI,EAAM0B,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1ByG,EAAQnI,EAAM0B,EAAQ,IAAM,GAAG,MAE/B,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMauN,EAAkB5E,GAA0B,CACvD,IAAM8C,EAAOO,EAAY,EAEnB5F,EAAQqF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMqC,EAAUrC,EAAK,SACfsC,EAAetC,EAAK,WAAW,EAAIqC,CAAO,EAChDrC,EAAK,iBAAiBsC,EAAcA,EAAeD,CAAO,EAC1D,IAAME,EAAY,OAAOvC,EAAK,SAASsC,EAAcD,IAAY,EAAI,MAAQ,KAAK,CAAC,EAC7EG,EAAsBxC,EAAK,SAASsC,EAAeD,EAAS,GAAG,EAC/DI,EAAeD,EAAsBxC,EAAK,aAAawC,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGtF,CAAO,gBAAgBqF,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAzC,EAAK,aAAarF,CAAK,CACzB,CACF,ICnEA,IAQa+H,GARbC,GAAA/P,EAAA,kBAKAmK,KACAgF,KAEaW,GAAiBpP,GAA6D,CACzF,IAAM0M,EAAOO,EAAY,EACrBqC,EAAmB,EACjBZ,EAAmB,CAAC,EAEpBa,EAA0CvP,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCuP,EAAW,iBAAmB,UAE9B,OAAOvP,EAAQ,kBAAqB,UACpC,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1CA,EAAQ,iBAAmB,GAC3BA,EAAQ,iBAAmB,EAE3B,MAAM,IAAI,MAAM,oCAAoCA,EAAQ,gBAAgB,EAAE,EAGhF,GAAIA,GAAS,oBAAsB,OACjCuP,EAAW,kBAAoB,UACtB,OAAOvP,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBuP,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIxP,GAAS,MAAQ,SACnBwP,EAAgBlB,EAAgBtO,EAAQ,IAAK0O,CAAM,GAGrDY,EAAmB5C,EAAK,qBACtB6C,EAAW,iBACXA,EAAW,kBACX,CAAC,CAACA,EAAW,UACbC,CACF,EACIF,IAAqB,GACvBd,EAAe,2BAA2B,EAGxCxO,GAAS,QAAU,QACrBuO,GAAoBvO,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACmI,EAAKlH,IAAU,CAC7F,IAAMwO,EAAgBnB,EAAgBnG,EAAKuG,CAAM,EAC3CgB,EAAkBpB,EAAgBrN,EAAOyN,CAAM,EAEjDhC,EAAK,sBAAsB4C,EAAkBG,EAAeC,CAAe,IAAM,GACnFlB,EAAe,iCAAiCrG,CAAG,MAAMlH,CAAK,GAAG,CAErE,CAAC,EAGI,CAACqO,EAAkBZ,CAAM,CAClC,OAAS3O,EAAG,CACV,MAAIuP,IAAqB,GACvB5C,EAAK,sBAAsB4C,CAAgB,EAE7CZ,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EACrC5P,CACR,CACF,ICvEA,IAQM6P,GAiBAC,GAWAC,GAsBAC,GAQAC,GAMAC,GA+FOC,GAvKbC,GAAA7Q,EAAA,kBAKAmK,KACAgF,KAEMmB,GAA4BQ,GAAqD,CACrF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMP,GAAoBQ,GAAqD,CAC7E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMP,GAAwB9P,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMsQ,EAAUtQ,EAAQ,MAAM,QACzBsQ,EAAQ,+BAEXA,EAAQ,6BAA+B,KAKvCtQ,EAAQ,oBACRA,EAAQ,mBAAmB,KAAMuQ,IAAQ,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAE5FvQ,EAAQ,iBAAmB,GAE/B,EAEM+P,GAAsB,CAACS,EAA8BrI,EAAalH,EAAeyN,IAA2B,CAChH,IAAMe,EAAgBnB,EAAgBnG,EAAKuG,CAAM,EAC3CgB,EAAkBpB,EAAgBrN,EAAOyN,CAAM,EACjDzB,EAAY,EAAE,0BAA0BuD,EAAsBf,EAAeC,CAAe,IAAM,GACpGlB,EAAe,qCAAqCrG,CAAG,MAAMlH,CAAK,GAAG,CAEzE,EAEM+O,GAAiB,CAACS,EAAoCtI,EAAalH,EAAeyN,IAA2B,CACjH,IAAMe,EAAgBnB,EAAgBnG,EAAKuG,CAAM,EAC3CgB,EAAkBpB,EAAgBrN,EAAOyN,CAAM,EACrD+B,EAAU,KAAK,CAAChB,EAAeC,CAAe,CAAC,CACjD,EAEMO,GAAwB,MAC5BO,EACAE,EACAhC,IACkB,CAClB,QAAW6B,KAAMG,EAAoB,CACnC,IAAI3G,EAAS,OAAOwG,GAAO,SAAWA,EAAKA,EAAG,KACxCE,EAAqC,CAAC,EAG5C,OAAQ1G,EAAQ,CACd,IAAK,QAEH,GADAA,EAAS,QACL,OAAOwG,GAAO,SAAU,CAG1B,IAAMtJ,EAFesJ,GAEsD,WACvEtJ,GACF8I,GAAoBS,EAAsB,aAAcvJ,EAAYyH,CAAM,CAE9E,CACA,MACF,IAAK,SAC6B,CAC9B3E,EAAS,SACT,IAAI4G,EAEJ,GAAI,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAgBL,EACtB,GAAIK,EAAc,OAChB,GAAI,OAAO,UAAc,KAAeA,EAAc,kBAAkB,UACtED,EAAeC,EAAc,WAE7B,OAAM,IAAI,MAAM,8CAA8C,CAKpE,CAEA,IAAMC,EAAO5D,EAAY,EAAE,qBAAsB0D,CAAY,EAC7D,GAAIE,EAAM,CACR,GAAM,CAACC,EAAUC,EAAgBC,CAAY,EAAIH,EACjDb,GAAeS,EAAW,WAAYK,EAAS,SAAS,EAAGpC,CAAM,EACjEsB,GAAeS,EAAW,iBAAkBM,EAAe,SAAS,EAAGrC,CAAM,EAC7EsB,GAAeS,EAAW,eAAgBO,EAAa,SAAS,EAAGtC,CAAM,CAC3E,CACF,CAYA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqC3E,CAAM,EAAE,CACjE,CAEA,IAAMkH,EAAmB3C,EAAgBvE,EAAQ2E,CAAM,EACjDwC,EAAiBT,EAAU,OAC7BU,EAAa,EACbC,EAAe,EACnB,GAAIF,EAAiB,EAAG,CACtBC,EAAalE,EAAY,EAAE,QAAQiE,EAAiBjE,EAAY,EAAE,QAAQ,EAC1EyB,EAAO,KAAKyC,CAAU,EACtBC,EAAenE,EAAY,EAAE,QAAQiE,EAAiBjE,EAAY,EAAE,QAAQ,EAC5EyB,EAAO,KAAK0C,CAAY,EACxB,QAASzR,EAAI,EAAGA,EAAIuR,EAAgBvR,IAClCsN,EAAY,EAAE,SAASkE,EAAaxR,EAAIsN,EAAY,EAAE,SAAUwD,EAAU9Q,CAAC,EAAE,CAAC,EAAG,GAAG,EACpFsN,EAAY,EAAE,SAASmE,EAAezR,EAAIsN,EAAY,EAAE,SAAUwD,EAAU9Q,CAAC,EAAE,CAAC,EAAG,GAAG,CAE1F,CAEG,MAAMsN,EAAY,EAAE,4BACnBuD,EACAS,EACAE,EACAC,EACAF,CACF,IAAO,GAEP1C,EAAe,oCAAoCzE,CAAM,GAAG,CAEhE,CACF,EAEamG,GAAoB,MAAOlQ,GAA2E,CACjH,IAAM0M,EAAOO,EAAY,EACrBuD,EAAuB,EACrB9B,EAAmB,CAAC,EAEpB2C,EAAkDrR,GAAW,CAAC,EACpE8P,GAAqBuB,CAAc,EAEnC,GAAI,CACF,IAAMjB,EAAyBR,GAAyByB,EAAe,wBAA0B,KAAK,EAChGhB,EAAgBR,GAAiBwB,EAAe,eAAiB,YAAY,EAC7EC,EACJ,OAAOD,EAAe,OAAU,SAAW/C,EAAgB+C,EAAe,MAAO3C,CAAM,EAAI,EAEvF6C,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,oCAAoCA,CAAgB,EAAE,EAGxE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EACJ,OAAOJ,EAAe,wBAA2B,SAC7C/C,EAAgB+C,EAAe,uBAAwB3C,CAAM,EAC7D,EAsBN,GApBA8B,EAAuB9D,EAAK,yBAC1B0D,EACA,CAAC,CAACiB,EAAe,kBACjB,CAAC,CAACA,EAAe,iBACjBhB,EACA,CAAC,CAACgB,EAAe,gBACjB,EACAC,EACAC,EACAC,EACAC,CACF,EACIjB,IAAyB,GAC3BhC,EAAe,+BAA+B,EAG5C6C,EAAe,oBACjB,MAAMpB,GAAsBO,EAAsBa,EAAe,mBAAoB3C,CAAM,EAGzF2C,EAAe,qBAAuB,OAAW,CACnD,GAAI,OAAOA,EAAe,oBAAuB,UAC/C,MAAM,IAAI,MAAM,+CAA+CA,EAAe,kBAAkB,EAAE,EAEpGtB,GACES,EACA,qBACAa,EAAe,mBAAmB,SAAS,EAC3C3C,CACF,CACF,CAEA,GAAI2C,EAAe,uBACjB,OAAW,CAAC9R,EAAM0B,CAAK,IAAK,OAAO,QAAQoQ,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAO9R,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAO0B,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMyQ,EAAapD,EAAgB/O,EAAMmP,CAAM,EAC3ChC,EAAK,6BAA6B8D,EAAsBkB,EAAYzQ,CAAK,IAAM,GACjFuN,EAAe,wCAAwCjP,CAAI,MAAM0B,CAAK,GAAG,CAE7E,CAGF,OAAIoQ,EAAe,QAAU,QAC3B9C,GAAoB8C,EAAe,MAAO,GAAI,IAAI,QAAoC,CAAClJ,EAAKlH,IAAU,CACpG8O,GAAoBS,EAAsBrI,EAAKlH,EAAOyN,CAAM,CAC9D,CAAC,EAGI,CAAC8B,EAAsB9B,CAAM,CACtC,OAAS3O,EAAG,CACV,MAAIyQ,IAAyB,GACvB9D,EAAK,0BAA0B8D,CAAoB,IAAM,GAC3DhC,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EACrC5P,CACR,CACF,ICnQA,IA2Ca4R,GAyCAC,GA0CAC,GAqCAC,GAgDAC,GAoBAC,GAcAC,GAgBAC,GArQbC,GAAA7S,EAAA,kBA2CaqS,GAA8B1M,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,OACH,MAAO,IACT,IAAK,QACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKa2M,GAA8BQ,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,OACT,IAAK,IACH,MAAO,QAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaP,GAA6B,CACxCQ,EACAC,IACuB,CACvB,IAAMC,EAAc,CAClB,GACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,GACA,EACA,EACA,EACA,EACA,EACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,EACF,EAAEF,CAAQ,EAEJvM,EAAO,OAAOwM,GAAe,SAAWA,EAAaA,EAAW,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAC/F,OAAOF,EAAc,EAAI,KAAK,KAAKzM,EAAOyM,CAAW,EAAI,MAC3D,EAKaT,GACX7M,GAY+B,CAC/B,OAAQA,EAAM,CACZ,IAAK,UAEH,OAAO,OAAO,aAAiB,KAAe,aAAa,KAAO,aAAe,YACnF,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKa8M,GAAwBW,GAA0E,CAC7G,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaV,GAA4B/M,GACvCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKEgN,GAA2BhN,GACtCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKEiN,GAA4BS,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,YACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,ICtRA,IAWaC,GAXbC,GAAAvT,EAAA,kBAGA4J,KAQa0J,GAAW,MAAOE,GAA4E,CACzG,GAAI,OAAOA,GAAS,SAClB,GAAI,GAEF,GAAI,CACF,GAAM,CAAE,SAAAC,CAAS,EAAI,GAAQ,kBAAkB,EAC/C,OAAO,IAAI,WAAW,MAAMA,EAASD,CAAI,CAAC,CAC5C,OAAS,EAAG,CACV,GAAI,EAAE,OAAS,wBAAyB,CAEtC,GAAM,CAAE,iBAAAE,CAAiB,EAAI,GAAQ,SAAS,EACxCC,EAASD,EAAiBF,CAAI,EAC9BI,EAAuB,CAAC,EAC9B,cAAiBC,KAASF,EACxBC,EAAO,KAAKC,CAAK,EAEnB,OAAO,IAAI,WAAW,OAAO,OAAOD,CAAM,CAAC,CAC7C,CACA,MAAM,CACR,KACK,CAEL,IAAME,EAAW,MAAM,MAAMN,CAAI,EACjC,GAAI,CAACM,EAAS,GACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,EAAE,EAE9D,IAAMO,EAAsBD,EAAS,QAAQ,IAAI,gBAAgB,EAC3DE,EAAWD,EAAsB,SAASA,EAAqB,EAAE,EAAI,EAC3E,GAAIC,EAAW,WAGb,OAAO,IAAI,WAAW,MAAMF,EAAS,YAAY,CAAC,EAC7C,CAEL,GAAI,CAACA,EAAS,KACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,qBAAqB,EAEjF,IAAMS,EAASH,EAAS,KAAK,UAAU,EAEnC5P,EACJ,GAAI,CAEFA,EAAS,IAAI,YAAY8P,CAAQ,CACnC,OAASvT,EAAG,CACV,GAAIA,aAAa,WAAY,CAE3B,IAAMyT,EAAQ,KAAK,KAAKF,EAAW,KAAK,EACxC9P,EAAS,IAAI,YAAY,OAAO,CAAE,QAASgQ,EAAO,QAASA,CAAM,CAAC,EAAE,MACtE,KACE,OAAMzT,CAEV,CAEA,IAAI0T,EAAS,EAEb,OAAa,CACX,GAAM,CAAE,KAAAC,EAAM,MAAAzS,CAAM,EAAI,MAAMsS,EAAO,KAAK,EAC1C,GAAIG,EACF,MAEF,IAAMC,EAAY1S,EAAM,WACV,IAAI,WAAWuC,EAAQiQ,EAAQE,CAAS,EAChD,IAAI1S,CAAK,EACfwS,GAAUE,CACZ,CACA,OAAO,IAAI,WAAWnQ,EAAQ,EAAG8P,CAAQ,CAC3C,CACF,KACK,QAAIR,aAAgB,KAClB,IAAI,WAAW,MAAMA,EAAK,YAAY,CAAC,EACrCA,aAAgB,WAClBA,EAEA,IAAI,WAAWA,CAAI,CAE9B,ICtFA,IAOac,GAPbC,GAAAvU,EAAA,kBAKA6S,KAEayB,GAAa,CACxBE,EACA7O,IAWiB,IAAK6M,GAAkC7M,CAAI,GAAG6O,CAAU,ICpB3E,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,EAzCbC,GAAAhV,EAAA,kBAKA6S,KAOM4B,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACO,EAAe3K,IAA0B,CAEtD,QAAQ,IAAI,IAAImK,GAAeQ,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAI3K,CAAO,EAAE,CAChF,EAKauK,GAAkB,CAACK,EAA2BC,IAA0B,CACnFR,GAAiBO,EACjBN,GAAQO,CACV,EAKaL,GAAM,CAAC1B,EAAoBvL,IAAuB,CAC7D,IAAMuN,EAAe3C,GAAqBW,CAAQ,EAC5CiC,EAAc5C,GAAqBkC,EAAc,EACnDS,GAAgBC,GAClBX,GAAMU,EAAc,OAAOvN,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKakN,EAAwB,IAAIO,IAAiC,CACpEV,IACFE,GAAI,GAAGQ,CAAI,CAEf,IC7CA,IAeMC,GAeOC,GAyDAC,GA8FTC,GACEC,GAOAC,GAUAC,GAWAC,GAsGAC,GAuIAC,GAkKOC,GAjmBbC,GAAAlW,EAAA,kBAIA6S,KACAmC,KAUMO,GAAsB,IAAI,IAA+B,CAC7D,CAAC,UAAW,EAAE,EACd,CAAC,UAAW,EAAE,EACd,CAAC,QAAS,EAAE,EACZ,CAAC,SAAU,EAAE,EACb,CAAC,QAAS,EAAE,EACZ,CAAC,SAAU,EAAE,EACb,CAAC,OAAQ,CAAC,EACV,CAAC,QAAS,CAAC,EACX,CAAC,OAAQ,CAAC,EACV,CAAC,QAAS,CAAC,CACb,CAAC,EAIYC,GAAqB,CAAC9Q,EAAkBe,IAA4C,CAC/F,GAAIA,IAAa,QACf,OAAOf,EAGT,IAAMyR,EAAeZ,GAAoB,IAAI9P,CAAQ,EACrD,GAAI,CAAC0Q,EACH,MAAM,IAAI,MAAM,6CAA6C1Q,CAAQ,EAAE,EAEzE,IAAM2Q,EAAkBD,EAAe,EAEvC,GAAIzR,EAAK,WAAa0R,IAAoB,EACxC,MAAM,IAAI,MAAM,qDAAqDA,CAAe,GAAG,EAIzF,IAAMC,EAAc3R,EAAK,WAAa0R,EAChCE,EAAgB,IAAK9D,GAAkC/M,CAAQ,GAAGf,EAAK,OAAQA,EAAK,WAAY2R,CAAW,EAEjH,OAAQ5Q,EAAU,CAChB,IAAK,QACL,IAAK,SAAU,CAEb,IAAM8Q,EAAa,IAAI,WAAWF,CAAW,EAC7C,QAAS,EAAI,EAAG,EAAIA,EAAa,IAAK,CACpC,IAAM1U,EAAQ2U,EAAc,CAAC,EAG7B,GAAI3U,EAAQ,aAAeA,EAAQ,CAAC,YAClC,MAAM,IAAI,MAAM,2DAA2D,EAG7E4U,EAAW,CAAC,EAAI,OAAO5U,CAAK,CAC9B,CAEA,OAAO,IAAI,WAAW4U,EAAW,MAAM,CACzC,CACA,IAAK,OACL,IAAK,QACL,IAAK,SAAU,CAEb,GAAI9Q,IAAa,UACX6Q,EAAc,KAAM3U,GAAUA,EAAQ,UAAU,EAClD,MAAM,IAAI,MAAM,4DAA4D,EAIhF,IAAM4U,EAAa,WAAW,KAAKD,EAAe,MAAM,EACxD,OAAO,IAAI,WAAWC,EAAW,MAAM,CACzC,CACA,QACE,MAAM,IAAI,MAAM,oCAAoC9Q,CAAQ,aAAa,CAC7E,CACF,EAIagQ,GAAqB,CAAC/Q,EAAkBe,IAA4C,CAC/F,GAAIA,IAAa,QACf,OAAOf,EAIT,GAAIA,EAAK,WAAa,IAAM,EAC1B,MAAM,IAAI,MAAM,8DAA8D,EAIhF,IAAM2R,EAAc3R,EAAK,WAAa,EAChC6R,EAAa,IAAI,WAAW7R,EAAK,OAAQA,EAAK,WAAY2R,CAAW,EAE3E,OAAQ5Q,EAAU,CAChB,IAAK,QAAS,CACZ,IAAM+Q,EAAgB,cAAc,KAAKD,EAAY,MAAM,EAC3D,OAAO,IAAI,WAAWC,EAAc,MAAM,CAC5C,CACA,IAAK,SAAU,CACb,GAAID,EAAW,KAAM5U,GAAUA,EAAQ,CAAC,EACtC,MAAM,IAAI,MAAM,6DAA6D,EAE/E,IAAM8U,EAAiB,eAAe,KAAKF,EAAY,MAAM,EAC7D,OAAO,IAAI,WAAWE,EAAe,MAAM,CAC7C,CACA,IAAK,OAAQ,CACX,GAAIF,EAAW,KAAM5U,GAAUA,EAAQ,MAAQA,EAAQ,GAAG,EACxD,MAAM,IAAI,MAAM,0DAA0D,EAE5E,IAAM+U,EAAY,UAAU,KAAKH,EAAY,MAAM,EACnD,OAAO,IAAI,WAAWG,EAAU,MAAM,CACxC,CACA,IAAK,QAAS,CACZ,GAAIH,EAAW,KAAM5U,GAAUA,EAAQ,GAAKA,EAAQ,GAAG,EACrD,MAAM,IAAI,MAAM,2DAA2D,EAE7E,OAAO,WAAW,KAAK4U,EAAY,MAAM,CAC3C,CACA,IAAK,SAAU,CACb,GAAIA,EAAW,KAAM5U,GAAUA,EAAQ,CAAC,EACtC,MAAM,IAAI,MAAM,8DAA8D,EAEhF,IAAMgV,EAAc,YAAY,KAAKJ,EAAY,MAAM,EACvD,OAAO,IAAI,WAAWI,EAAY,MAAM,CAC1C,CACA,QACE,MAAM,IAAI,MAAM,+CAA+ClR,CAAQ,EAAE,CAC7E,CACF,EA6CIiQ,GAAa,EACXC,GAAoB,IAAgBD,KAOpCE,GAA0B,IAAI,IAA0C,CAC5E,CAAC,OAAQ,OAAO,EAChB,CAAC,QAAS,OAAO,EACjB,CAAC,SAAU,OAAO,EAClB,CAAC,QAAS,OAAO,CACnB,CAAC,EAKKC,GAAsB,CAACpQ,EAA6BmR,IAAqC,CAC7F,IAAMT,EAAeZ,GAAoB,IAAI9P,CAAQ,EACrD,GAAI,CAAC0Q,EACH,MAAM,IAAI,MAAM,6CAA6C1Q,CAAQ,EAAE,EAEzE,OAAOmR,EAAM,OAAS,EAAI,KAAK,KAAMA,EAAM,OAAO,CAAC1D,EAAGC,IAAMD,EAAIC,CAAC,EAAIgD,EAAgB,CAAC,EAAI,CAC5F,EAKML,GAAN,KAAoB,CAalB,YAAYe,EAOT,CAhBH,KAAO,gBAAkB,GAiBvB,GAAM,CAAE,UAAA5L,EAAW,QAAAhG,EAAS,OAAAjD,EAAQ,SAAAyD,EAAU,MAAAmR,EAAO,iBAAAE,CAAiB,EAAID,EAC1E,KAAK,UAAY5L,EACjB,KAAK,UAAYhG,EACjB,KAAK,SAAWjD,EAChB,KAAK,SAAWyD,EAChB,KAAK,YAAcmR,EACnB,KAAK,iBAAmBE,CAC1B,CAEA,IAAW,QAAmB,CAC5B,OAAO,KAAK,QACd,CAEA,IAAW,MAA0B,CACnC,OAAO,KAAK,QACd,CAEA,IAAW,cAA8C,CACvD,OAAO,KAAK,gBACd,CAEA,IAAW,OAA2B,CACpC,OAAO,KAAK,WACd,CAEA,IAAW,YAAqB,CAC9B,OAAOjB,GAAoB,KAAK,SAAU,KAAK,WAAW,CAC5D,CAEO,SAAgB,CACrBd,EAAU,UAAW,IAAM,+BAA+B,EAC1D,KAAK,SAAS,QAAQ,CACxB,CAEO,MAAMrQ,EAAwB,CACnC,KAAK,UAAU,YAAY,KAAK,SAAUA,CAAI,CAChD,CAIA,MAAa,KAAKqS,EAA6E,CAC7F,GAAI,KAAK,iBAAkB,CAEzB,IAAMrS,EAAO,MAAM,KAAK,UAAU,WAAW,KAAK,QAAQ,EACpDsS,EAAevB,GAAmB,IAAI,WAAW/Q,CAAI,EAAG,KAAK,QAAQ,EAE3E,GAAIqS,EAAW,EAEXA,aAAqB,YACjB,IAAI,WAAWA,CAAS,EACxB,IAAI,WAAWA,EAAU,OAAQA,EAAU,WAAYA,EAAU,UAAU,GACpE,IAAIC,CAAY,EAC7B,MACF,KACE,QAAOA,EAAa,MAExB,KACE,QAAOD,EAAY,KAAK,UAAU,WAAW,KAAK,SAAUA,CAAS,EAAI,KAAK,UAAU,WAAW,KAAK,QAAQ,CAEpH,CAEO,eAAe9R,EAAoBQ,EAA6BmR,EAAmC,CACxG,OACE,KAAK,YAAc3R,GACnB,KAAK,WAAaQ,GAClB,KAAK,YAAY,SAAWmR,EAAM,QAClC,KAAK,YAAY,MAAM,CAAClO,EAAGrI,IAAMqI,IAAMkO,EAAMvW,CAAC,CAAC,CAEnD,CAEO,mBAAmB4W,EAA4B,CACpD,KAAK,gBAAkBA,CACzB,CACF,EAQMlB,GAAN,KAAsB,CAGpB,YACUmB,EACAC,EACR,CAFQ,mBAAAD,EACA,aAAAC,CACP,CAEH,IAAW,eAA2C,CACpD,OAAO,KAAK,OACd,CAEO,eAAsB,CACvB,KAAK,gBACP,KAAK,cAAc,cAAc,KAAK,aAAa,EACnD,KAAK,QAAU,OAEnB,CAEA,MAAa,aACXlM,EACAxF,EACAmR,EACAQ,EACmB,CACnB,IAAMnS,EAAU,KAAK,cAAc,aAAagG,CAAS,EACrD6L,EAEJ,GAAI,CAAC7R,EAAQ,gBAAgB,EAAE,MAAM,UAAU,SAASQ,CAAQ,EAAG,CAEjE,GADAqR,EAAmBlB,GAAwB,IAAInQ,CAAQ,EACnD,CAACqR,GAAoB,CAAC7R,EAAQ,gBAAgB,EAAE,MAAM,UAAU,SAAS6R,CAAgB,EAC3F,MAAM,IAAI,MAAM,6CAA6CrR,CAAQ,EAAE,EAEzEsP,EACE,UACA,IAAM,gEAAgEtP,CAAQ,OAAOqR,CAAgB,EACvG,CACF,CAEA,GAAI,KAAK,QAAS,CAChB,GAAI,KAAK,QAAQ,eAAe7R,EAASQ,EAAUmR,CAAK,EACtD,OAAO,KAAK,QAAQ,OAEpB,GAAIQ,EAAS,CACX,GAAI,KAAK,QAAQ,aAAevB,GAAoBpQ,EAAUmR,CAAK,EACjE,MAAM,IAAI,MAAM,oDAAoD,EAEtE,KAAK,aAAe,IAAI,WAAW,MAAM,KAAK,QAAQ,KAAK,CAAC,CAC9D,CACA,KAAK,cAAc,cAAc,KAAK,OAAO,CAEjD,CAGA,IAAMS,EAAQ,OAAO,cAAiB,IAAc,OAAY,cAAc,KAAO,cAAc,MACnG,YAAK,QAAU,MAAM,KAAK,cAAc,gBACtCpM,EACAxF,EACAmR,EACAS,EACA,GACA,GACAP,CACF,EAEIM,GAAW,KAAK,eAGlB,KAAK,QAAQ,MAAM,KAAK,YAAY,EACpC,KAAK,aAAe,QAGf,KAAK,QAAQ,MACtB,CAEO,OAAO1S,EAAwB,CACpC,IAAI4S,EAAU5S,EACd,GAAI,KAAK,QAAS,CAChB,GAAI,KAAK,QAAQ,aACf,GAAI,KAAK,QAAQ,eAAiB,QAEhC4S,EAAU9B,GAAmB9Q,EAAM,KAAK,QAAQ,IAAI,EACpD,KAAK,QAAQ,mBAAmB,EAAI,MAEpC,OAAM,IAAI,MAAM,mCAAmC,KAAK,QAAQ,YAAY,EAAE,EAKlF,GAAIA,EAAK,aAAe,KAAK,QAAQ,WAAY,CAE/C,KAAK,QAAQ,MAAM4S,CAAO,EAC1B,MACF,MACEvC,EAAU,UAAW,IAAM,yDAAyD,EACpF,KAAK,cAAc,CAEvB,CAEI,KAAK,aACP,KAAK,aAAa,IAAIuC,CAAO,EAE7B,KAAK,aAAe,IAAI,WAAWA,CAAO,CAE9C,CAEA,MAAa,SAASP,EAA6E,CACjG,GAAI,KAAK,aAAc,CAErB,IAAMQ,EAAU,KAAK,SAAS,gBAC1B9B,GAAmB,KAAK,aAAc,KAAK,SAAS,IAAI,EACxD,KAAK,aAET,GAAIsB,EAAW,CACTA,aAAqB,YACvB,IAAI,WAAWA,CAAS,EAAE,IAAIQ,CAAO,EAErC,IAAI,WAAWR,EAAU,OAAQA,EAAU,WAAYA,EAAU,UAAU,EAAE,IAAIQ,CAAO,EAE1F,MACF,KACE,QAAOA,EAAQ,MAEnB,CACA,GAAI,CAAC,KAAK,QACR,MAAM,IAAI,MAAM,8BAA8B,EAGhD,OAAKR,EAGE,KAAK,QAAQ,KAAKA,CAAS,EAFzB,KAAK,QAAQ,KAAK,CAG7B,CACF,EAEMf,GAAN,KAAiD,CAK/C,YAAoB9V,EAAuB,CAAvB,aAAAA,EAJpB,KAAQ,mBAAqD,IAAI,IACjE,KAAQ,YAA+B,CAAC,EACxC,KAAQ,gBAAsC,IAAI,GAEN,CAErC,aAAa+K,EAA8B,CAChD,IAAMhG,EAAU,KAAK,QAAQ,aAAagG,CAAS,EACnD,GAAI,CAAChG,EACH,MAAM,IAAI,MAAM,kCAAkC,EAEpD,OAAOA,CACT,CAEO,iBAA4B,CACjC,IAAMuS,EAAW7B,GAAkB,EACnC,YAAK,mBAAmB,IAAI6B,EAAU,IAAIzB,GAAgB,IAAI,CAAC,EACxDyB,CACT,CAEO,gBAAgBA,EAA0B,CAC/C,IAAMC,EAAgB,KAAK,mBAAmB,IAAID,CAAQ,EACrDC,IAGL,KAAK,mBAAmB,OAAOD,CAAQ,EACnCC,EAAc,eAChB,KAAK,cAAcA,EAAc,aAAa,EAElD,CAEA,MAAa,aACXxM,EACAuM,EACA/R,EACAmR,EACAQ,EACmB,CACnBrC,EACE,UACA,IACE,iDAAiDyC,CAAQ,eACvD/R,CACF,YAAYmR,CAAK,cAAcQ,CAAO,GAC1C,EACA,IAAMpV,EAAS,KAAK,mBAAmB,IAAIwV,CAAQ,EACnD,GAAI,CAACxV,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAOA,EAAO,aAAaiJ,EAAWxF,EAAUmR,EAAOQ,CAAO,CAChE,CAEO,OAAOI,EAAoB9S,EAAwB,CACxD,IAAM1C,EAAS,KAAK,mBAAmB,IAAIwV,CAAQ,EACnD,GAAI,CAACxV,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErCA,EAAO,OAAO0C,CAAI,CACpB,CAIA,MAAM,SAAS8S,EAAoBT,EAA6E,CAC9GhC,EACE,UACA,IAAM,6CAA6CyC,CAAQ,gBAAgBT,GAAW,UAAU,GAClG,EACA,IAAMU,EAAgB,KAAK,mBAAmB,IAAID,CAAQ,EAC1D,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAOA,EAAc,SAASV,CAAS,CACzC,CAEO,yBAAyB9L,EAAyB,CACvD,QAAWjJ,KAAU,KAAK,YACpBA,EAAO,YAAciJ,GACvBjJ,EAAO,QAAQ,EAGnB,KAAK,YAAc,KAAK,YAAY,OAAQA,GAAWA,EAAO,YAAciJ,CAAS,CACvF,CAEO,eACLA,EACAvF,EACAD,EACAmR,EACU,CACV,IAAM3R,EAAU,KAAK,aAAagG,CAAS,EACrCuM,EAAW7B,GAAkB,EAG7BwB,EAAU,IAAIrB,GAAc,CAChC,UAAA7K,EACA,QAAAhG,EACA,OAAQS,EACR,SAAAD,EACA,MAAAmR,CACF,CAAC,EACD,YAAK,mBAAmB,IAAIY,EAAU,IAAIzB,GAAgB,KAAMoB,CAAO,CAAC,EACxE,KAAK,gBAAgB,IAAIA,CAAO,EACzBK,CACT,CAKA,MAAa,gBACXvM,EACAxF,EACAmR,EACAS,EACAK,EACAC,EACAb,EACwB,CACxB,IAAM7R,EAAU,KAAK,aAAagG,CAAS,EAC3C,OAAW,CAAC2M,EAAO5V,CAAM,IAAK,KAAK,YAAY,QAAQ,EACrD,GAAIA,EAAO,eAAeiD,EAASQ,EAAUmR,CAAK,EAAG,CACnD7B,EACE,UACA,IACE,qCAAqCtP,CAAQ,KAC3CqR,EAAmB,qBAAqBA,CAAgB,IAAM,EAChE,WAAWF,CAAK,EACpB,EACA,IAAMO,EAAU,KAAK,YAAY,OAAOS,EAAO,CAAC,EAAE,CAAC,EACnD,OAAAT,EAAQ,UAAYlM,EACbkM,CACT,CAEFpC,EACE,UACA,IACE,6CAA6CtP,CAAQ,KACnDqR,EAAmB,qBAAqBA,CAAgB,IAAM,EAChE,WAAWF,CAAK,GACpB,EACA,IAAM5U,EAAS,MAAMiD,EAAQ,aAAa,CACxC,SAAU6R,GAAoBrR,EAC9B,MAAAmR,EACA,WAAYA,EACZ,MAAAS,EACA,SAAAK,EACA,SAAAC,CACF,CAAC,EACD,OAAO,IAAI7B,GAAc,CAAE,UAAA7K,EAAW,QAAAhG,EAAS,OAAAjD,EAAQ,SAAAyD,EAAU,MAAAmR,EAAO,iBAAAE,CAAiB,CAAC,CAC5F,CAKO,cAAce,EAA8B,CAC7C,KAAK,gBAAgB,IAAIA,CAAa,GACxC,KAAK,gBAAgB,OAAOA,CAAa,EAE3C,KAAK,YAAY,KAAKA,CAAa,CACrC,CACF,EAEa5B,GAAsB,IAAIX,IACrC,IAAIU,GAAkB,GAAGV,CAAI,IClmB/B,IAAAwC,GAAA,GAAApO,GAAAoO,GAAA,kBAAAC,KAAA,IAoBMC,GAoBAC,GAgBOF,GAxDbG,GAAAlY,EAAA,kBAUA6S,KACA1I,KAEAoK,KACA2B,KACAlB,KAKMgD,GAA8B,IAAI,IAAiC,CACvE,GAAiB,SAAS,EAC1B,IAAmB,SAAS,EAC5B,GAAiB,OAAO,EACxB,IAAkB,QAAQ,EAC1B,GAAiB,OAAO,EACxB,IAAkB,QAAQ,EAC1B,IAAgB,MAAM,EACtB,IAAiB,OAAO,EACxB,GAAgB,MAAM,EACtB,GAAiB,OAAO,EACxB,GAAgB,OAAO,CACzB,CAAC,EAQKC,GAA0B,CAAC/E,EAAsBC,IAAkC,CACvF,GAAID,IAAMC,EACR,MAAO,GAET,GAAID,IAAM,QAAaC,IAAM,OAC3B,MAAO,GAET,IAAMgF,EAAQ,OAAO,KAAKjF,CAAC,EAAE,KAAK,EAC5BkF,EAAQ,OAAO,KAAKjF,CAAC,EAAE,KAAK,EAClC,OAAOgF,EAAM,SAAWC,EAAM,QAAUD,EAAM,MAAM,CAACtP,EAAK+O,IAAU/O,IAAQuP,EAAMR,CAAK,GAAK1E,EAAErK,CAAG,IAAMsK,EAAEtK,CAAG,CAAC,CAC/G,EAMakP,GAAN,KAAmB,CA4CxB,YAAYtW,EAAU,CAxCtB,KAAQ,cAAgBwU,GAAoB,IAAI,EAIhD,KAAQ,qBAAuB,IAAI,IAInC,KAAQ,sBAAwB,IAAI,IAIpC,KAAQ,eAAmC,CAAC,EAQ5C,KAAQ,mBAA4C,IAAI,IAIxD,KAAQ,oBAA6C,IAAI,IAKzD,KAAQ,qBAAiC,CAAC,EAK1C,KAAQ,sBAAkC,CAAC,EAI3C,KAAQ,0BAAqD,IAAI,IAG/DpB,GAAgBpT,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,CAC5C,CAEA,IAAW,kBAA2B,CACpC,GAAI,KAAK,kBAAoB,OAC3B,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,KAAK,eACd,CAEO,WAAWwJ,EAAyB,CACzC8J,EAAU,UAAW,IAAM,kCAAkC9J,CAAS,GAAG,EACzE,KAAK,gBAAkBA,CACzB,CAEO,SAASA,EAAyB,CACvC8J,EAAU,UAAW,IAAM,gCAAgC9J,CAAS,GAAG,EACvE,IAAMoN,EAAY,KAAK,0BAA0B,IAAIpN,CAAS,EAC9D,GAAKoN,EAGL,SAAWb,KAAYa,EACrBtD,EAAU,UAAW,IAAM,iDAAiDyC,CAAQ,GAAG,EACvF,KAAK,cAAc,gBAAgBA,CAAQ,EAE7C,KAAK,0BAA0B,OAAOvM,CAAS,EAC/C,KAAK,gBAAkB,OACzB,CAEA,MAAa,gBAAgBqN,EAAoE,CAC/F,GAAIA,aAA2B,UAAW,CACxC,IAAMC,EAAiB,KAAK,eAAe,UAAWC,GAAUA,EAAM,YAAcF,CAAe,EACnG,GAAIC,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAcH,CAAe,EAClE,YAAK,eAAe,KAAK,CAAE,UAAWA,EAAiB,UAAAG,CAAU,CAAC,EAC3DA,CACT,CACF,SAAWH,IAAoB,OAAW,CACxC,IAAMC,EAAiB,KAAK,eAAe,UACxCC,GAAUA,EAAM,UAAY,QAAaA,EAAM,YAAc,MAChE,EACA,GAAID,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAc,EACnD,YAAK,eAAe,KAAK,CAAE,UAAAA,CAAU,CAAC,EAC/BA,CACT,CACF,CAEA,IAAMF,EAAiB,KAAK,eAAe,UAAWC,GACpDP,GAAwBO,EAAM,QAASF,CAAe,CACxD,EACA,GAAIC,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAcH,CAAe,EAClE,YAAK,eAAe,KAAK,CAAE,QAASA,EAAiB,UAAAG,CAAU,CAAC,EACzDA,CACT,CACF,CAEO,kBAAkBxN,EAAmBwN,EAA4B,CACtE,KAAK,qBAAqB,IAAIxN,EAAWwN,CAAS,EAClD,IAAIC,EAAa,KAAK,sBAAsB,IAAID,CAAS,EACpDC,IACHA,EAAa,IAAI,IACjB,KAAK,sBAAsB,IAAID,EAAWC,CAAU,GAEtDA,EAAW,IAAIzN,CAAS,EAEpB,KAAK,qBAAqB,OAAS,IACrC,KAAK,mBAAmB,IAAIA,EAAW,KAAK,oBAAoB,EAChE,KAAK,qBAAuB,CAAC,GAE3B,KAAK,sBAAsB,OAAS,IACtC,KAAK,oBAAoB,IAAIA,EAAW,KAAK,qBAAqB,EAClE,KAAK,sBAAwB,CAAC,EAElC,CAEO,iBAAiBA,EAAyB,CAC/C,KAAK,mBAAmB,OAAOA,CAAS,EACxC,KAAK,oBAAoB,OAAOA,CAAS,EACzC,IAAMwN,EAAY,KAAK,qBAAqB,IAAIxN,CAAS,EACzD,GAAI,CAACwN,EAEH,OAEF,KAAK,cAAc,yBAAyBxN,CAAS,EACrD,KAAK,qBAAqB,OAAOA,CAAS,EAC1C,IAAMyN,EAAa,KAAK,sBAAsB,IAAID,CAAS,EAE3D,GADAC,EAAW,OAAOzN,CAAS,EACvByN,EAAW,OAAS,EAAG,CACzB,KAAK,sBAAsB,OAAOD,CAAS,EAC3C,IAAMF,EAAiB,KAAK,eAAe,UAAWC,GAAUA,EAAM,YAAcC,CAAS,EACzFF,IAAmB,IACrB,KAAK,eAAe,OAAOA,EAAgB,CAAC,CAEhD,CACF,CAEO,aAAatN,EAA0C,CAC5D,OAAO,KAAK,qBAAqB,IAAIA,CAAS,CAChD,CAEO,iBAA4B,CACjC,OAAO,KAAK,cAAc,gBAAgB,CAC5C,CAEO,gBAAgBuM,EAA0B,CAC/CzC,EAAU,UAAW,IAAM,sCAAsCyC,CAAQ,GAAG,EAC5E,KAAK,cAAc,gBAAgBA,CAAQ,CAC7C,CAEA,MAAa,aACXvM,EACAuM,EACAmB,EACAC,EACAxB,EACmB,CACnB,IAAMyB,EAAgBb,GAA4B,IAAIW,CAAY,EAClE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,+BAA+BF,CAAY,EAAE,EAE/D,OAAO,KAAK,cAAc,aACxB1N,GAAa,KAAK,iBAClBuM,EACAqB,EACAD,EACAxB,CACF,CACF,CAEA,MAAa,sBACXnM,EACA0N,EACA/B,EACmB,CACnB7B,EAAU,UAAW,IAAM,gDAAgD4D,CAAY,YAAY/B,CAAK,GAAG,EAC3G,IAAMnR,EAAWuS,GAA4B,IAAIW,CAAY,EAC7D,GAAI,CAAClT,EACH,MAAM,IAAI,MAAM,+BAA+BkT,CAAY,EAAE,EAE/D,IAAMnB,EAAW,KAAK,cAAc,gBAAgB,EACpD,MAAM,KAAK,cAAc,aAAavM,EAAWuM,EAAU/R,EAAUmR,EAAO,EAAK,EACjF,IAAMyB,EAAY,KAAK,0BAA0B,IAAIpN,CAAS,EAC9D,OAAKoN,EAGHA,EAAU,KAAKb,CAAQ,EAFvB,KAAK,0BAA0B,IAAIvM,EAAW,CAACuM,CAAQ,CAAC,EAInDA,CACT,CAEO,aAAaA,EAAoB9S,EAAwB,CAE9D,GAAI,CADSiJ,EAAY,EACf,yBACR,MAAM,IAAI,MAAM,wEAAwE,EAE1FoH,EAAU,UAAW,IAAM,mCAAmCyC,CAAQ,WAAW9S,EAAK,UAAU,GAAG,EACnG,KAAK,cAAc,OAAO8S,EAAU9S,CAAI,CAC1C,CAEA,MAAa,eAAe8S,EAAoBT,EAA8D,CAC5G,OAAO,KAAK,cAAc,SAASS,EAAUT,CAAS,CACxD,CAEO,yBAAyBS,EAAoB7R,EAAgE,CAClH,MAAO,UAAY,CACjB,IAAMjB,EAAO,MAAM,KAAK,cAAc,SAAS8S,CAAQ,EACvD,OAAOlD,GAAW5P,EAAMiB,CAAI,CAC9B,CACF,CAEO,iBAAiBsF,EAAmBjJ,EAAkB2W,EAAwBC,EAAgC,CACnH,IAAMC,EAAgBb,GAA4B,IAAIW,CAAY,EAClE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,+BAA+BF,CAAY,EAAE,EAG/D,IAAMG,EAAK,KAAK,cAAc,eAAe7N,EAAWjJ,EAAQ6W,EAAeD,CAAU,EACzF,OAAA7D,EACE,UACA,IACE,qCAAqC/S,CAAM,eAAe6W,CAAa,iBACrED,CACF,mBAAmBE,CAAE,GACzB,EACOA,CACT,CAGO,mBACLC,EACAzJ,EACAD,EACA2J,EACAC,EACAC,EACAC,EAA4B,GACjB,CAEX,GAAI,CAACD,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAIE,EAAWL,EACXA,EAAiB,WAAW,IAAI,IAClCK,EAAWL,EAAiB,UAAU,CAAC,GAEzC,IAAMM,EAAWH,EAAa,IAAIE,CAAQ,EAC1C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,kBAAkBD,CAAQ,gCAAgC,EAG5E,GAAI9J,EAAaD,EAAagK,EAAS,WACrC,MAAM,IAAI,MAAM,2EAA2E,EAG7F,IAAMnV,EAASmV,EAAS,MAAM/J,EAAYA,EAAaD,CAAU,EAAE,OAC/DiK,EACJ,OAAQL,EAAK,SAAU,CACrB,IAAK,UACHK,EAAa,IAAI,aAAapV,CAAM,EACpC,MACF,IAAK,UACHoV,EACE,OAAO,aAAiB,KAAe,aAAa,KAAO,IAAI,aAAapV,CAAM,EAAI,IAAI,YAAYA,CAAM,EAC9G,MACF,IAAK,QACHoV,EAAa,IAAI,WAAWpV,CAAM,EAClC,MACF,IAAK,SACHoV,EAAa,IAAI,YAAYpV,CAAM,EACnC,MACF,IAAK,QACH,GAAIiV,EAA2B,CAE7B,IAAMI,EAAc/D,GAAmB,IAAI,WAAWtR,CAAM,EAAG,OAAO,EACtEoV,EAAa,IAAI,WAAWC,EAAY,MAAM,EAC9CN,EAAK,SAAW,OAClB,MACEK,EAAa,IAAI,cAAcpV,CAAM,EAEvC,MACF,IAAK,SACHoV,EAAa,IAAI,eAAepV,CAAM,EACtC,MACF,IAAK,OACHoV,EAAa,IAAI,UAAUpV,CAAM,EACjC,MACF,IAAK,OACL,IAAK,QACL,IAAK,QACHoV,EAAa,IAAI,WAAWpV,CAAM,EAClC,MACF,QACE,MAAM,IAAI,MAAM,0BAA0B+U,EAAK,QAAQ,iDAAiD,CAC5G,CAEA,OAAAlE,EACE,UACA,IACE,yCAAyCkE,EAAK,QAAQ,YAAYA,EAAK,KAAK,MAC1EE,EAA4B,uEAAyE,EACvG,EACJ,EAEOH,EAAQ,SAASC,EAAMK,CAAU,CAC1C,CAEO,mBAAmBE,EAAyB,CACjD,KAAK,qBAAqB,KAAKA,CAAS,CAC1C,CAEO,oBAAoBC,EAA0B,CACnD,KAAK,sBAAsB,KAAKA,CAAU,CAC5C,CAEO,aAAaxO,EAAmBuO,EAA4B,CACjE,IAAME,EAAa,KAAK,mBAAmB,IAAIzO,CAAS,EACxD,OAAKyO,EAGEA,EAAW,SAASF,CAAS,EAF3B,EAGX,CAEO,cAAcvO,EAAmBwO,EAA6B,CACnE,IAAME,EAAc,KAAK,oBAAoB,IAAI1O,CAAS,EAC1D,OAAK0O,EAGEA,EAAY,SAASF,CAAU,EAF7B,EAGX,CAEO,gCAAgCxO,EAAmBtF,EAAmBiU,EAAU,GAAe,CACpG,IAAM3U,EAAU,KAAK,qBAAqB,IAAIgG,CAAS,EACjDxF,EAAWuS,GAA4B,IAAI3F,GAA2B1M,CAAI,CAAC,EAEjF,OAAI,OAAOF,EAAa,IACf,GAGLmU,EACK,CAAC,CAAC3U,GAAS,gBAAgB,EAAE,MAAM,UAAU,SAASQ,CAAQ,EAE9D,CAAC,CAACR,GAAS,gBAAgB,EAAE,OAAO,UAAU,SAASQ,CAAQ,CAE1E,CAEO,OAAc,CAErB,CACF,IClaA,IAiFMoU,GAWOrP,GAWAE,GAsIPoP,GAOAC,GAiBAC,GAiDOpP,GAkBAE,GA6MAE,GA+BAiP,GAqIA5O,GA2YAI,GAgBAD,GAplCbtB,GAAAlK,EAAA,kBAQA2J,KAQAoG,KACAc,KACAgC,KAUA1I,KACAgF,KACAoE,KAmDMsG,GAAU,CAAC/L,EAAoBoM,IAA+B,CAChDvM,EAAY,EAAE,SAASG,EAAYoM,CAAY,IAC/C,GAChBhL,EAAe,+BAA+B,CAElD,EAMa1E,GAAc,MAAO/I,GAA4B,CAE5DoY,GAAQpY,EAAI,KAAK,WAAagR,GAAqBhR,EAAI,QAAQ,CAAC,CAClE,EAQaiJ,GAAS,MAAOjJ,EAAUgJ,IAAkC,CAEvEkD,EAAY,EAAE,YAAY,EAG1B,IAAIwM,EAAgB1Y,EAAI,OAAO,QAC/B,GAAIgJ,IAAW,SAAU,CACvB,GAAI,OAAO,UAAc,KAAe,CAAC,UAAU,IACjD,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAK0P,GAmBH,GACE,OAAOA,EAAc,QAAW,UAChC,OAAOA,EAAc,UAAa,UAClC,OAAOA,EAAc,eAAkB,WAEvC,MAAM,IAAI,MAAM,kFAAkF,MAxBlF,CAElB,IAAMC,EAAkB3Y,EAAI,OAAO,gBACnC,GAAI2Y,IAAoB,QAAaA,IAAoB,aAAeA,IAAoB,mBAC1F,MAAM,IAAI,MAAM,qCAAqCA,CAAe,GAAG,EAEzE,IAAMC,EAAuB5Y,EAAI,OAAO,qBACxC,GAAI4Y,IAAyB,QAAa,OAAOA,GAAyB,UACxE,MAAM,IAAI,MAAM,0CAA0CA,CAAoB,GAAG,EAGnF,GADAF,EAAgB,MAAM,UAAU,IAAI,eAAe,CAAE,gBAAAC,EAAiB,qBAAAC,CAAqB,CAAC,EACxF,CAACF,EACH,MAAM,IAAI,MACR,0GAEF,CAEJ,CAUF,CAGA,GAAI1P,IAAW,UACT,OAAO,UAAc,KAAe,CAAE,UAAyC,IACjF,MAAM,IAAI,MAAM,+CAA+C,EAoBjE,GALkCA,IAAW,UAC3CkD,EAAY,EAAE,WAAa2M,GAAW,CACpC7Y,EAAI,OAAO,OAAS6Y,CACtB,CAAC,EAE8B7P,IAAW,QAAS,CAEnD,IAAMvK,EAAU,GAAK,cAAgC,aAAcuB,CAAG,EACtEkM,EAAY,EAAE,UAAW,CACvBzN,EAEA,IAAMA,EAAQ,gBAAgB,EAE7BsX,GAAqBtX,EAAQ,gBAAgBsX,CAAQ,EAEtD,MAAOvM,EAA+BuM,EAAkBmB,EAAsB/B,EAAiBQ,IAC7FlX,EAAQ,aAAa+K,EAAWuM,EAAUmB,EAAc/B,EAAOQ,CAAO,EAExE,CAACI,EAAkB9S,IAAqB,CACtCxE,EAAQ,aAAasX,EAAU9S,CAAI,CACrC,EAEA,MAAO8S,EAAkBT,IACvB7W,EAAQ,eAAesX,EAAUT,CAAS,EAE5C,CAAC9L,EAAmBwN,IAAyBvY,EAAQ,kBAAkB+K,EAAWwN,CAAS,EAE3F,CAAC,CAAChX,EAAI,KACR,CAAC,CACH,CAEJ,EA8CMqY,GAAiB,IAAI,IAOrBC,GAA8BQ,GAA4C,CAC9E,IAAMnN,EAAOO,EAAY,EACnB5F,EAAQqF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMqC,EAAUrC,EAAK,SACfkC,EAAalC,EAAK,WAAW,EAAIqC,CAAO,EAC5BrC,EAAK,wBAAwBmN,EAAejL,EAAYA,EAAaG,CAAO,IAC5E,GAChBP,EAAe,uCAAuC,EAExD,IAAMvJ,EAAO8J,IAAY,EAAI,MAAQ,MACrC,MAAO,CAAC,OAAOrC,EAAK,SAASkC,EAAY3J,CAAI,CAAC,EAAG,OAAOyH,EAAK,SAASkC,EAAaG,EAAS9J,CAAI,CAAC,CAAC,CACpG,QAAE,CACAyH,EAAK,aAAarF,CAAK,CACzB,CACF,EAEMiS,GAAgC,CACpCO,EACA3C,IAC6E,CAC7E,IAAMxK,EAAOO,EAAY,EACnB5F,EAAQqF,EAAK,UAAU,EACzBoN,EAAiB,EACrB,GAAI,CACF,IAAM/K,EAAUrC,EAAK,SACfkC,EAAalC,EAAK,WAAW,EAAIqC,CAAO,EAC5BrC,EAAK,2BAA2BmN,EAAe3C,EAAOtI,EAAYA,EAAaG,CAAO,IACtF,GAChBP,EAAe,0CAA0C,EAE3D,IAAMkD,EAAa,OAAOhF,EAAK,SAASkC,EAAY,GAAG,CAAC,EACxDkL,EAAiB,OAAOpN,EAAK,SAASkC,EAAaG,EAAS,GAAG,CAAC,EAEhE,IAAMgL,EAAcrN,EAAK,OAAOoN,EAAiB,CAAC,EAClD,GAAIC,IAAgB,EAClB,MAAO,CAACrI,EAAY,CAAC,EAIvB,IAAMsI,EAAYtN,EAAK,QAAQoN,EAAiB,EAAI,CAAC,EAE/CjV,EAA+B,CAAC,EACtC,QAASlF,EAAI,EAAGA,EAAIqa,EAAWra,IAAK,CAClC,IAAMsa,EAAwB,OAAOvN,EAAK,SAASoN,EAAiB,EAAIna,EAAIoP,EAAS,GAAG,CAAC,EACzFlK,EAAK,KACHoV,IAA0B,EACtBvN,EAAK,aAAauN,CAAqB,EACvC,OAAOvN,EAAK,SAASoN,EAAiB,GAAKna,EAAIqa,GAAajL,EAAS,GAAG,CAAC,CAC/E,CACF,CACA,MAAO,CAAC2C,EAAYqI,EAAalV,CAAI,CACvC,QAAE,CACA6H,EAAK,aAAarF,CAAK,EACnByS,IAAmB,GACrBpN,EAAK,SAASoN,CAAc,CAEhC,CACF,EAQa5P,GAA0BC,GAAwC,CAC7E,IAAMuC,EAAOO,EAAY,EACnBiN,EAAkBxN,EAAK,QAAQvC,EAAM,UAAU,EACrD,GAAI+P,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+D/P,EAAM,UAAU,GAAG,EAEpG,OAAAuC,EAAK,OAAO,IAAIvC,EAAO+P,CAAe,EAC/B,CAACA,EAAiB/P,EAAM,UAAU,CAC3C,EAUaC,GAAgB,MAC3B+P,EACAna,IACyC,CACzC,IAAIka,EAAyBE,EACvB1N,EAAOO,EAAY,EAErB,MAAM,QAAQkN,CAAS,EAEzB,CAACD,EAAiBE,CAAe,EAAID,EAC5BA,EAAU,SAAWzN,EAAK,OAAO,OAE1C,CAACwN,EAAiBE,CAAe,EAAI,CAACD,EAAU,WAAYA,EAAU,UAAU,EAGhF,CAACD,EAAiBE,CAAe,EAAIlQ,GAAuBiQ,CAAS,EAGvE,IAAIN,EAAgB,EAChBrJ,EAAuB,EACvB6J,EAAkB,EAClB3L,EAAmB,CAAC,EAClB4L,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CAGF,GAFA,CAAC/J,EAAsB9B,CAAM,EAAI,MAAMwB,GAAkBlQ,CAAO,EAE5DA,GAAS,cAAgB0M,EAAK,kBAAmB,CACnD,IAAM8N,EAAkB,CAAC,EACzB,QAAW1H,KAAQ9S,EAAQ,aAAc,CACvC,IAAMya,EAAO,OAAO3H,GAAS,SAAWA,EAAOA,EAAK,KACpD0H,EAAgB,KACd5H,GAAS,OAAOE,GAAS,SAAWA,EAAOA,EAAK,IAAI,EAAE,KAAM9O,GAAS,CACnE0I,EAAK,kBAAkB+N,EAAMzW,CAAI,CACnC,CAAC,CACH,CACF,CAGA,MAAM,QAAQ,IAAIwW,CAAe,CACnC,CAEA,QAAWE,KAAY1a,GAAS,oBAAsB,CAAC,EAErD,IADqB,OAAO0a,GAAa,SAAWA,EAAWA,EAAS,QACnD,QAAS,CAE5B,GADAhO,EAAK,yBAA2B,GAC5B,OAAOgO,GAAa,SAAU,CAChC,IAAMC,EAAeD,EACfnW,EAAWoW,GAA6D,QACxEC,EAAaD,GAAsD,UACnE1T,EAAc0T,GAAuD,WACrEjB,GAAmBiB,GAAuD,gBAC5EpW,EACFmI,EAAK,eAAiBnI,EACbqW,EACTlO,EAAK,eAAiB,MAAMA,EAAK,qBAAsBkO,CAAS,EAEhElO,EAAK,eAAiB,MAAMA,EAAK,qBAAsB,CAAE,WAAAzF,EAAY,gBAAAyS,EAAgB,CAAC,CAE1F,MACEhN,EAAK,eAAiB,MAAMA,EAAK,qBAAsB,EAEzD,KACF,CAGFmN,EAAgB,MAAMnN,EAAK,kBAAkBwN,EAAiBE,EAAiB5J,CAAoB,EACnG9D,EAAK,wBAAwBmN,CAAa,EACtCA,IAAkB,GACpBrL,EAAe,yBAAyB,EAG1C9B,EAAK,sBAAsB,EAGvBA,EAAK,iBACPA,EAAK,uBAAwBmN,EAAenN,EAAK,cAAc,EAC/DA,EAAK,eAAiB,OACtBA,EAAK,yBAA2B,IAGlC,GAAM,CAACmO,EAAYC,CAAW,EAAIzB,GAA2BQ,CAAa,EAEpEkB,EAAqB,CAAC,CAAC/a,GAAS,mBAEhCgZ,EAAa,CAAC,EACdC,EAAc,CAAC,EACf+B,EAAkD,CAAC,EACnDC,EAAmD,CAAC,EACpDC,EAAwE,CAAC,EAC/E,QAASvb,EAAI,EAAGA,EAAIkb,EAAYlb,IAAK,CACnC,GAAM,CAAC+R,EAAYqI,EAAa7D,CAAK,EAAIoD,GAA8BO,EAAela,CAAC,EACnF+R,IAAe,GACjBlD,EAAe,0BAA0B,EAE3C8L,EAAsB,KAAK5I,CAAU,EACrC,IAAMnS,EAAOmN,EAAK,aAAagF,CAAU,EACzCsH,EAAW,KAAKzZ,CAAI,EACpByb,EAAc,KACZjB,IAAgB,EACZ,CAAE,KAAAxa,EAAM,SAAU,EAAM,EACxB,CAAE,KAAAA,EAAM,SAAU,GAAM,KAAMqS,GAA2BmI,CAAW,EAAG,MAAO7D,CAAO,CAC3F,CACF,CACA,QAASvW,EAAI,EAAGA,EAAImb,EAAanb,IAAK,CACpC,GAAM,CAAC+R,EAAYqI,EAAa7D,CAAK,EAAIoD,GAA8BO,EAAela,EAAIkb,CAAU,EAChGnJ,IAAe,GACjBlD,EAAe,2BAA2B,EAE5C+L,EAAuB,KAAK7I,CAAU,EACtC,IAAMyJ,EAAazO,EAAK,aAAagF,CAAU,EAC/CuH,EAAY,KAAKkC,CAAU,EAC3BF,EAAe,KACblB,IAAgB,EACZ,CAAE,KAAMoB,EAAY,SAAU,EAAM,EACpC,CAAE,KAAMA,EAAY,SAAU,GAAM,KAAMvJ,GAA2BmI,CAAW,EAAG,MAAO7D,CAAO,CACvG,EAE4D,CAC1D,GAAI6E,GAAsB/a,GAAS,0BAA4B,OAAW,CACxEkb,EAAyB,KAAK,YAAY,EAC1C,QACF,CACA,IAAMvI,EACJ,OAAO3S,GAAS,yBAA4B,SACxCA,EAAQ,wBACPA,GAAS,0BAA0Bmb,CAAU,GAAK,MACnDC,GAAgB1O,EAAK,mBAC3B,GAAIiG,IAAa,OAASyI,IAAiBA,GAAcvB,EAAesB,CAAU,EAAG,CACnFD,EAAyB,KAAK,sBAAsB,EACpD,QACF,CACA,GAAIvI,IAAa,OAASA,IAAa,cAAgBA,IAAa,cAAgBA,IAAa,YAC/F,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzE,GAAIoI,GAAsBpI,IAAa,aACrC,MAAM,IAAI,MACR,4CAA4CA,CAAQ,4EACtD,EAEFuI,EAAyB,KAAKvI,CAAQ,CACxC,CACF,CAGA,IAAI0I,EAAsC,KAC1C,OAEEH,EAAyB,KAAMI,GAAMA,IAAM,cAAgBA,IAAM,aAAeA,IAAM,sBAAsB,IAE5GjB,EAAkB3N,EAAK,kBAAkBmN,CAAa,EAClDQ,IAAoB,GACtB7L,EAAe,0BAA0B,EAG3C6M,EAAe,CACb,OAAQhB,EACR,yBAAAa,EACA,gCAAiCA,EAE9B,IAAKI,GAAOA,IAAM,uBAAyB,YAAcA,CAAE,EAC3D,IAAKA,GAAMpJ,GAAyBoJ,CAAC,CAAC,CAC3C,GAGFlC,GAAe,IAAIS,EAAe,CAChCA,EACAS,EACAC,EACAc,EACAN,EACA,EACF,CAAC,EACM,CAAClB,EAAeb,EAAYC,EAAa+B,EAAeC,CAAc,CAC/E,OAASlb,EAAG,CACV,MAAAua,EAAsB,QAASiB,GAAQ7O,EAAK,SAAS6O,CAAG,CAAC,EACzDhB,EAAuB,QAASgB,GAAQ7O,EAAK,SAAS6O,CAAG,CAAC,EAEtDlB,IAAoB,GAClB3N,EAAK,mBAAmB2N,CAAe,IAAM,GAC/C7L,EAAe,2BAA2B,EAI1CqL,IAAkB,GAChBnN,EAAK,mBAAmBmN,CAAa,IAAM,GAC7CrL,EAAe,wBAAwB,EAGrCzO,CACR,QAAE,CACA2M,EAAK,MAAMwN,CAAe,EACtB1J,IAAyB,GACvB9D,EAAK,0BAA0B8D,CAAoB,IAAM,GAC3DhC,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUjD,EAAK,MAAMiD,CAAK,CAAC,EAG3CjD,EAAK,sBAAsB,CAC7B,CACF,EAEapC,GAAkBC,GAA4B,CACzD,IAAMmC,EAAOO,EAAY,EACnBqD,EAAU8I,GAAe,IAAI7O,CAAS,EAC5C,GAAI,CAAC+F,EACH,MAAM,IAAI,MAAM,+CAA+C/F,CAAS,EAAE,EAE5E,GAAM,CAACsP,EAAeS,EAAuBC,EAAwBiB,EAAgBT,CAAkB,EAAIzK,EAEvGkL,IACET,GACErO,EAAK,sBAAsB8O,EAAe,MAAM,IAAM,GACxDhN,EAAe,4BAA4B,EAG3C9B,EAAK,mBAAmB8O,EAAe,MAAM,IAAM,GACrDhN,EAAe,2BAA2B,GAI9C9B,EAAK,uBAAuBnC,CAAS,EACrCmC,EAAK,wBAAwBnC,CAAS,EACtCmC,EAAK,yBAAyBnC,CAAS,EAEvC+P,EAAsB,QAASiB,GAAQ7O,EAAK,SAAS6O,CAAG,CAAC,EACzDhB,EAAuB,QAASgB,GAAQ7O,EAAK,SAAS6O,CAAG,CAAC,EACtD7O,EAAK,mBAAmBmN,CAAa,IAAM,GAC7CrL,EAAe,wBAAwB,EAEzC4K,GAAe,OAAO7O,CAAS,CACjC,EAEagP,GAA2B,MACtCjY,EACAma,EACA/M,EACAnE,EACAmR,EACAxE,EACA6D,EAAqB,KACH,CAClB,GAAI,CAACzZ,EAAQ,CACXma,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAM/O,EAAOO,EAAY,EACnB8B,EAAUrC,EAAK,SAEf3H,EAAWzD,EAAO,CAAC,EACnBuD,EAAOvD,EAAO,CAAC,EACfqR,EAAWrR,EAAO,CAAC,EACrBqa,EAAiBhJ,EAEjBiJ,EACAC,EAEJ,GAAI9W,IAAa,WAAa4N,IAAa,cAAgBA,IAAa,aACtE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIoI,GAAsBpI,IAAa,aACrC,MAAM,IAAI,MACR,2DAA2DuE,CAAK,mCAClE,EAGF,GAAIvE,IAAa,aAAc,CAC7B,IAAM7N,EAAYxD,EAAO,CAAC,EAAE,UAC5Bua,EAAiBhK,GAA2BF,GAA2B5M,CAAQ,EAAGF,CAAI,EAEtD,CAC9B,IAAMiX,EAAiBpP,EAAK,qBAC5B,GAAI,CAACoP,EACH,MAAM,IAAI,MAAM,qEAAqE,EAGvFF,EAAUE,EAAehX,EAAWyF,CAAS,CAC/C,CAOF,SAAWoI,IAAa,YAAa,CACnC,IAAM3N,EAAW1D,EAAO,CAAC,EAAE,SAC3Bua,EAAiBhK,GAA2BF,GAA2B5M,CAAQ,EAAGF,CAAI,EAEtF,IAAMkX,EAAmBrP,EAAK,sBAC9B,GAAI,CAACqP,EACH,MAAM,IAAI,MAAM,mEAAmE,EAErFH,EAAUG,EAAiBxR,EAAWvF,EAAU2M,GAA2B5M,CAAQ,EAAGF,CAAI,CAC5F,KAAO,CACL,IAAMb,EAAO1C,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQ0C,CAAI,EAAG,CAEvB6X,EAAiB9M,EAAU/K,EAAK,OAChC4X,EAAUlP,EAAK,QAAQmP,CAAc,EACrCnN,EAAO,KAAKkN,CAAO,EACnB,QAASjc,EAAI,EAAGA,EAAIqE,EAAK,OAAQrE,IAAK,CACpC,GAAI,OAAOqE,EAAKrE,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjE+M,EAAK,SAASkP,EAAUjc,EAAIoP,EAAST,EAAgBtK,EAAKrE,CAAC,EAAG+O,CAAM,EAAG,GAAG,CAC5E,CACF,KAAO,CACL,IAAMsN,EAAetP,EAAK,kBACpB0O,EAAgB1O,EAAK,mBAC3B,GAAI3H,IAAa,UAAYiX,GAAgBZ,EAAe,CAC1D,IAAMa,EAAavP,EAAK,aAAagP,CAAqB,EAE1D,GAAIM,EAAazR,EAAW0R,CAAU,GAAKb,EAAc7Q,EAAW0R,CAAU,EAAG,CAC/E,IAAMC,EAAevK,GAA2B5M,CAAQ,EACxD8W,EAAiBhK,GAA2BqK,EAAcrX,CAAI,EAC9D8W,EAAiB,YACjB,IAAMQ,EAAwBzP,EAAK,2BAC7B0P,EAAe1P,EAAK,kBAC1B,GAAI,CAACyP,GAAyB,CAACC,EAC7B,MAAM,IAAI,MAAM,mEAAmE,EAErF,IAAMtF,EAAW,MAAMqF,EAAsB5R,EAAW2R,EAAcrX,CAAgB,EACtFuX,EAAatF,EAAU,IAAI,WAAW9S,EAAK,OAAQA,EAAK,WAAYA,EAAK,UAAU,CAAC,EACpF4X,EAAU9E,CACZ,MACE+E,EAAiB7X,EAAK,WACtB4X,EAAUlP,EAAK,QAAQmP,CAAc,EACrCnN,EAAO,KAAKkN,CAAO,EACnBlP,EAAK,OAAO,IAAI,IAAI,WAAW1I,EAAK,OAAQA,EAAK,WAAY6X,CAAc,EAAGD,CAAO,CAEzF,MACEC,EAAiB7X,EAAK,WACtB4X,EAAUlP,EAAK,QAAQmP,CAAc,EACrCnN,EAAO,KAAKkN,CAAO,EACnBlP,EAAK,OAAO,IAAI,IAAI,WAAW1I,EAAK,OAAQA,EAAK,WAAY6X,CAAc,EAAGD,CAAO,CAEzF,CACF,CAEA,IAAMvU,EAAQqF,EAAK,UAAU,EACvB2P,EAAa3P,EAAK,WAAW,EAAI7H,EAAK,MAAM,EAClD,GAAI,CACFA,EAAK,QAAQ,CAACyX,EAAGpF,IAAUxK,EAAK,SAAS2P,EAAanF,EAAQnI,EAASuN,EAAGvN,IAAY,EAAI,MAAQ,KAAK,CAAC,EACxG,IAAMzN,EAASoL,EAAK,iBAClBiF,GAA2B5M,CAAQ,EACnC6W,EACAC,EACAQ,EACAxX,EAAK,OACLqN,GAAyByJ,CAAc,CACzC,EACIra,IAAW,GACbkN,EAAe,iDAAiDjE,CAAS,WAAW2M,CAAK,GAAG,EAE9FuE,EAAc,KAAKna,CAAM,CAC3B,QAAE,CACAoL,EAAK,aAAarF,CAAK,CACzB,CACF,EAKasD,GAAM,MACjBJ,EACAC,EACA+R,EACA7R,EACA8R,EACAxc,IAC8B,CAC9B,IAAM0M,EAAOO,EAAY,EACnB8B,EAAUrC,EAAK,SACf4D,EAAU8I,GAAe,IAAI7O,CAAS,EAC5C,GAAI,CAAC+F,EACH,MAAM,IAAI,MAAM,6CAA6C/F,CAAS,EAAE,EAE1E,IAAMsP,EAAgBvJ,EAAQ,CAAC,EACzBgK,EAAwBhK,EAAQ,CAAC,EACjCiK,EAAyBjK,EAAQ,CAAC,EAClCkL,EAAiBlL,EAAQ,CAAC,EAC1ByK,EAAqBzK,EAAQ,CAAC,EAC9BmM,EAAmBnM,EAAQ,CAAC,EAE5BuK,EAAarQ,EAAa,OAC1BsQ,EAAcpQ,EAAc,OAE9B4E,EAAmB,EACnBoN,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBpQ,EAAK,UAAU,EAChCqQ,EAAoBrQ,EAAK,WAAWmO,EAAa9L,CAAO,EACxDiO,EAAmBtQ,EAAK,WAAWmO,EAAa9L,CAAO,EACvDkO,EAAqBvQ,EAAK,WAAWoO,EAAc/L,CAAO,EAC1DmO,GAAoBxQ,EAAK,WAAWoO,EAAc/L,CAAO,EAE/D,GAAI,CACF,CAACO,EAAkBoN,CAAgB,EAAItN,GAAcpP,CAAO,EAE5D8G,EAAkB,+BAA+B,EAEjD,QAASnH,EAAI,EAAGA,EAAIkb,EAAYlb,IAC9B,MAAM4Z,GACJgD,EAAa5c,CAAC,EACdgd,EACAE,EACAtS,EACA+P,EAAsB9P,EAAa7K,CAAC,CAAC,EACrC6K,EAAa7K,CAAC,EACdob,CACF,EAIF,QAASpb,EAAI,EAAGA,EAAImb,EAAanb,IAC/B,MAAM4Z,GACJiD,EAAc7c,CAAC,EACfid,EACAC,EACAtS,EACAgQ,EAAuB7P,EAAc/K,CAAC,CAAC,EACvCkb,EAAanQ,EAAc/K,CAAC,EAC5Bob,CACF,EAEFhU,EAAgB,+BAA+B,EAE/C,QAASpH,EAAI,EAAGA,EAAIkb,EAAYlb,IAC9B+M,EAAK,SAASqQ,EAAoBpd,EAAIoP,EAAS4N,EAAmBhd,CAAC,EAAG,GAAG,EACzE+M,EAAK,SAASsQ,EAAmBrd,EAAIoP,EAASuL,EAAsB9P,EAAa7K,CAAC,CAAC,EAAG,GAAG,EAE3F,QAASA,EAAI,EAAGA,EAAImb,EAAanb,IAC/B+M,EAAK,SAASuQ,EAAqBtd,EAAIoP,EAAS6N,EAAoBjd,CAAC,EAAG,GAAG,EAC3E+M,EAAK,SAASwQ,GAAoBvd,EAAIoP,EAASwL,EAAuB7P,EAAc/K,CAAC,CAAC,EAAG,GAAG,EAG9F,GAAgE6b,GAAkB,CAACiB,EAAkB,CACnG,GAAM,CAAE,OAAAU,EAAQ,yBAAAjC,EAA0B,gCAAAkC,EAAgC,EAAI5B,EAE9E,GAAIlB,EAAsB,SAAWO,EACnC,MAAM,IAAI,MACR,2BAA2BA,CAAU,4DAA4DP,EAAsB,MAAM,IAC/H,EAGFxT,EAAkB,wBAAwB,EAE1C,QAASnH,EAAI,EAAGA,EAAIkb,EAAYlb,IAAK,CACnC,IAAMuX,EAAQ1M,EAAa7K,CAAC,EACV,MAAM+M,EAAK,cAAcyQ,EAAQ7C,EAAsBpD,CAAK,EAAGyF,EAAmBhd,CAAC,CAAC,IACpF,GAChB6O,EAAe,oBAAoB7O,CAAC,iBAAiB4K,CAAS,GAAG,CAErE,CAGA,QAAS5K,EAAI,EAAGA,EAAImb,EAAanb,IAAK,CACpC,IAAMuX,EAAQxM,EAAc/K,CAAC,EACZ6c,EAAc7c,CAAC,IAAI,CAAC,EAIjB+M,EAAK,eAAeyQ,EAAQ5C,EAAuBrD,CAAK,EAAG0F,EAAoBjd,CAAC,EAAG,CAAC,IACpF,GAChB6O,EAAe,mCAAmC7O,CAAC,iBAAiB4K,CAAS,GAAG,EAIhEmC,EAAK,eACrByQ,EACA5C,EAAuBrD,CAAK,EAC5B,EACAkG,GAAgClG,CAAK,CACvC,IACkB,GAChB1I,EAAe,qBAAqB7O,CAAC,QAAQub,EAAyBvb,CAAC,CAAC,gBAAgB4K,CAAS,GAAG,CAG1G,CACAxD,EAAgB,wBAAwB,EACxCqS,GAAe,IAAI7O,EAAW,CAC5BsP,EACAS,EACAC,EACAiB,EACAT,EACA,EACF,CAAC,CACH,CAEArO,EAAK,iBAAiBmN,CAAa,EACnCnN,EAAK,kBAAkBmN,CAAa,EAEpC,IAAI5K,EAC4DuM,EAC9DvM,EAAY,MAAMvC,EAAK,mBACrBmN,EACA2B,EAAe,OACfV,EACAmC,EACA3N,CACF,EAEAL,EAAY,MAAMvC,EAAK,QACrBmN,EACAmD,EACAD,EACAlC,EACAqC,GACApC,EACAmC,EACA3N,CACF,EAGEL,IAAc,GAChBT,EAAe,0BAA0B,EAG3C,IAAM6O,EAA2B,CAAC,EAC5BC,GAA4D,CAAC,EAEnExW,EAAkB,0BAA0B,EAC5C,QAASnH,EAAI,EAAGA,EAAImb,EAAanb,IAAK,CACpC,IAAM2B,EAAS,OAAOoL,EAAK,SAASuQ,EAAqBtd,EAAIoP,EAAS,GAAG,CAAC,EAC1E,GAAIzN,IAAWsb,EAAoBjd,CAAC,EAAG,CAErC0d,EAAO,KAAKb,EAAc7c,CAAC,CAAE,EAC7B,QACF,CAEA,IAAM4d,GAA2B7Q,EAAK,UAAU,EAE1C8Q,EAAmB9Q,EAAK,WAAW,EAAIqC,CAAO,EAEhD0O,EAAmB,GACnBxY,EACF2J,EAAa,EACf,GAAI,CACgBlC,EAAK,kBACrBpL,EACAkc,EACAA,EAAmBzO,EACnByO,EAAmB,EAAIzO,EAEvByO,EAAmB,EAAIzO,CACzB,IACkB,GAChBP,EAAe,4CAA4C7O,CAAC,GAAG,EAEjE,IAAM+d,GAAY3O,IAAY,EAAI,MAAQ,MACpChK,GAAW,OAAO2H,EAAK,SAAS8Q,EAAkBE,EAAS,CAAC,EAClE9O,EAAalC,EAAK,SAAS8Q,EAAmBzO,EAAS,GAAG,EAC1D,IAAMsN,GAAa3P,EAAK,SAAS8Q,EAAmBzO,EAAU,EAAG,GAAG,EAC9D4O,GAAa,OAAOjR,EAAK,SAAS8Q,EAAmBzO,EAAU,EAAG2O,EAAS,CAAC,EAC5E7Y,EAAO,CAAC,EACd,QAASlF,EAAI,EAAGA,EAAIge,GAAYhe,IAC9BkF,EAAK,KAAK,OAAO6H,EAAK,SAAS2P,GAAa1c,EAAIoP,EAAS2O,EAAS,CAAC,CAAC,EAElEhR,EAAK,SAAS2P,EAAU,IAAM,GAChC7N,EAAe,oCAAoC,EAErD,IAAM1I,EAAOjB,EAAK,OAAO,CAAC2N,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAC3CxN,EAAO2M,GAA2B7M,EAAQ,EAE1C,IAAM6Y,GAAoBpC,GAAgB,yBAAyB9Q,EAAc/K,CAAC,CAAC,EAEnF,GAAIsF,IAAS,SAAU,CACrB,GAAI2Y,KAAsB,cAAgBA,KAAsB,YAC9D,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,EAAuB,CAAC,EAC9B,QAASle,EAAI,EAAGA,EAAImG,EAAMnG,IAAK,CAC7B,IAAM8T,EAAS/G,EAAK,SAASkC,EAAajP,EAAIoP,EAAS,GAAG,EACpD+O,GAAapR,EAAK,SAASkC,GAAcjP,EAAI,GAAKoP,EAAS,GAAG,EAC9DgP,GAAiBpe,IAAMmG,EAAO,EAAI,OAAYgY,GAAarK,EACjEoK,EAAW,KAAKnR,EAAK,aAAa+G,EAAQsK,EAAc,CAAC,CAC3D,CACAV,EAAO,KAAK,CAACpY,EAAMJ,EAAMgZ,EAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgB9X,EAAO,EAAG,CAClD,IAAMkY,EAAyCtR,EAAK,gBACpD,GAAI,CAACsR,EACH,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMlZ,EAAYkZ,EAAUpP,CAAU,EAChCqP,EAAapM,GAA2B9M,GAAUe,CAAI,EAC5D,GAAImY,IAAe,QAAa,CAACjM,GAAyB/M,CAAI,EAC5D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAIlDwY,EAAmB,GAEa,CAC9B/Q,EAAK,qBAAsB5H,EAAWyF,EAAWqE,CAAU,EAC3D,IAAMsP,GAAuBxR,EAAK,uBAAwB5H,EAAWmZ,EAAY1T,CAAS,EAC1F8S,EAAO,KAAK,CACVpY,EACAJ,EACA,CACE,UAAAC,EACA,SAAU,SAAY,CACpB,IAAMqZ,GAAc,MAAMD,GAAqB,EAE/C,OADa,IAAKpM,GAAkC7M,CAAK,GAAGkZ,EAAW,CAEzE,EACA,QAAS,IAAM,CACTzR,EAAK,kBAAkBpL,CAAM,IAAM,GACrCkN,EAAe,uBAAuB,CAE1C,CACF,EACA,YACF,CAAC,CACH,CAgBF,SAAWoP,KAAsB,aAAe9X,EAAO,EAAG,CACxD,IAAMsY,EAAe1R,EAAK,kBACpB2R,EAAkC3R,EAAK,qCAC7C,GAAI,CAAC0R,GAAgB,CAACC,EACpB,MAAM,IAAI,MAAM,qEAAqE,EAGvF,GADmBxM,GAA2B9M,GAAUe,CAAI,IACzC,QAAa,CAACmM,GAAwBhN,CAAI,EAC3D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,GAAI,CAACoZ,EAAgC9T,EAAWtF,EAAM,EAAK,EACzD,MAAM,IAAI,MACR,qCAAqCA,CAAI,oDAC3C,EAMF,IAAMD,GAAW,MAAMoZ,EAAa7T,EAAWqE,EAAY7J,GAAUF,EAAM,EAAK,EAGhF4Y,EAAmB,GAEnBJ,EAAO,KAAK,CACVpY,EACAJ,EACA,CACE,SAAAG,GACA,SAAU0H,EAAK,8BAA+BkC,EAAY3J,CAAI,EAC9D,QAAS,IAAM,CACbyH,EAAK,qBAAsBkC,CAAU,EACrClC,EAAK,kBAAkBpL,CAAM,CAC/B,CACF,EACA,WACF,CAAC,CACH,SAAWsc,KAAsB,wBAA0B9X,EAAO,EAAG,CACnE,IAAM9B,EAAO0I,EAAK,8BAA+BkC,EAAY3J,CAAgC,EAAE,EACzFiS,EAAQmG,EAAO,OAErBI,EAAmB,GACnBH,GAAe,MACZ,SAAY,CACX,IAAMlV,EAAoC,CAAC8O,EAAO,MAAMlT,CAAI,EAC5D,OAAA0I,EAAK,qBAAsBkC,CAAU,EACrClC,EAAK,kBAAkBpL,CAAM,EACtB8G,CACT,GAAG,CACL,EACAiV,EAAO,KAAK,CAACpY,EAAMJ,EAAM,CAAC,EAAG,KAAK,CAAC,CACrC,KAAO,CACL,IAAMwB,EAAwByL,GAAkC7M,CAAI,EAC9DjB,EAAO,IAAIqC,EAAsBP,CAAI,EAC3C,IAAI,WAAW9B,EAAK,OAAQA,EAAK,WAAYA,EAAK,UAAU,EAAE,IAC5D0I,EAAK,OAAO,SAASkC,EAAYA,EAAa5K,EAAK,UAAU,CAC/D,EACAqZ,EAAO,KAAK,CAACpY,EAAMJ,EAAMb,EAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACA0I,EAAK,aAAa6Q,EAAwB,EACtCtY,IAAS,UAAY2J,GACvBlC,EAAK,MAAMkC,CAAU,EAElB6O,GACH/Q,EAAK,kBAAkBpL,CAAM,CAEjC,CACF,CAEIka,GAAkB,CAACT,IACjBrO,EAAK,sBAAsB8O,EAAe,MAAM,IAAM,GACxDhN,EAAe,4BAA4B,EAE7C4K,GAAe,IAAI7O,EAAW,CAC5BsP,EACAS,EACAC,EACAiB,EACAT,EACA,EACF,CAAC,GAGH,OAAW,CAAC7D,EAAOlT,CAAI,IAAK,MAAM,QAAQ,IAAIsZ,EAAc,EAC1DD,EAAOnG,CAAK,EAAE,CAAC,EAAIlT,EAErB,OAAA+C,EAAgB,0BAA0B,EACnCsW,CACT,QAAE,CACA3Q,EAAK,gBAAgBmN,CAAa,EAElCnN,EAAK,aAAaoQ,CAAc,EAG9BP,EAAa,QAAS+B,GAAM,CACtBA,GAAKA,EAAE,CAAC,IAAM,cAChB5R,EAAK,uBAAwB4R,EAAE,CAAC,EAAE,SAAS,CAE/C,CAAC,EACD9B,EAAc,QAAS8B,GAAM,CACvBA,GAAKA,EAAE,CAAC,IAAM,cAChB5R,EAAK,uBAAwB4R,EAAE,CAAC,EAAE,SAAS,CAE/C,CAAC,EAEH3B,EAAmB,QAAS3U,GAAM0E,EAAK,kBAAkB1E,CAAC,CAAC,EAC3D4U,EAAoB,QAAS5U,GAAM0E,EAAK,kBAAkB1E,CAAC,CAAC,EAC5D6U,EAAkB,QAAS0B,GAAM7R,EAAK,MAAM6R,CAAC,CAAC,EAE1CjP,IAAqB,GACvB5C,EAAK,sBAAsB4C,CAAgB,EAE7CoN,EAAiB,QAAS6B,GAAM7R,EAAK,MAAM6R,CAAC,CAAC,CAC/C,CACF,EAKaxT,GAAgBR,GAA4B,CACvD,IAAMmC,EAAOO,EAAY,EACnBqD,EAAU8I,GAAe,IAAI7O,CAAS,EAC5C,GAAI,CAAC+F,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMuJ,EAAgBvJ,EAAQ,CAAC,EAGzBkO,EAAkB9R,EAAK,iBAAiBmN,CAAa,EACvD2E,IAAoB,GACtBhQ,EAAe,iCAAiC,EAElD9B,EAAK,SAAS8R,CAAe,CAC/B,EAEa1T,GAA8B2T,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAWpd,KAAUmd,EAAS,CAC5B,IAAMza,EAAO1C,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQ0C,CAAI,GAAK,WAAYA,GACtC0a,EAAQ,KAAK1a,EAAK,MAAM,CAE5B,CACA,OAAO0a,CACT,IC7lCA,IAoBMC,GACFC,EACAhS,GACAD,GACAE,GACAgS,GAGAC,GACEC,GAEAC,GASAC,GAMAC,GAkCOC,GAiFAC,GAaAlV,GAaAE,GAwBAE,GAaAK,GAgCAI,GAhQbsU,GAAA/f,EAAA,kBAGA2J,KASAO,KACAC,KACAC,KAMMiV,GAAU,IAAe,CAAC,CAAC5d,EAAI,KAAK,OAAS,OAAO,SAAa,IAEnE6L,GAAe,GACfD,GAAc,GACdE,GAAU,GAKRkS,GAAiF,IAAI,IAErFC,GAAmB,CAAC/Z,EAA8Bqa,IAA+C,CACrG,IAAMC,EAAQR,GAAgB,IAAI9Z,CAAI,EAClCsa,EACFA,EAAM,KAAKD,CAAS,EAEpBP,GAAgB,IAAI9Z,EAAM,CAACqa,CAAS,CAAC,CAEzC,EAEML,GAAe,IAAY,CAC/B,GAAIrS,IAAgB,CAACD,IAAeE,IAAW,CAAC+R,EAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMM,GAAwBvV,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACHiD,GAAe,GACXjD,EAAG,KAAK,KACVkD,GAAU,GACViS,GAAkB,CAAC,EAAEnV,EAAG,KAAK,GAAG,IAEhCgD,GAAc,GACdmS,GAAkB,CAAC,EAAE,GAEnBD,KACF,IAAI,gBAAgBA,EAAkB,EACtCA,GAAqB,QAEvB,MACF,IAAK,UACL,IAAK,YACL,IAAK,SACL,IAAK,UACL,IAAK,MACL,IAAK,gBAAiB,CACpB,IAAMS,EAAYP,GAAgB,IAAIpV,EAAG,KAAK,IAAI,EAC9CA,EAAG,KAAK,IACV2V,EAAU,MAAM,EAAG,CAAC,EAAE3V,EAAG,KAAK,GAAG,EAEjC2V,EAAU,MAAM,EAAG,CAAC,EAAE3V,EAAG,KAAK,GAAI,EAEpC,KACF,CACA,QACF,CACF,EAEawV,GAAqC,SAA2B,CAC3E,GAAI,CAAAxS,GAGJ,IAAIC,GACF,MAAM,IAAI,MAAM,0CAA0C,EAE5D,GAAIC,GACF,MAAM,IAAI,MAAM,uCAAuC,EAKzD,GAFAD,GAAe,GAEuB+R,GAAQ,EAC5C,OAAO,IAAI,QAAc,CAACta,EAASC,IAAW,CAC5Csa,GAAa,UAAU,EAElBjT,GAAkB,EAAE,KAAK,CAAC,CAACkC,EAAW2R,CAAM,IAAM,CACrD,GAAI,CACFZ,EAAcY,EACdZ,EAAY,QAAWjV,GAAmBrF,EAAOqF,CAAE,EACnDiV,EAAY,UAAYM,GACxBJ,GAAoB,CAACza,EAASC,CAAM,EACpC,IAAMsF,EAA0B,CAAE,KAAM,YAAa,GAAI7I,CAAI,EAM7D,GAAyC,CAAC6I,EAAQ,GAAI,KAAK,WAAaiE,EAAW,CAGjF,IAAMM,EAAyB/C,GAAiC,EAC5D+C,IACFvE,EAAQ,GAAI,KAAK,UAAYuE,EAEjC,CAwBAyQ,EAAY,YAAYhV,CAAO,EAC/BiV,GAAqBhR,CACvB,OAAS9N,EAAG,CACVuE,EAAOvE,CAAC,CACV,CACF,EAAGuE,CAAM,CACX,CAAC,EAED,GAAI,CACF,MAAMuF,GAAsB9I,EAAI,IAAI,EACpC,MAAW+I,GAAY/I,CAAG,EAC1B4L,GAAc,EAChB,OAAS5M,EAAG,CACV,MAAA8M,GAAU,GACJ9M,CACR,QAAE,CACA6M,GAAe,EACjB,EAEJ,EAEawS,GAAkB,MAAOrV,GAAkC,CACtE,GAAsC4U,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC5a,EAASC,IAAW,CAC5C0a,GAAiB,UAAW,CAAC3a,EAASC,CAAM,CAAC,EAC7C,IAAMsF,EAA0B,CAAE,KAAM,UAAW,GAAI,CAAE,OAAAG,EAAQ,IAAAhJ,CAAI,CAAE,EACvE6d,EAAa,YAAYhV,CAAO,CAClC,CAAC,EAED,MAAWI,GAAOjJ,EAAKgJ,CAAM,CAEjC,EAEaG,GAAyB,MAAO1G,GACLmb,GAAQ,GAC5CM,GAAa,EACN,IAAI,QAAoC,CAAC5a,EAASC,IAAW,CAClE0a,GAAiB,YAAa,CAAC3a,EAASC,CAAM,CAAC,EAC/C,IAAMsF,EAA0B,CAAE,KAAM,YAAa,GAAI,CAAE,OAAApG,CAAO,CAAE,EACpEob,EAAa,YAAYhV,EAAS,CAACpG,EAAO,MAAM,CAAC,CACnD,CAAC,GAEW0G,GAAuB1G,CAAM,EAIhC4G,GAAgB,MAC3BD,EACAnK,IACyC,CACzC,GAAsC2e,GAAQ,EAAG,CAE/C,GAAI3e,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAAif,GAAa,EACN,IAAI,QAAqC,CAAC5a,EAASC,IAAW,CACnE0a,GAAiB,SAAU,CAAC3a,EAASC,CAAM,CAAC,EAC5C,IAAMsF,EAA0B,CAAE,KAAM,SAAU,GAAI,CAAE,MAAAO,EAAO,QAAS,CAAE,GAAGnK,CAAQ,CAAE,CAAE,EACnFyf,EAA+B,CAAC,EAClCtV,aAAiB,YACnBsV,EAAa,KAAKtV,EAAM,MAAM,EAEhCyU,EAAa,YAAYhV,EAAS6V,CAAY,CAChD,CAAC,CACH,KACE,QAAYrV,GAAcD,EAAOnK,CAAO,CAE5C,EAEasK,GAAiB,MAAOC,GAAqC,CACxE,GAAsCoU,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC5a,EAASC,IAAW,CAC5C0a,GAAiB,UAAW,CAAC3a,EAASC,CAAM,CAAC,EAC7C,IAAMsF,EAA0B,CAAE,KAAM,UAAW,GAAIW,CAAU,EACjEqU,EAAa,YAAYhV,CAAO,CAClC,CAAC,EAEIU,GAAeC,CAAS,CAEjC,EAEaI,GAAM,MACjBJ,EACAC,EACAC,EACAC,EACAE,EACA5K,IAC8B,CAC9B,GAAsC2e,GAAQ,EAAG,CAE/C,GAAIlU,EAAO,KAAM6T,GAAMA,EAAE,CAAC,IAAM,KAAK,EACnC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAI1T,EAAQ,KAAM0T,GAAMA,CAAC,EACvB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAW,GAAa,EACN,IAAI,QAAsC,CAAC5a,EAASC,IAAW,CACpE0a,GAAiB,MAAO,CAAC3a,EAASC,CAAM,CAAC,EACzC,IAAMob,EAAqBjV,EACrBb,EAA0B,CAC9B,KAAM,MACN,GAAI,CAAE,UAAAW,EAAW,aAAAC,EAAc,OAAQkV,EAAoB,cAAAhV,EAAe,QAAA1K,CAAQ,CACpF,EACA4e,EAAa,YAAYhV,EAAckB,GAA2B4U,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAY/U,GAAIJ,EAAWC,EAAcC,EAAQC,EAAeE,EAAS5K,CAAO,CAEpF,EAEa+K,GAAe,MAAOR,GAAqC,CACtE,GAAsCoU,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC5a,EAASC,IAAW,CAC5C0a,GAAiB,gBAAiB,CAAC3a,EAASC,CAAM,CAAC,EACnD,IAAMsF,EAA0B,CAAE,KAAM,gBAAiB,GAAIW,CAAU,EACvEqU,EAAa,YAAYhV,CAAO,CAClC,CAAC,EAEImB,GAAaR,CAAS,CAE/B,IC3QA,IAkBaoV,GAaAC,GAyBAC,GAxDbC,GAAAxgB,EAAA,kBAGA2J,KAUAoW,KACAlN,KACAjJ,KACA2J,KAEa8M,GAAuB,CAACre,EAAgBye,IAA0C,CAC7F,OAAQze,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,UAAWA,EAAO,SAAU,EAAG,YAAY,EACjF,IAAK,YACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,SAAUA,EAAO,QAAS,EAAG,WAAW,EAC9E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQye,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaH,GAAwBte,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIqC,EAAOrC,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMyD,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAAC0Q,GAAyBjN,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAE,UAAAD,EAAW,SAAAH,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EACjD,OAAOqC,EAAO,cAAcmB,EAAW,CAAE,SAAAC,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACzF,CACA,IAAK,YAAa,CAChB,IAAMG,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAAC2Q,GAAwBlN,CAAQ,EACnC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,oCAAoC,EAE1F,GAAM,CAAE,SAAAC,EAAU,SAAAL,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EAChD,OAAOqC,EAAO,aAAaqB,EAAU,CAAE,SAAAD,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BtD,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaue,GAAN,KAA8E,CAQnF,MAAM,8BAA8BpF,EAAmD,CAErF,OAAOvQ,GAAuB,MAAM0I,GAAS6H,CAAI,CAAC,CACpD,CAEA,MAAM,UAAUuF,EAAmChgB,EAA0D,CAC3G4G,EAAiB,EACjB,IAAIuD,EAEA,OAAO6V,GAAiB,SAOxB7V,EAAQ,MAAM,KAAK,8BAA8B6V,CAAY,EAG/D7V,EAAQ6V,EAGV,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,YAAa,KAAK,cAAe,KAAK,cAAc,EAAI,MAAM5V,GACnGD,EACAnK,CACF,EACA6G,GAAe,CACjB,CAEA,MAAM,SAAyB,CAC7B,OAAOyD,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IACJ3C,EACAC,EACA5H,EACoC,CACpC4G,EAAiB,EACjB,IAAMqZ,EAAuB,CAAC,EACxBzV,EAAyB,CAAC,EAChC,OAAO,QAAQ7C,CAAK,EAAE,QAASuY,GAAQ,CACrC,IAAM3gB,EAAO2gB,EAAI,CAAC,EACZ5e,EAAS4e,EAAI,CAAC,EACdhJ,EAAQ,KAAK,WAAW,QAAQ3X,CAAI,EAC1C,GAAI2X,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkB3X,CAAI,GAAG,EAE3C0gB,EAAW,KAAK3e,CAAM,EACtBkJ,EAAa,KAAK0M,CAAK,CACzB,CAAC,EAED,IAAMiJ,EAAoC,CAAC,EACrCzV,EAA0B,CAAC,EACjC,OAAO,QAAQ9C,CAAO,EAAE,QAASsY,GAAQ,CACvC,IAAM3gB,EAAO2gB,EAAI,CAAC,EACZ5e,EAAS4e,EAAI,CAAC,EACdhJ,EAAQ,KAAK,YAAY,QAAQ3X,CAAI,EAC3C,GAAI2X,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmB3X,CAAI,GAAG,EAE5C4gB,EAAY,KAAK7e,CAAM,EACvBoJ,EAAc,KAAKwM,CAAK,CAC1B,CAAC,EAED,IAAMzM,EAASwV,EAAW,IAAI,CAAC3B,EAAG3e,IAChCggB,GAAqBrB,EAAG,IAAM,UAAU,KAAK,WAAW9T,EAAa7K,CAAC,CAAC,CAAC,GAAG,CAC7E,EACMiL,EAAUuV,EAAY,IAAI,CAAC7B,EAAG3e,IAClC2e,EAAIqB,GAAqBrB,EAAG,IAAM,WAAW,KAAK,YAAY5T,EAAc/K,CAAC,CAAC,CAAC,GAAG,EAAI,IACxF,EAEMsI,EAAU,MAAM0C,GAAI,KAAK,UAAWH,EAAcC,EAAQC,EAAeE,EAAS5K,CAAO,EAEzFogB,EAAuC,CAAC,EAC9C,QAASzgB,EAAI,EAAGA,EAAIsI,EAAQ,OAAQtI,IAClCygB,EAAU,KAAK,YAAY1V,EAAc/K,CAAC,CAAC,CAAC,EAAIwgB,EAAYxgB,CAAC,GAAKigB,GAAqB3X,EAAQtI,CAAC,CAAC,EAEnG,OAAAkH,GAAe,EACRuZ,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdrV,GAAa,KAAK,SAAS,CAClC,CACF,ICzJA,IAAAsV,GAAA,GAAArX,GAAAqX,GAAA,mCAAAC,GAAA,oBAAAC,GAAA,gBAAAC,KAAA,IAcaD,GA4CAD,GAqCAE,GA/FbC,GAAAnhB,EAAA,kBAGA2J,KAEAoW,KACAS,KAQaS,GAAkB,IAAY,EACrC,OAAOxf,EAAI,KAAK,aAAgB,UAAYA,EAAI,KAAK,YAAc,KACrEA,EAAI,KAAK,YAAc,GAGzB,IAAM2f,EAAO3f,EAAI,KAAK,KAiBtB,GAhBI,OAAO2f,GAAS,WAAaA,IAAS,QAAaA,IAAS,SAAWA,IAAS,YAElF,QAAQ,KACN,qDAAqDA,CAAI,4DAC3D,EACA3f,EAAI,KAAK,KAAO,IAGd,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,EAAI,KAAK,UAAU,GAAKA,EAAI,KAAK,YAAc,EAY9G,GAAI,OAAO,KAAS,KAAe,CAAC,KAAK,oBACvCA,EAAI,KAAK,WAAa,MACjB,CACL,IAAM4f,EACJ,OAAO,UAAc,IAAc,GAAQ,SAAS,EAAE,KAAK,EAAE,OAAS,UAAU,oBAClF5f,EAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAM4f,GAAsB,GAAK,CAAC,CAAC,CAC5E,CAEJ,EAEaL,GAAN,KAAuD,CAS5D,MAAM,KAAK1gB,EAAoC,CAE7C2gB,GAAgB,EAGhB,MAAMpB,GAAmC,EAGzC,MAAMC,GAAgBxf,CAAW,CACnC,CASA,MAAM,8BACJogB,EACAhgB,EACkC,CAClC,IAAM0H,EAAU,IAAImY,GACpB,aAAMnY,EAAQ,UAAUsY,EAAchgB,CAAO,EACtC0H,CACT,CACF,EAEa8Y,GAAc,IAAIF,KC/F/B,IAAAM,GAAA,GAAA5X,GAAA4X,GAAA,sBAAArZ,GAAA,UAAAb,GAAA,sBAAAI,EAAA,oBAAAC,EAAA,qBAAAH,EAAA,mBAAAC,GAAA,WAAAlD,EAAA,YAAAkd,GAAA,QAAA9f,EAAA,oBAAA7B,IASA+J,KACAA,KAGAA,KCPO,IAAMrI,GAAU,SDKvB,IAAOigB,GAAQ9X,GAwBe,CAC5B,IAAMyX,EAAc,cAA0B,YAE5CthB,EAAgB,SAAUshB,EAAa,CAAC,EAGxCthB,EAAgB,QAASshB,EAAa,CAAC,EAEzCthB,EAAgB,MAAOshB,EAAa,EAAE,EACtCthB,EAAgB,OAAQshB,EAAa,EAAE,CACzC,CAEA,OAAO,eAAezf,EAAI,SAAU,MAAO,CAAE,MAAOH,GAAS,WAAY,EAAK,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Backend } from './backend.js';\r\nimport { InferenceSession } from './inference-session.js';\r\n\r\ninterface BackendInfo {\r\n  backend: Backend;\r\n  priority: number;\r\n\r\n  initPromise?: Promise<void>;\r\n  initialized?: boolean;\r\n  aborted?: boolean;\r\n  error?: string;\r\n}\r\n\r\nconst backends: Map<string, BackendInfo> = new Map();\r\nconst backendsSortedByPriority: string[] = [];\r\n\r\n/**\r\n * Register a backend.\r\n *\r\n * @param name - the name as a key to lookup as an execution provider.\r\n * @param backend - the backend object.\r\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\r\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\r\n *\r\n * @ignore\r\n */\r\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\r\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\r\n    const currentBackend = backends.get(name);\r\n    if (currentBackend === undefined) {\r\n      backends.set(name, { backend, priority });\r\n    } else if (currentBackend.priority > priority) {\r\n      // same name is already registered with a higher priority. skip registeration.\r\n      return;\r\n    } else if (currentBackend.priority === priority) {\r\n      if (currentBackend.backend !== backend) {\r\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\r\n      }\r\n    }\r\n\r\n    if (priority >= 0) {\r\n      const i = backendsSortedByPriority.indexOf(name);\r\n      if (i !== -1) {\r\n        backendsSortedByPriority.splice(i, 1);\r\n      }\r\n\r\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\r\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\r\n          backendsSortedByPriority.splice(i, 0, name);\r\n          return;\r\n        }\r\n      }\r\n      backendsSortedByPriority.push(name);\r\n    }\r\n    return;\r\n  }\r\n\r\n  throw new TypeError('not a valid backend');\r\n};\r\n\r\n/**\r\n * Try to resolve and initialize a backend.\r\n *\r\n * @param backendName - the name of the backend.\r\n * @returns the backend instance if resolved and initialized successfully, or an error message if failed.\r\n */\r\nconst tryResolveAndInitializeBackend = async (backendName: string): Promise<Backend | string> => {\r\n  const backendInfo = backends.get(backendName);\r\n  if (!backendInfo) {\r\n    return 'backend not found.';\r\n  }\r\n\r\n  if (backendInfo.initialized) {\r\n    return backendInfo.backend;\r\n  } else if (backendInfo.aborted) {\r\n    return backendInfo.error!;\r\n  } else {\r\n    const isInitializing = !!backendInfo.initPromise;\r\n    try {\r\n      if (!isInitializing) {\r\n        backendInfo.initPromise = backendInfo.backend.init(backendName);\r\n      }\r\n      await backendInfo.initPromise;\r\n      backendInfo.initialized = true;\r\n      return backendInfo.backend;\r\n    } catch (e) {\r\n      if (!isInitializing) {\r\n        backendInfo.error = `${e}`;\r\n        backendInfo.aborted = true;\r\n      }\r\n      return backendInfo.error!;\r\n    } finally {\r\n      delete backendInfo.initPromise;\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * Resolve execution providers from the specific session options.\r\n *\r\n * @param options - the session options object.\r\n * @returns a promise that resolves to a tuple of an initialized backend instance and a session options object with\r\n * filtered EP list.\r\n *\r\n * @ignore\r\n */\r\nexport const resolveBackendAndExecutionProviders = async (\r\n  options: InferenceSession.SessionOptions,\r\n): Promise<[backend: Backend, options: InferenceSession.SessionOptions]> => {\r\n  // extract backend hints from session options\r\n  const eps = options.executionProviders || [];\r\n  const backendHints = eps.map((i) => (typeof i === 'string' ? i : i.name));\r\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\r\n\r\n  // try to resolve and initialize all requested backends\r\n  let backend: Backend | undefined;\r\n  const errors = [];\r\n  const availableBackendNames = new Set<string>();\r\n  for (const backendName of backendNames) {\r\n    const resolveResult = await tryResolveAndInitializeBackend(backendName);\r\n    if (typeof resolveResult === 'string') {\r\n      errors.push({ name: backendName, err: resolveResult });\r\n    } else {\r\n      if (!backend) {\r\n        backend = resolveResult;\r\n      }\r\n      if (backend === resolveResult) {\r\n        availableBackendNames.add(backendName);\r\n      }\r\n    }\r\n  }\r\n\r\n  // if no backend is available, throw error.\r\n  if (!backend) {\r\n    throw new Error(`no available backend found. ERR: ${errors.map((e) => `[${e.name}] ${e.err}`).join(', ')}`);\r\n  }\r\n\r\n  // for each explicitly requested backend, if it's not available, output warning message.\r\n  for (const { name, err } of errors) {\r\n    if (backendHints.includes(name)) {\r\n      // eslint-disable-next-line no-console\r\n      console.warn(\r\n        `removing requested execution provider \"${name}\" from session options because it is not available: ${err}`,\r\n      );\r\n    }\r\n  }\r\n\r\n  const filteredEps = eps.filter((i) => availableBackendNames.has(typeof i === 'string' ? i : i.name));\r\n\r\n  return [\r\n    backend,\r\n    new Proxy(options, {\r\n      get: (target, prop) => {\r\n        if (prop === 'executionProviders') {\r\n          return filteredEps;\r\n        }\r\n        return Reflect.get(target, prop);\r\n      },\r\n    }),\r\n  ];\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession } from './inference-session.js';\r\nimport { OnnxValue } from './onnx-value.js';\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport declare namespace SessionHandler {\r\n  type FeedsType = { [name: string]: OnnxValue };\r\n  type FetchesType = { [name: string]: OnnxValue | null };\r\n  type ReturnType = { [name: string]: OnnxValue };\r\n}\r\n\r\n/**\r\n * Represents shared SessionHandler functionality\r\n *\r\n * @ignore\r\n */\r\ninterface SessionHandler {\r\n  dispose(): Promise<void>;\r\n\r\n  readonly inputNames: readonly string[];\r\n  readonly outputNames: readonly string[];\r\n\r\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n}\r\n\r\n/**\r\n * Represent a handler instance of an inference session.\r\n *\r\n * @ignore\r\n */\r\nexport interface InferenceSessionHandler extends SessionHandler {\r\n  startProfiling(): void;\r\n  endProfiling(): void;\r\n\r\n  run(\r\n    feeds: SessionHandler.FeedsType,\r\n    fetches: SessionHandler.FetchesType,\r\n    options: InferenceSession.RunOptions,\r\n  ): Promise<SessionHandler.ReturnType>;\r\n}\r\n\r\n/**\r\n * Represent a backend that provides implementation of model inferencing.\r\n *\r\n * @ignore\r\n */\r\nexport interface Backend {\r\n  /**\r\n   * Initialize the backend asynchronously. Should throw when failed.\r\n   */\r\n  init(backendName: string): Promise<void>;\r\n\r\n  createInferenceSessionHandler(\r\n    uriOrBuffer: string | Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n}\r\n\r\nexport { registerBackend } from './backend-impl.js';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// This file is generated by /js/scripts/update-version.ts\r\n// Do not modify file content manually.\r\n\r\nexport const version = '1.23.0';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Env } from './env.js';\r\nimport { version } from './version.js';\r\n\r\ntype LogLevelType = Env['logLevel'];\r\n\r\nlet logLevelValue: Required<LogLevelType> = 'warning';\r\n\r\nexport const env: Env = {\r\n  wasm: {} as Env.WebAssemblyFlags,\r\n  webgl: {} as Env.WebGLFlags,\r\n  webgpu: {} as Env.WebGpuFlags,\r\n  versions: { common: version },\r\n\r\n  set logLevel(value: LogLevelType) {\r\n    if (value === undefined) {\r\n      return;\r\n    }\r\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\r\n      throw new Error(`Unsupported logging level: ${value}`);\r\n    }\r\n    logLevelValue = value;\r\n  },\r\n  get logLevel(): Required<LogLevelType> {\r\n    return logLevelValue;\r\n  },\r\n};\r\n\r\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\r\nObject.defineProperty(env, 'logLevel', { enumerable: true });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env as envImpl } from './env-impl.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\nexport declare namespace Env {\r\n  export type WasmPathPrefix = string;\r\n  export interface WasmFilePaths {\r\n    /**\r\n     * Specify the override path for the main .wasm file.\r\n     *\r\n     * This path should be an absolute path.\r\n     *\r\n     * If not modified, the filename of the .wasm file is:\r\n     * - `ort-wasm-simd-threaded.wasm` for default build\r\n     * - `ort-wasm-simd-threaded.jsep.wasm` for JSEP build (with WebGPU and WebNN)\r\n     * - `ort-wasm-simd-threaded.asyncify.wasm` for WebGPU build with Asyncify (with WebNN)\r\n     */\r\n    wasm?: URL | string;\r\n    /**\r\n     * Specify the override path for the main .mjs file.\r\n     *\r\n     * This path should be an absolute path.\r\n     *\r\n     * If not modified, the filename of the .mjs file is:\r\n     * - `ort-wasm-simd-threaded.mjs` for default build\r\n     * - `ort-wasm-simd-threaded.jsep.mjs` for JSEP build (with WebGPU and WebNN)\r\n     * - `ort-wasm-simd-threaded.asyncify.mjs` for WebGPU build with Asyncify (with WebNN)\r\n     */\r\n    mjs?: URL | string;\r\n  }\r\n  export type WasmPrefixOrFilePaths = WasmPathPrefix | WasmFilePaths;\r\n  export interface WebAssemblyFlags {\r\n    /**\r\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\r\n     * to 1, no worker thread will be spawned.\r\n     *\r\n     * This setting is available only when WebAssembly multithread feature is available in current context.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    numThreads?: number;\r\n\r\n    /**\r\n     * set a value indicating whether to enable SIMD.\r\n     *\r\n     * ONNX Runtime will perform feature detection based on the value of this property. Specifically, when the value is\r\n     * set to:\r\n     * - `undefined`, `true` or `\"fixed\"`: will check availability of Fixed-width SIMD.\r\n     * - `\"relaxed\"`: will check availability of Relaxed SIMD.\r\n     * - `false`: will not perform SIMD feature checking.\r\n     *\r\n     * Setting this property does not make ONNX Runtime to switch to the corresponding runtime automatically. User need\r\n     * to set `wasmPaths` or `wasmBinary` property to load the corresponding runtime.\r\n     *\r\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\r\n     *\r\n     * @defaultValue `true`\r\n     */\r\n    simd?: boolean | 'fixed' | 'relaxed';\r\n\r\n    /**\r\n     * set or get a boolean value indicating whether to enable trace.\r\n     *\r\n     * @defaultValue `false`\r\n     *\r\n     * @deprecated Use `env.trace` instead. If `env.trace` is set, this property will be ignored.\r\n     */\r\n    trace?: boolean;\r\n\r\n    /**\r\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\r\n     * value indicates no timeout is set.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    initTimeout?: number;\r\n\r\n    /**\r\n     * Set a custom URL prefix to the .wasm/.mjs files, or an object of overrides for both .wasm/.mjs file. The override\r\n     * path should be an absolute path.\r\n     */\r\n    wasmPaths?: WasmPrefixOrFilePaths;\r\n\r\n    /**\r\n     * Set a custom buffer which contains the WebAssembly binary. If this property is set, the `wasmPaths` property will\r\n     * be ignored.\r\n     */\r\n    wasmBinary?: ArrayBufferLike | Uint8Array;\r\n\r\n    /**\r\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    proxy?: boolean;\r\n  }\r\n\r\n  export interface WebGLFlags {\r\n    /**\r\n     * Set or get the WebGL Context ID (webgl or webgl2).\r\n     *\r\n     * @defaultValue `'webgl2'`\r\n     */\r\n    contextId?: 'webgl' | 'webgl2';\r\n    /**\r\n     * Get the WebGL rendering context.\r\n     */\r\n    readonly context: WebGLRenderingContext;\r\n    /**\r\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\r\n     *\r\n     * @deprecated\r\n     */\r\n    matmulMaxBatchSize?: number;\r\n    /**\r\n     * Set or get the texture cache mode.\r\n     *\r\n     * @defaultValue `'full'`\r\n     */\r\n    textureCacheMode?: 'initializerOnly' | 'full';\r\n    /**\r\n     * Set or get the packed texture mode\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    pack?: boolean;\r\n    /**\r\n     * Set or get whether enable async download.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    async?: boolean;\r\n  }\r\n\r\n  export interface WebGpuProfilingDataV1TensorMetadata {\r\n    dims: readonly number[];\r\n    dataType: string;\r\n  }\r\n  export interface WebGpuProfilingDataV1 {\r\n    version: 1;\r\n    inputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\r\n    outputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\r\n    kernelId: number;\r\n    kernelType: string;\r\n    kernelName: string;\r\n    programName: string;\r\n    startTime: number;\r\n    endTime: number;\r\n  }\r\n\r\n  export type WebGpuProfilingData = WebGpuProfilingDataV1;\r\n\r\n  export interface WebGpuFlags {\r\n    /**\r\n     * Set or get the profiling mode.\r\n     *\r\n     * @deprecated Use `env.webgpu.profiling.mode` instead. If `env.webgpu.profiling.mode` is set, this property will be\r\n     * ignored.\r\n     */\r\n    profilingMode?: 'off' | 'default';\r\n    /**\r\n     * Set or get the profiling configuration.\r\n     */\r\n    profiling: {\r\n      /**\r\n       * Set or get the profiling mode.\r\n       *\r\n       * @defaultValue `'off'`\r\n       */\r\n      mode?: 'off' | 'default';\r\n\r\n      /**\r\n       * Set or get a callback function when a profiling data is received. If not set, the profiling data will be\r\n       * printed to console.\r\n       */\r\n      ondata?: (data: WebGpuProfilingData) => void;\r\n    };\r\n    /**\r\n     * Set or get the power preference.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as options for `navigator.gpu.requestAdapter()`.\r\n     *\r\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\r\n     *\r\n     * @defaultValue `undefined`\r\n     *\r\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\r\n     * you want to use a specific power preference.\r\n     */\r\n    powerPreference?: 'low-power' | 'high-performance';\r\n    /**\r\n     * Set or get the force fallback adapter flag.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as options for `navigator.gpu.requestAdapter()`.\r\n     *\r\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\r\n     *\r\n     * @defaultValue `undefined`\r\n     *\r\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\r\n     * you want to use a specific fallback option.\r\n     */\r\n    forceFallbackAdapter?: boolean;\r\n    /**\r\n     * Set or get the adapter for WebGPU.\r\n     *\r\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\r\n     * used as the GPU adapter for the underlying WebGPU backend to create GPU device.\r\n     *\r\n     * If this property is not set, it will be available to get after the first WebGPU inference session is created. The\r\n     * value will be the GPU adapter that created by the underlying WebGPU backend.\r\n     *\r\n     * When use with TypeScript, the type of this property is `GPUAdapter` defined in \"@webgpu/types\".\r\n     *\r\n     * @deprecated It is no longer recommended to use this property. The latest WebGPU spec adds `GPUDevice.adapterInfo`\r\n     * (https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo), which allows to get the adapter information from the\r\n     * device. When it's available, there is no need to set/get the {@link adapter} property.\r\n     */\r\n    adapter: TryGetGlobalType<'GPUAdapter'>;\r\n    /**\r\n     * Set or get the GPU device for WebGPU.\r\n     *\r\n     * There are 3 valid scenarios of accessing this property:\r\n     * - Set a value before the first WebGPU inference session is created. The value will be used by the WebGPU backend\r\n     * to perform calculations. If the value is not a `GPUDevice` object, an error will be thrown.\r\n     * - Get the value before the first WebGPU inference session is created. This will try to create a new GPUDevice\r\n     * instance. Returns a `Promise` that resolves to a `GPUDevice` object.\r\n     * - Get the value after the first WebGPU inference session is created. Returns a resolved `Promise` to the\r\n     * `GPUDevice` object used by the WebGPU backend.\r\n     */\r\n    get device(): Promise<TryGetGlobalType<'GPUDevice'>>;\r\n    set device(value: TryGetGlobalType<'GPUDevice'>);\r\n    /**\r\n     * Set or get whether validate input content.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    validateInputContent?: boolean;\r\n  }\r\n}\r\n\r\nexport interface Env {\r\n  /**\r\n   * set the severity level for logging.\r\n   *\r\n   * @defaultValue `'warning'`\r\n   */\r\n  logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal';\r\n\r\n  /**\r\n   * Indicate whether run in debug mode.\r\n   *\r\n   * @defaultValue `false`\r\n   */\r\n  debug?: boolean;\r\n\r\n  /**\r\n   * set or get a boolean value indicating whether to enable trace.\r\n   *\r\n   * @defaultValue `false`\r\n   */\r\n  trace?: boolean;\r\n\r\n  /**\r\n   * Get version of the current package.\r\n   */\r\n  readonly versions: {\r\n    readonly common: string;\r\n    readonly web?: string;\r\n    readonly node?: string;\r\n    // eslint-disable-next-line @typescript-eslint/naming-convention\r\n    readonly 'react-native'?: string;\r\n  };\r\n\r\n  /**\r\n   * Represent a set of flags for WebAssembly\r\n   */\r\n  readonly wasm: Env.WebAssemblyFlags;\r\n\r\n  /**\r\n   * Represent a set of flags for WebGL\r\n   */\r\n  readonly webgl: Env.WebGLFlags;\r\n\r\n  /**\r\n   * Represent a set of flags for WebGPU\r\n   */\r\n  readonly webgpu: Env.WebGpuFlags;\r\n\r\n  [name: string]: unknown;\r\n}\r\n\r\n/**\r\n * Represent a set of flags as a global singleton.\r\n */\r\nexport const env: Env = envImpl;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\r\nimport { Tensor } from './tensor.js';\r\n\r\n/**\r\n * implementation of Tensor.toDataURL()\r\n */\r\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\r\n  const canvas = typeof document !== 'undefined' ? document.createElement('canvas') : new OffscreenCanvas(1, 1);\r\n  canvas.width = tensor.dims[3];\r\n  canvas.height = tensor.dims[2];\r\n  const pixels2DContext = canvas.getContext('2d') as\r\n    | CanvasRenderingContext2D\r\n    | OffscreenCanvasRenderingContext2D\r\n    | null;\r\n\r\n  if (pixels2DContext != null) {\r\n    // Default values for height and width & format\r\n    let width: number;\r\n    let height: number;\r\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\r\n      width = tensor.dims[2];\r\n      height = tensor.dims[3];\r\n    } else {\r\n      // Default layout is NCWH\r\n      width = tensor.dims[3];\r\n      height = tensor.dims[2];\r\n    }\r\n\r\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\r\n\r\n    const norm = options?.norm;\r\n    let normMean: [number, number, number, number];\r\n    let normBias: [number, number, number, number];\r\n    if (norm === undefined || norm.mean === undefined) {\r\n      normMean = [255, 255, 255, 255];\r\n    } else {\r\n      if (typeof norm.mean === 'number') {\r\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n      } else {\r\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\r\n        if (norm.mean[3] !== undefined) {\r\n          normMean[3] = norm.mean[3];\r\n        }\r\n      }\r\n    }\r\n    if (norm === undefined || norm.bias === undefined) {\r\n      normBias = [0, 0, 0, 0];\r\n    } else {\r\n      if (typeof norm.bias === 'number') {\r\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n      } else {\r\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\r\n        if (norm.bias[3] !== undefined) {\r\n          normBias[3] = norm.bias[3];\r\n        }\r\n      }\r\n    }\r\n\r\n    const stride = height * width;\r\n    // Default pointer assignments\r\n    let rTensorPointer = 0,\r\n      gTensorPointer = stride,\r\n      bTensorPointer = stride * 2,\r\n      aTensorPointer = -1;\r\n\r\n    // Updating the pointer assignments based on the input image format\r\n    if (inputformat === 'RGBA') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n      aTensorPointer = stride * 3;\r\n    } else if (inputformat === 'RGB') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n    } else if (inputformat === 'RBG') {\r\n      rTensorPointer = 0;\r\n      bTensorPointer = stride;\r\n      gTensorPointer = stride * 2;\r\n    }\r\n\r\n    for (let i = 0; i < height; i++) {\r\n      for (let j = 0; j < width; j++) {\r\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\r\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\r\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\r\n        const A = aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\r\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\r\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\r\n        pixels2DContext.fillRect(j, i, 1, 1);\r\n      }\r\n    }\r\n    if ('toDataURL' in canvas) {\r\n      return canvas.toDataURL();\r\n    } else {\r\n      throw new Error('toDataURL is not supported');\r\n    }\r\n  } else {\r\n    throw new Error('Can not access image data');\r\n  }\r\n};\r\n\r\n/**\r\n * implementation of Tensor.toImageData()\r\n */\r\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\r\n  const pixels2DContext =\r\n    typeof document !== 'undefined'\r\n      ? document.createElement('canvas').getContext('2d')\r\n      : (new OffscreenCanvas(1, 1).getContext('2d') as OffscreenCanvasRenderingContext2D);\r\n  let image: ImageData;\r\n  if (pixels2DContext != null) {\r\n    // Default values for height and width & format\r\n    let width: number;\r\n    let height: number;\r\n    let channels: number;\r\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\r\n      width = tensor.dims[2];\r\n      height = tensor.dims[1];\r\n      channels = tensor.dims[3];\r\n    } else {\r\n      // Default layout is NCWH\r\n      width = tensor.dims[3];\r\n      height = tensor.dims[2];\r\n      channels = tensor.dims[1];\r\n    }\r\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\r\n\r\n    const norm = options?.norm;\r\n    let normMean: [number, number, number, number];\r\n    let normBias: [number, number, number, number];\r\n    if (norm === undefined || norm.mean === undefined) {\r\n      normMean = [255, 255, 255, 255];\r\n    } else {\r\n      if (typeof norm.mean === 'number') {\r\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n      } else {\r\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\r\n        if (norm.mean[3] !== undefined) {\r\n          normMean[3] = norm.mean[3];\r\n        }\r\n      }\r\n    }\r\n    if (norm === undefined || norm.bias === undefined) {\r\n      normBias = [0, 0, 0, 0];\r\n    } else {\r\n      if (typeof norm.bias === 'number') {\r\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n      } else {\r\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\r\n        if (norm.bias[3] !== undefined) {\r\n          normBias[3] = norm.bias[3];\r\n        }\r\n      }\r\n    }\r\n\r\n    const stride = height * width;\r\n    if (options !== undefined) {\r\n      if (\r\n        (options.format !== undefined && channels === 4 && options.format !== 'RGBA') ||\r\n        (channels === 3 && options.format !== 'RGB' && options.format !== 'BGR')\r\n      ) {\r\n        throw new Error(\"Tensor format doesn't match input tensor dims\");\r\n      }\r\n    }\r\n\r\n    // Default pointer assignments\r\n    const step = 4;\r\n    let rImagePointer = 0,\r\n      gImagePointer = 1,\r\n      bImagePointer = 2,\r\n      aImagePointer = 3;\r\n    let rTensorPointer = 0,\r\n      gTensorPointer = stride,\r\n      bTensorPointer = stride * 2,\r\n      aTensorPointer = -1;\r\n\r\n    // Updating the pointer assignments based on the input image format\r\n    if (inputformat === 'RGBA') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n      aTensorPointer = stride * 3;\r\n    } else if (inputformat === 'RGB') {\r\n      rTensorPointer = 0;\r\n      gTensorPointer = stride;\r\n      bTensorPointer = stride * 2;\r\n    } else if (inputformat === 'RBG') {\r\n      rTensorPointer = 0;\r\n      bTensorPointer = stride;\r\n      gTensorPointer = stride * 2;\r\n    }\r\n\r\n    image = pixels2DContext.createImageData(width, height);\r\n\r\n    for (\r\n      let i = 0;\r\n      i < height * width;\r\n      rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++\r\n    ) {\r\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\r\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\r\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\r\n      image.data[aImagePointer] =\r\n        aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\r\n    }\r\n  } else {\r\n    throw new Error('Can not access image data');\r\n  }\r\n  return image;\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  OptionsDimensions,\r\n  OptionsFormat,\r\n  OptionsNormalizationParameters,\r\n  OptionsTensorFormat,\r\n  OptionsTensorLayout,\r\n  TensorFromGpuBufferOptions,\r\n  TensorFromImageBitmapOptions,\r\n  TensorFromImageDataOptions,\r\n  TensorFromImageElementOptions,\r\n  TensorFromMLTensorOptions,\r\n  TensorFromTextureOptions,\r\n  TensorFromUrlOptions,\r\n} from './tensor-factory.js';\r\nimport { Tensor } from './tensor-impl.js';\r\nimport { Tensor as TensorInterface } from './tensor.js';\r\n\r\ninterface BufferToTensorOptions\r\n  extends OptionsDimensions,\r\n    OptionsTensorLayout,\r\n    OptionsNormalizationParameters,\r\n    OptionsFormat,\r\n    OptionsTensorFormat {}\r\n\r\n/**\r\n * Create a new tensor object from image object\r\n *\r\n * @param buffer - Extracted image buffer data - assuming RGBA format\r\n * @param imageFormat - input image configuration - required configurations height, width, format\r\n * @param tensorFormat - output tensor configuration - Default is RGB format\r\n */\r\nexport const bufferToTensor = (buffer: Uint8ClampedArray | undefined, options: BufferToTensorOptions): Tensor => {\r\n  if (buffer === undefined) {\r\n    throw new Error('Image buffer must be defined');\r\n  }\r\n  if (options.height === undefined || options.width === undefined) {\r\n    throw new Error('Image height and width must be defined');\r\n  }\r\n  if (options.tensorLayout === 'NHWC') {\r\n    throw new Error('NHWC Tensor layout is not supported yet');\r\n  }\r\n\r\n  const { height, width } = options;\r\n\r\n  const norm = options.norm ?? { mean: 255, bias: 0 };\r\n  let normMean: [number, number, number, number];\r\n  let normBias: [number, number, number, number];\r\n\r\n  if (typeof norm.mean === 'number') {\r\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\r\n  } else {\r\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\r\n  }\r\n\r\n  if (typeof norm.bias === 'number') {\r\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\r\n  } else {\r\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\r\n  }\r\n\r\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\r\n  // default value is RGBA since imagedata and HTMLImageElement uses it\r\n\r\n  const outputformat =\r\n    options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\r\n  const stride = height * width;\r\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\r\n\r\n  // Default pointer assignments\r\n  let step = 4,\r\n    rImagePointer = 0,\r\n    gImagePointer = 1,\r\n    bImagePointer = 2,\r\n    aImagePointer = 3;\r\n  let rTensorPointer = 0,\r\n    gTensorPointer = stride,\r\n    bTensorPointer = stride * 2,\r\n    aTensorPointer = -1;\r\n\r\n  // Updating the pointer assignments based on the input image format\r\n  if (inputformat === 'RGB') {\r\n    step = 3;\r\n    rImagePointer = 0;\r\n    gImagePointer = 1;\r\n    bImagePointer = 2;\r\n    aImagePointer = -1;\r\n  }\r\n\r\n  // Updating the pointer assignments based on the output tensor format\r\n  if (outputformat === 'RGBA') {\r\n    aTensorPointer = stride * 3;\r\n  } else if (outputformat === 'RBG') {\r\n    rTensorPointer = 0;\r\n    bTensorPointer = stride;\r\n    gTensorPointer = stride * 2;\r\n  } else if (outputformat === 'BGR') {\r\n    bTensorPointer = 0;\r\n    gTensorPointer = stride;\r\n    rTensorPointer = stride * 2;\r\n  }\r\n\r\n  for (\r\n    let i = 0;\r\n    i < stride;\r\n    i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step\r\n  ) {\r\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\r\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\r\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\r\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\r\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\r\n    }\r\n  }\r\n\r\n  // Float32Array -> ort.Tensor\r\n  const outputTensor =\r\n    outputformat === 'RGBA'\r\n      ? new Tensor('float32', float32Data, [1, 4, height, width])\r\n      : new Tensor('float32', float32Data, [1, 3, height, width]);\r\n  return outputTensor;\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromImage().\r\n */\r\nexport const tensorFromImage = async (\r\n  image: ImageData | HTMLImageElement | ImageBitmap | string,\r\n  options?:\r\n    | TensorFromImageDataOptions\r\n    | TensorFromImageElementOptions\r\n    | TensorFromImageBitmapOptions\r\n    | TensorFromUrlOptions,\r\n): Promise<Tensor> => {\r\n  // checking the type of image object\r\n  const isHTMLImageEle = typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement;\r\n  const isImageDataEle = typeof ImageData !== 'undefined' && image instanceof ImageData;\r\n  const isImageBitmap = typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap;\r\n  const isString = typeof image === 'string';\r\n\r\n  let data: Uint8ClampedArray | undefined;\r\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\r\n\r\n  const createCanvas = () => {\r\n    if (typeof document !== 'undefined') {\r\n      return document.createElement('canvas');\r\n    } else if (typeof OffscreenCanvas !== 'undefined') {\r\n      return new OffscreenCanvas(1, 1);\r\n    } else {\r\n      throw new Error('Canvas is not supported');\r\n    }\r\n  };\r\n  const createCanvasContext = (canvas: HTMLCanvasElement | OffscreenCanvas) => {\r\n    if (typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement) {\r\n      return canvas.getContext('2d');\r\n    } else if (canvas instanceof OffscreenCanvas) {\r\n      return canvas.getContext('2d') as OffscreenCanvasRenderingContext2D;\r\n    } else {\r\n      return null;\r\n    }\r\n  };\r\n  // filling and checking image configuration options\r\n  if (isHTMLImageEle) {\r\n    // HTMLImageElement - image object - format is RGBA by default\r\n    const canvas = createCanvas();\r\n    canvas.width = image.width;\r\n    canvas.height = image.height;\r\n    const pixels2DContext = createCanvasContext(canvas);\r\n\r\n    if (pixels2DContext != null) {\r\n      let height = image.height;\r\n      let width = image.width;\r\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\r\n        height = options.resizedHeight;\r\n        width = options.resizedWidth;\r\n      }\r\n\r\n      if (options !== undefined) {\r\n        bufferToTensorOptions = options;\r\n        if (options.tensorFormat !== undefined) {\r\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\r\n        } else {\r\n          bufferToTensorOptions.tensorFormat = 'RGBA';\r\n        }\r\n        bufferToTensorOptions.height = height;\r\n        bufferToTensorOptions.width = width;\r\n      } else {\r\n        bufferToTensorOptions.tensorFormat = 'RGBA';\r\n        bufferToTensorOptions.height = height;\r\n        bufferToTensorOptions.width = width;\r\n      }\r\n\r\n      pixels2DContext.drawImage(image, 0, 0);\r\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n    } else {\r\n      throw new Error('Can not access image data');\r\n    }\r\n  } else if (isImageDataEle) {\r\n    let height: number;\r\n    let width: number;\r\n\r\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\r\n      height = options.resizedHeight;\r\n      width = options.resizedWidth;\r\n    } else {\r\n      height = image.height;\r\n      width = image.width;\r\n    }\r\n\r\n    if (options !== undefined) {\r\n      bufferToTensorOptions = options;\r\n    }\r\n    bufferToTensorOptions.format = 'RGBA';\r\n    bufferToTensorOptions.height = height;\r\n    bufferToTensorOptions.width = width;\r\n\r\n    if (options !== undefined) {\r\n      const tempCanvas = createCanvas();\r\n\r\n      tempCanvas.width = width;\r\n      tempCanvas.height = height;\r\n\r\n      const pixels2DContext = createCanvasContext(tempCanvas);\r\n\r\n      if (pixels2DContext != null) {\r\n        pixels2DContext.putImageData(image, 0, 0);\r\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n      } else {\r\n        throw new Error('Can not access image data');\r\n      }\r\n    } else {\r\n      data = image.data;\r\n    }\r\n  } else if (isImageBitmap) {\r\n    // ImageBitmap - image object - format must be provided by user\r\n    if (options === undefined) {\r\n      throw new Error('Please provide image config with format for Imagebitmap');\r\n    }\r\n\r\n    const canvas = createCanvas();\r\n    canvas.width = image.width;\r\n    canvas.height = image.height;\r\n    const pixels2DContext = createCanvasContext(canvas);\r\n\r\n    if (pixels2DContext != null) {\r\n      const height = image.height;\r\n      const width = image.width;\r\n      pixels2DContext.drawImage(image, 0, 0, width, height);\r\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\r\n      bufferToTensorOptions.height = height;\r\n      bufferToTensorOptions.width = width;\r\n      return bufferToTensor(data, bufferToTensorOptions);\r\n    } else {\r\n      throw new Error('Can not access image data');\r\n    }\r\n  } else if (isString) {\r\n    return new Promise((resolve, reject) => {\r\n      const canvas = createCanvas();\r\n      const context = createCanvasContext(canvas);\r\n      if (!image || !context) {\r\n        return reject();\r\n      }\r\n      const newImage = new Image();\r\n      newImage.crossOrigin = 'Anonymous';\r\n      newImage.src = image;\r\n      newImage.onload = () => {\r\n        canvas.width = newImage.width;\r\n        canvas.height = newImage.height;\r\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\r\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\r\n\r\n        bufferToTensorOptions.height = canvas.height;\r\n        bufferToTensorOptions.width = canvas.width;\r\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\r\n      };\r\n    });\r\n  } else {\r\n    throw new Error('Input data provided is not supported - aborted tensor creation');\r\n  }\r\n\r\n  if (data !== undefined) {\r\n    return bufferToTensor(data, bufferToTensorOptions);\r\n  } else {\r\n    throw new Error('Input data provided is not supported - aborted tensor creation');\r\n  }\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromTexture().\r\n */\r\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\r\n  texture: TensorInterface.TextureType,\r\n  options: TensorFromTextureOptions<T>,\r\n): Tensor => {\r\n  const { width, height, download, dispose } = options;\r\n  // Always assume RGBAF32. TODO: support different texture format\r\n  const dims = [1, height, width, 4];\r\n  return new Tensor({ location: 'texture', type: 'float32', texture, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromGpuBuffer().\r\n */\r\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\r\n  gpuBuffer: TensorInterface.GpuBufferType,\r\n  options: TensorFromGpuBufferOptions<T>,\r\n): Tensor => {\r\n  const { dataType, dims, download, dispose } = options;\r\n  return new Tensor({ location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromMLTensor().\r\n */\r\nexport const tensorFromMLTensor = <T extends TensorInterface.MLTensorDataTypes>(\r\n  mlTensor: TensorInterface.MLTensorType,\r\n  options: TensorFromMLTensorOptions<T>,\r\n): Tensor => {\r\n  const { dataType, dims, download, dispose } = options;\r\n  return new Tensor({ location: 'ml-tensor', type: dataType ?? 'float32', mlTensor, dims, download, dispose });\r\n};\r\n\r\n/**\r\n * implementation of Tensor.fromPinnedBuffer().\r\n */\r\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\r\n  type: T,\r\n  buffer: TensorInterface.DataTypeMap[T],\r\n  dims?: readonly number[],\r\n): Tensor => new Tensor({ location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length] });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from './tensor.js';\r\n\r\nexport type SupportedTypedArrayConstructors =\r\n  | Float32ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Int8ArrayConstructor\r\n  | Uint16ArrayConstructor\r\n  | Int16ArrayConstructor\r\n  | Int32ArrayConstructor\r\n  | BigInt64ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Float64ArrayConstructor\r\n  | Uint32ArrayConstructor\r\n  | BigUint64ArrayConstructor;\r\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\r\n  ['float32', Float32Array],\r\n  ['uint8', Uint8Array],\r\n  ['int8', Int8Array],\r\n  ['uint16', Uint16Array],\r\n  ['int16', Int16Array],\r\n  ['int32', Int32Array],\r\n  ['bool', Uint8Array],\r\n  ['float64', Float64Array],\r\n  ['uint32', Uint32Array],\r\n  ['int4', Uint8Array],\r\n  ['uint4', Uint8Array],\r\n]);\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\r\n  [Float32Array, 'float32'],\r\n  [Uint8Array, 'uint8'],\r\n  [Int8Array, 'int8'],\r\n  [Uint16Array, 'uint16'],\r\n  [Int16Array, 'int16'],\r\n  [Int32Array, 'int32'],\r\n  [Float64Array, 'float64'],\r\n  [Uint32Array, 'uint32'],\r\n]);\r\n\r\n// the following code allows delaying execution of BigInt/Float16Array checking. This allows lazy initialization for\r\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt/Float16Array\r\n// polyfill if available.\r\nlet isTypedArrayChecked = false;\r\nexport const checkTypedArray = () => {\r\n  if (!isTypedArrayChecked) {\r\n    isTypedArrayChecked = true;\r\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && BigInt64Array.from;\r\n    const isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && BigUint64Array.from;\r\n\r\n    // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\r\n    const Float16Array = (globalThis as any).Float16Array;\r\n    const isFloat16ArrayAvailable = typeof Float16Array !== 'undefined' && Float16Array.from;\r\n\r\n    if (isBigInt64ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\r\n    }\r\n    if (isBigUint64ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\r\n    }\r\n    if (isFloat16ArrayAvailable) {\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Float16Array);\r\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(Float16Array, 'float16');\r\n    } else {\r\n      // if Float16Array is not available, use 'Uint16Array' to store the data.\r\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Uint16Array);\r\n    }\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  CpuPinnedConstructorParameters,\r\n  GpuBufferConstructorParameters,\r\n  MLTensorConstructorParameters,\r\n  TextureConstructorParameters,\r\n} from './tensor-factory.js';\r\nimport { Tensor } from './tensor-impl.js';\r\n\r\n/**\r\n * calculate size from dims.\r\n *\r\n * @param dims the dims array. May be an illegal input.\r\n */\r\nexport const calculateSize = (dims: readonly unknown[]): number => {\r\n  let size = 1;\r\n  for (let i = 0; i < dims.length; i++) {\r\n    const dim = dims[i];\r\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\r\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\r\n    }\r\n    if (dim < 0) {\r\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\r\n    }\r\n    size *= dim;\r\n  }\r\n  return size;\r\n};\r\n\r\n/**\r\n * implementation of Tensor.reshape()\r\n */\r\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\r\n  switch (tensor.location) {\r\n    case 'cpu':\r\n      return new Tensor(tensor.type, tensor.data, dims);\r\n    case 'cpu-pinned':\r\n      return new Tensor({\r\n        location: 'cpu-pinned',\r\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\r\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'texture':\r\n      return new Tensor({\r\n        location: 'texture',\r\n        texture: tensor.texture,\r\n        type: tensor.type as TextureConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'gpu-buffer':\r\n      return new Tensor({\r\n        location: 'gpu-buffer',\r\n        gpuBuffer: tensor.gpuBuffer,\r\n        type: tensor.type as GpuBufferConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    case 'ml-tensor':\r\n      return new Tensor({\r\n        location: 'ml-tensor',\r\n        mlTensor: tensor.mlTensor,\r\n        type: tensor.type as MLTensorConstructorParameters['type'],\r\n        dims,\r\n      });\r\n    default:\r\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { tensorToDataURL, tensorToImageData } from './tensor-conversion-impl.js';\r\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\r\nimport {\r\n  tensorFromGpuBuffer,\r\n  tensorFromImage,\r\n  tensorFromMLTensor,\r\n  tensorFromPinnedBuffer,\r\n  tensorFromTexture,\r\n} from './tensor-factory-impl.js';\r\nimport {\r\n  CpuPinnedConstructorParameters,\r\n  GpuBufferConstructorParameters,\r\n  MLTensorConstructorParameters,\r\n  TensorFromGpuBufferOptions,\r\n  TensorFromImageBitmapOptions,\r\n  TensorFromImageDataOptions,\r\n  TensorFromImageElementOptions,\r\n  TensorFromMLTensorOptions,\r\n  TensorFromTextureOptions,\r\n  TensorFromUrlOptions,\r\n  TextureConstructorParameters,\r\n} from './tensor-factory.js';\r\nimport {\r\n  checkTypedArray,\r\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP,\r\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP,\r\n  SupportedTypedArray,\r\n  SupportedTypedArrayConstructors,\r\n} from './tensor-impl-type-mapping.js';\r\nimport { calculateSize, tensorReshape } from './tensor-utils-impl.js';\r\nimport { Tensor as TensorInterface } from './tensor.js';\r\n\r\n// type aliases for those exported from Tensor interface\r\n\r\ntype TensorType = TensorInterface.Type;\r\ntype TensorDataType = TensorInterface.DataType;\r\ntype TensorDataLocation = TensorInterface.DataLocation;\r\ntype TensorTextureType = TensorInterface.TextureType;\r\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\r\ntype TensorMLTensorType = TensorInterface.MLTensorType;\r\n\r\n/**\r\n * the implementation of Tensor interface.\r\n *\r\n * @ignore\r\n */\r\nexport class Tensor implements TensorInterface {\r\n  // #region constructors\r\n\r\n  /**\r\n   * Construct a new CPU tensor object from the given type, data and dims.\r\n   */\r\n  constructor(\r\n    type: TensorType,\r\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly number[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  );\r\n  /**\r\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\r\n   */\r\n  constructor(\r\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  );\r\n  /**\r\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'cpu-pinned'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: CpuPinnedConstructorParameters);\r\n  /**\r\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'texture'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: TextureConstructorParameters);\r\n  /**\r\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'gpu-buffer'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: GpuBufferConstructorParameters);\r\n\r\n  /**\r\n   * Construct a new tensor object from the WebNN MLTensor with the given type and dims.\r\n   *\r\n   * Tensor's location will be set to 'ml-tensor'.\r\n   *\r\n   * @param params - Specify the parameters to construct the tensor.\r\n   */\r\n  constructor(params: MLTensorConstructorParameters);\r\n\r\n  /**\r\n   * implementation.\r\n   */\r\n  constructor(\r\n    arg0:\r\n      | TensorType\r\n      | TensorDataType\r\n      | Uint8ClampedArray\r\n      | readonly string[]\r\n      | readonly boolean[]\r\n      | CpuPinnedConstructorParameters\r\n      | TextureConstructorParameters\r\n      | GpuBufferConstructorParameters\r\n      | MLTensorConstructorParameters,\r\n    arg1?: TensorDataType | Uint8ClampedArray | readonly number[] | readonly string[] | readonly boolean[],\r\n    arg2?: readonly number[],\r\n  ) {\r\n    // perform one-time check for BigInt/Float16Array support\r\n    checkTypedArray();\r\n\r\n    let type: TensorType;\r\n    let dims: readonly number[];\r\n\r\n    if (typeof arg0 === 'object' && 'location' in arg0) {\r\n      //\r\n      // constructing tensor from specific location\r\n      //\r\n      this.dataLocation = arg0.location;\r\n      type = arg0.type;\r\n      dims = arg0.dims;\r\n      switch (arg0.location) {\r\n        case 'cpu-pinned': {\r\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\r\n          if (!expectedTypedArrayConstructor) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\r\n          }\r\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\r\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\r\n          }\r\n          this.cpuData = arg0.data;\r\n          break;\r\n        }\r\n        case 'texture': {\r\n          if (type !== 'float32') {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\r\n          }\r\n          this.gpuTextureData = arg0.texture;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        case 'gpu-buffer': {\r\n          if (\r\n            type !== 'float32' &&\r\n            type !== 'float16' &&\r\n            type !== 'int32' &&\r\n            type !== 'int64' &&\r\n            type !== 'uint32' &&\r\n            type !== 'uint8' &&\r\n            type !== 'bool' &&\r\n            type !== 'uint4' &&\r\n            type !== 'int4'\r\n          ) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\r\n          }\r\n          this.gpuBufferData = arg0.gpuBuffer;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        case 'ml-tensor': {\r\n          if (\r\n            type !== 'float32' &&\r\n            type !== 'float16' &&\r\n            type !== 'int32' &&\r\n            type !== 'int64' &&\r\n            type !== 'uint32' &&\r\n            type !== 'uint64' &&\r\n            type !== 'int8' &&\r\n            type !== 'uint8' &&\r\n            type !== 'bool' &&\r\n            type !== 'uint4' &&\r\n            type !== 'int4'\r\n          ) {\r\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from MLTensor`);\r\n          }\r\n          this.mlTensorData = arg0.mlTensor;\r\n          this.downloader = arg0.download;\r\n          this.disposer = arg0.dispose;\r\n          break;\r\n        }\r\n        default:\r\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\r\n      }\r\n    } else {\r\n      //\r\n      // constructing tensor of location 'cpu'\r\n      //\r\n      let data: TensorDataType;\r\n      let maybeDims: typeof arg1 | typeof arg2;\r\n      // check whether arg0 is type or data\r\n      if (typeof arg0 === 'string') {\r\n        //\r\n        // Override: constructor(type, data, ...)\r\n        //\r\n        type = arg0;\r\n        maybeDims = arg2;\r\n        if (arg0 === 'string') {\r\n          // string tensor\r\n          if (!Array.isArray(arg1)) {\r\n            throw new TypeError(\"A string tensor's data must be a string array.\");\r\n          }\r\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\r\n          // error will be populated at inference\r\n          data = arg1;\r\n        } else {\r\n          // numeric tensor\r\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\r\n          if (typedArrayConstructor === undefined) {\r\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\r\n          }\r\n          if (Array.isArray(arg1)) {\r\n            if ((arg0 === 'float16' && typedArrayConstructor === Uint16Array) || arg0 === 'uint4' || arg0 === 'int4') {\r\n              // - 'float16':\r\n              //   When no Float16Array polyfill is used, we cannot create 'float16' tensor from number array.\r\n              //\r\n              //   Throw error here because when user try to use number array as data,\r\n              //   e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\r\n              //   Uint16Array.from(arg1) which generates wrong data.\r\n              //\r\n              // - 'uint4' and 'int4':\r\n              //   Uint8Array.from(arg1) will generate wrong data for 'uint4' and 'int4' tensor.\r\n              //\r\n              throw new TypeError(\r\n                `Creating a ${arg0} tensor from number array is not supported. Please use ${typedArrayConstructor.name} as data.`,\r\n              );\r\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\r\n              // use 'as any' here because:\r\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\r\n              // see https://github.com/microsoft/TypeScript/issues/17002\r\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\r\n              // does not accept parameter mapFn.\r\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\r\n              // type.\r\n\r\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\r\n\r\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\r\n            } else {\r\n              // assume 'arg1' is of type \"readonly number[]\" here.\r\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n              data = (typedArrayConstructor as any).from(arg1);\r\n            }\r\n          } else if (arg1 instanceof typedArrayConstructor) {\r\n            data = arg1;\r\n          } else if (arg1 instanceof Uint8ClampedArray) {\r\n            if (arg0 === 'uint8') {\r\n              data = Uint8Array.from(arg1);\r\n            } else {\r\n              throw new TypeError(`A Uint8ClampedArray tensor's data must be type of uint8`);\r\n            }\r\n          } else if (arg0 === 'float16' && arg1 instanceof Uint16Array && typedArrayConstructor !== Uint16Array) {\r\n            // when Float16Array is available and data is of type Uint16Array.\r\n            // We allow Uint16Array to be passed in as data for 'float16' tensor until Float16Array is generally\r\n            // supported in JavaScript environment.\r\n\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n            data = new (globalThis as any).Float16Array(arg1.buffer, arg1.byteOffset, arg1.length);\r\n          } else {\r\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\r\n          }\r\n        }\r\n      } else {\r\n        //\r\n        // Override: constructor(data, ...)\r\n        //\r\n        maybeDims = arg1;\r\n        if (Array.isArray(arg0)) {\r\n          // only boolean[] and string[] is supported\r\n          if (arg0.length === 0) {\r\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\r\n          }\r\n          const firstElementType = typeof arg0[0];\r\n          if (firstElementType === 'string') {\r\n            type = 'string';\r\n            data = arg0;\r\n          } else if (firstElementType === 'boolean') {\r\n            type = 'bool';\r\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\r\n            // wrong type. We use 'as any' to make it happy.\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n            data = Uint8Array.from(arg0 as any[]);\r\n          } else {\r\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\r\n          }\r\n        } else if (arg0 instanceof Uint8ClampedArray) {\r\n          type = 'uint8';\r\n          data = Uint8Array.from(arg0);\r\n        } else {\r\n          // get tensor type from TypedArray\r\n          const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(\r\n            arg0.constructor as SupportedTypedArrayConstructors,\r\n          );\r\n          if (mappedType === undefined) {\r\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\r\n          }\r\n          type = mappedType;\r\n          data = arg0 as SupportedTypedArray;\r\n        }\r\n      }\r\n\r\n      // type and data is processed, now processing dims\r\n      if (maybeDims === undefined) {\r\n        // assume 1-D tensor if dims omitted\r\n        maybeDims = [data.length];\r\n      } else if (!Array.isArray(maybeDims)) {\r\n        throw new TypeError(\"A tensor's dims must be a number array\");\r\n      }\r\n      dims = maybeDims as readonly number[];\r\n\r\n      this.cpuData = data;\r\n      this.dataLocation = 'cpu';\r\n    }\r\n\r\n    // perform check on dims\r\n    const size = calculateSize(dims);\r\n    // if data is on CPU, check whether data length matches tensor size\r\n    if (this.cpuData && size !== this.cpuData.length) {\r\n      if ((type === 'uint4' || type === 'int4') && Math.ceil(size / 2) === this.cpuData.length) {\r\n        // for (u)int4, the data length is half of the tensor size. So we check this special case when size is odd.\r\n      } else {\r\n        throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\r\n      }\r\n    }\r\n\r\n    this.type = type;\r\n    this.dims = dims;\r\n    this.size = size;\r\n  }\r\n  // #endregion\r\n\r\n  // #region factory\r\n  static async fromImage(\r\n    image: ImageData | HTMLImageElement | ImageBitmap | string,\r\n    options?:\r\n      | TensorFromImageDataOptions\r\n      | TensorFromImageElementOptions\r\n      | TensorFromImageBitmapOptions\r\n      | TensorFromUrlOptions,\r\n  ): Promise<TensorInterface> {\r\n    return tensorFromImage(image, options);\r\n  }\r\n\r\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\r\n    texture: TensorTextureType,\r\n    options: TensorFromTextureOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromTexture(texture, options);\r\n  }\r\n\r\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\r\n    gpuBuffer: TensorGpuBufferType,\r\n    options: TensorFromGpuBufferOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromGpuBuffer(gpuBuffer, options);\r\n  }\r\n\r\n  static fromMLTensor<T extends TensorInterface.MLTensorDataTypes>(\r\n    mlTensor: TensorMLTensorType,\r\n    options: TensorFromMLTensorOptions<T>,\r\n  ): TensorInterface {\r\n    return tensorFromMLTensor(mlTensor, options);\r\n  }\r\n\r\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\r\n    type: T,\r\n    buffer: TensorInterface.DataTypeMap[T],\r\n    dims?: readonly number[],\r\n  ): Tensor {\r\n    return tensorFromPinnedBuffer(type, buffer, dims);\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region conversions\r\n  toDataURL(options?: TensorToDataUrlOptions): string {\r\n    return tensorToDataURL(this, options);\r\n  }\r\n\r\n  toImageData(options?: TensorToImageDataOptions): ImageData {\r\n    return tensorToImageData(this, options);\r\n  }\r\n  // #endregion\r\n\r\n  // #region public fields\r\n  readonly dims: readonly number[];\r\n  readonly type: TensorType;\r\n  readonly size: number;\r\n  // #endregion\r\n\r\n  // #region private fields\r\n\r\n  /**\r\n   * stores the location of the data.\r\n   */\r\n  private dataLocation: TensorDataLocation;\r\n\r\n  /**\r\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\r\n   */\r\n  private cpuData?: TensorDataType;\r\n\r\n  /**\r\n   * stores the underlying texture when location is 'texture'. otherwise empty.\r\n   */\r\n  private gpuTextureData?: TensorTextureType;\r\n\r\n  /**\r\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\r\n   */\r\n  private gpuBufferData?: TensorGpuBufferType;\r\n\r\n  /**\r\n   * stores the underlying WebNN MLTensor when location is 'ml-tensor'. otherwise empty.\r\n   */\r\n  private mlTensorData?: TensorMLTensorType;\r\n\r\n  /**\r\n   * stores an optional downloader function to download data from GPU to CPU.\r\n   */\r\n  private downloader?(): Promise<TensorDataType>;\r\n\r\n  /**\r\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\r\n   */\r\n  private isDownloading?: boolean;\r\n\r\n  /**\r\n   * stores an optional disposer function to dispose the underlying data.\r\n   */\r\n  private disposer?(): void;\r\n  // #endregion\r\n\r\n  // #region properties\r\n  get data(): TensorDataType {\r\n    this.ensureValid();\r\n    if (!this.cpuData) {\r\n      throw new Error(\r\n        'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\r\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.',\r\n      );\r\n    }\r\n    return this.cpuData;\r\n  }\r\n\r\n  get location(): TensorDataLocation {\r\n    return this.dataLocation;\r\n  }\r\n\r\n  get texture(): TensorTextureType {\r\n    this.ensureValid();\r\n    if (!this.gpuTextureData) {\r\n      throw new Error('The data is not stored as a WebGL texture.');\r\n    }\r\n    return this.gpuTextureData;\r\n  }\r\n\r\n  get gpuBuffer(): TensorGpuBufferType {\r\n    this.ensureValid();\r\n    if (!this.gpuBufferData) {\r\n      throw new Error('The data is not stored as a WebGPU buffer.');\r\n    }\r\n    return this.gpuBufferData;\r\n  }\r\n\r\n  get mlTensor(): TensorMLTensorType {\r\n    this.ensureValid();\r\n    if (!this.mlTensorData) {\r\n      throw new Error('The data is not stored as a WebNN MLTensor.');\r\n    }\r\n    return this.mlTensorData;\r\n  }\r\n  // #endregion\r\n\r\n  // #region methods\r\n\r\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\r\n    this.ensureValid();\r\n    switch (this.dataLocation) {\r\n      case 'cpu':\r\n      case 'cpu-pinned':\r\n        return this.data;\r\n      case 'texture':\r\n      case 'gpu-buffer':\r\n      case 'ml-tensor': {\r\n        if (!this.downloader) {\r\n          throw new Error('The current tensor is not created with a specified data downloader.');\r\n        }\r\n        if (this.isDownloading) {\r\n          throw new Error('The current tensor is being downloaded.');\r\n        }\r\n        try {\r\n          this.isDownloading = true;\r\n          const data = await this.downloader();\r\n          this.downloader = undefined;\r\n          this.dataLocation = 'cpu';\r\n          this.cpuData = data;\r\n\r\n          if (releaseData && this.disposer) {\r\n            this.disposer();\r\n            this.disposer = undefined;\r\n          }\r\n\r\n          return data;\r\n        } finally {\r\n          this.isDownloading = false;\r\n        }\r\n      }\r\n      default:\r\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\r\n    }\r\n  }\r\n\r\n  dispose(): void {\r\n    if (this.isDownloading) {\r\n      throw new Error('The current tensor is being downloaded.');\r\n    }\r\n\r\n    if (this.disposer) {\r\n      this.disposer();\r\n      this.disposer = undefined;\r\n    }\r\n    this.cpuData = undefined;\r\n    this.gpuTextureData = undefined;\r\n    this.gpuBufferData = undefined;\r\n    this.mlTensorData = undefined;\r\n    this.downloader = undefined;\r\n    this.isDownloading = undefined;\r\n\r\n    this.dataLocation = 'none';\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region tensor utilities\r\n  private ensureValid(): void {\r\n    if (this.dataLocation === 'none') {\r\n      throw new Error('The tensor is disposed.');\r\n    }\r\n  }\r\n\r\n  reshape(dims: readonly number[]): TensorInterface {\r\n    this.ensureValid();\r\n    if (this.downloader || this.disposer) {\r\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\r\n    }\r\n    return tensorReshape(this, dims);\r\n  }\r\n  // #endregion\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { TensorFactory } from './tensor-factory.js';\r\nimport { Tensor as TensorImpl } from './tensor-impl.js';\r\nimport { TypedTensorUtils } from './tensor-utils.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\n/**\r\n * represent a basic tensor with specified dimensions and data type.\r\n */\r\ninterface TypedTensorBase<T extends Tensor.Type> {\r\n  /**\r\n   * Get the dimensions of the tensor.\r\n   */\r\n  readonly dims: readonly number[];\r\n  /**\r\n   * Get the data type of the tensor.\r\n   */\r\n  readonly type: T;\r\n  /**\r\n   * Get the buffer data of the tensor.\r\n   *\r\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\r\n   */\r\n  readonly data: Tensor.DataTypeMap[T];\r\n  /**\r\n   * Get the location of the data.\r\n   */\r\n  readonly location: Tensor.DataLocation;\r\n  /**\r\n   * Get the WebGL texture that holds the tensor data.\r\n   *\r\n   * If the data is not on GPU as WebGL texture, throw error.\r\n   */\r\n  readonly texture: Tensor.TextureType;\r\n  /**\r\n   * Get the WebGPU buffer that holds the tensor data.\r\n   *\r\n   * If the data is not on GPU as WebGPU buffer, throw error.\r\n   */\r\n  readonly gpuBuffer: Tensor.GpuBufferType;\r\n\r\n  /**\r\n   * Get the WebNN MLTensor that holds the tensor data.\r\n   *\r\n   * If the data is not in a WebNN MLTensor, throw error.\r\n   */\r\n  readonly mlTensor: Tensor.MLTensorType;\r\n\r\n  /**\r\n   * Get the buffer data of the tensor.\r\n   *\r\n   * If the data is on CPU, returns the data immediately.\r\n   * If the data is on GPU, downloads the data and returns the promise.\r\n   *\r\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\r\n   */\r\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\r\n\r\n  /**\r\n   * Dispose the tensor data.\r\n   *\r\n   * If the data is on CPU, remove its internal reference to the underlying data.\r\n   * If the data is on GPU, release the data on GPU.\r\n   *\r\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\r\n   */\r\n  dispose(): void;\r\n}\r\n\r\nexport declare namespace Tensor {\r\n  interface DataTypeMap {\r\n    float32: Float32Array;\r\n    uint8: Uint8Array;\r\n    int8: Int8Array;\r\n    uint16: Uint16Array;\r\n    int16: Int16Array;\r\n    int32: Int32Array;\r\n    int64: BigInt64Array;\r\n    string: string[];\r\n    bool: Uint8Array;\r\n    float16: Uint16Array; // Keep using Uint16Array until we have a concrete solution for float 16.\r\n    float64: Float64Array;\r\n    uint32: Uint32Array;\r\n    uint64: BigUint64Array;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n    uint4: Uint8Array;\r\n    int4: Int8Array;\r\n  }\r\n\r\n  interface ElementTypeMap {\r\n    float32: number;\r\n    uint8: number;\r\n    int8: number;\r\n    uint16: number;\r\n    int16: number;\r\n    int32: number;\r\n    int64: bigint;\r\n    string: string;\r\n    bool: boolean;\r\n    float16: number; // Keep using Uint16Array until we have a concrete solution for float 16.\r\n    float64: number;\r\n    uint32: number;\r\n    uint64: bigint;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n    uint4: number;\r\n    int4: number;\r\n  }\r\n\r\n  type DataType = DataTypeMap[Type];\r\n  type ElementType = ElementTypeMap[Type];\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a pinned CPU buffer\r\n   */\r\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\r\n\r\n  /**\r\n   * type alias for WebGL texture\r\n   */\r\n  export type TextureType = WebGLTexture;\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebGL texture\r\n   */\r\n  export type TextureDataTypes = 'float32';\r\n\r\n  type GpuBufferTypeFallback = { size: number; mapState: 'unmapped' | 'pending' | 'mapped' };\r\n  /**\r\n   * type alias for WebGPU buffer\r\n   */\r\n  export type GpuBufferType = TryGetGlobalType<'GPUBuffer', GpuBufferTypeFallback>;\r\n\r\n  type MLTensorTypeFallback = { destroy(): void };\r\n  /**\r\n   * type alias for WebNN MLTensor\r\n   *\r\n   * The specification for WebNN's MLTensor is currently in flux.\r\n   */\r\n  export type MLTensorType = TryGetGlobalType<'MLTensor', MLTensorTypeFallback>;\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebGPU buffer\r\n   */\r\n  export type GpuBufferDataTypes = 'float32' | 'float16' | 'int32' | 'int64' | 'uint32' | 'uint8' | 'bool';\r\n\r\n  /**\r\n   * supported data types for constructing a tensor from a WebNN MLTensor\r\n   */\r\n  export type MLTensorDataTypes =\r\n    | 'float32'\r\n    | 'float16'\r\n    | 'int8'\r\n    | 'uint8'\r\n    | 'int32'\r\n    | 'uint32'\r\n    | 'int64'\r\n    | 'uint64'\r\n    | 'bool'\r\n    | 'uint4'\r\n    | 'int4';\r\n\r\n  /**\r\n   * represent where the tensor data is stored\r\n   */\r\n  export type DataLocation = 'none' | 'cpu' | 'cpu-pinned' | 'texture' | 'gpu-buffer' | 'ml-tensor';\r\n\r\n  /**\r\n   * represent the data type of a tensor\r\n   */\r\n  export type Type = keyof DataTypeMap;\r\n}\r\n\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\r\n\r\n/**\r\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\r\n */\r\nexport interface TensorConstructor extends TensorFactory {\r\n  // #region CPU tensor - specify element type\r\n  /**\r\n   * Construct a new string tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: 'string',\r\n    data: Tensor.DataTypeMap['string'] | readonly string[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: 'bool',\r\n    data: Tensor.DataTypeMap['bool'] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from a Uint8ClampedArray, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (type: 'uint8', data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new <T extends 'uint64' | 'int64'>(\r\n    type: T,\r\n    data: Tensor.DataTypeMap[T] | readonly bigint[] | readonly number[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * Construct a new numeric tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new <T extends Exclude<Tensor.Type, 'string' | 'bool' | 'uint64' | 'int64'>>(\r\n    type: T,\r\n    data: Tensor.DataTypeMap[T] | readonly number[],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n  // #endregion\r\n\r\n  // #region CPU tensor - infer element types\r\n\r\n  /**\r\n   * Construct a new float32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\r\n\r\n  /**\r\n   * Construct a new int8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new uint16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\r\n\r\n  /**\r\n   * Construct a new int16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\r\n\r\n  /**\r\n   * Construct a new int32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\r\n\r\n  /**\r\n   * Construct a new int64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\r\n\r\n  /**\r\n   * Construct a new string tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new float64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\r\n\r\n  /**\r\n   * Construct a new uint32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\r\n\r\n  /**\r\n   * Construct a new uint64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\r\n\r\n  // #endregion\r\n\r\n  // #region CPU tensor - fall back to non-generic tensor type declaration\r\n\r\n  /**\r\n   * Construct a new tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (\r\n    type: Tensor.Type,\r\n    data: Tensor.DataType | readonly number[] | readonly string[] | readonly bigint[] | readonly boolean[],\r\n    dims?: readonly number[],\r\n  ): Tensor;\r\n\r\n  /**\r\n   * Construct a new tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the CPU tensor data.\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new (data: Tensor.DataType, dims?: readonly number[]): Tensor;\r\n  // #endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const Tensor = TensorImpl as TensorConstructor;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env } from './env-impl.js';\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE = (deviceType: string, label: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.timeStamp(`${deviceType}::ORT::${label}`);\r\n};\r\n\r\nconst TRACE_FUNC = (msg: string, extraMsg?: string) => {\r\n  const stack = new Error().stack?.split(/\\r\\n|\\r|\\n/g) || [];\r\n  let hasTraceFunc = false;\r\n  for (let i = 0; i < stack.length; i++) {\r\n    if (hasTraceFunc && !stack[i].includes('TRACE_FUNC')) {\r\n      let label = `FUNC_${msg}::${stack[i].trim().split(' ')[1]}`;\r\n      if (extraMsg) {\r\n        label += `::${extraMsg}`;\r\n      }\r\n      TRACE('CPU', label);\r\n      return;\r\n    }\r\n    if (stack[i].includes('TRACE_FUNC')) {\r\n      hasTraceFunc = true;\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_FUNC_BEGIN = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  TRACE_FUNC('BEGIN', extraMsg);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_FUNC_END = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  TRACE_FUNC('END', extraMsg);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_EVENT_BEGIN = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.time(`ORT::${extraMsg}`);\r\n};\r\n\r\n/**\r\n * @ignore\r\n */\r\nexport const TRACE_EVENT_END = (extraMsg?: string) => {\r\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\r\n    return;\r\n  }\r\n  // eslint-disable-next-line no-console\r\n  console.timeEnd(`ORT::${extraMsg}`);\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { resolveBackendAndExecutionProviders } from './backend-impl.js';\r\nimport { InferenceSessionHandler } from './backend.js';\r\nimport { InferenceSession as InferenceSessionInterface } from './inference-session.js';\r\nimport { OnnxValue } from './onnx-value.js';\r\nimport { Tensor } from './tensor.js';\r\nimport { TRACE_FUNC_BEGIN, TRACE_FUNC_END, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from './trace.js';\r\n\r\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\r\ntype RunOptions = InferenceSessionInterface.RunOptions;\r\ntype FeedsType = InferenceSessionInterface.FeedsType;\r\ntype FetchesType = InferenceSessionInterface.FetchesType;\r\ntype ReturnType = InferenceSessionInterface.ReturnType;\r\n\r\nexport class InferenceSession implements InferenceSessionInterface {\r\n  private constructor(handler: InferenceSessionHandler) {\r\n    this.handler = handler;\r\n  }\r\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\r\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\r\n  async run(feeds: FeedsType, arg1?: FetchesType | RunOptions, arg2?: RunOptions): Promise<ReturnType> {\r\n    TRACE_FUNC_BEGIN();\r\n    TRACE_EVENT_BEGIN('InferenceSession.run');\r\n    const fetches: { [name: string]: OnnxValue | null } = {};\r\n    let options: RunOptions = {};\r\n    // check inputs\r\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\r\n      throw new TypeError(\r\n        \"'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.\",\r\n      );\r\n    }\r\n\r\n    let isFetchesEmpty = true;\r\n    // determine which override is being used\r\n    if (typeof arg1 === 'object') {\r\n      if (arg1 === null) {\r\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\r\n      }\r\n      if (arg1 instanceof Tensor) {\r\n        throw new TypeError(\"'fetches' cannot be a Tensor\");\r\n      }\r\n\r\n      if (Array.isArray(arg1)) {\r\n        if (arg1.length === 0) {\r\n          throw new TypeError(\"'fetches' cannot be an empty array.\");\r\n        }\r\n        isFetchesEmpty = false;\r\n        // output names\r\n        for (const name of arg1) {\r\n          if (typeof name !== 'string') {\r\n            throw new TypeError(\"'fetches' must be a string array or an object.\");\r\n          }\r\n          if (this.outputNames.indexOf(name) === -1) {\r\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\r\n          }\r\n          fetches[name] = null;\r\n        }\r\n\r\n        if (typeof arg2 === 'object' && arg2 !== null) {\r\n          options = arg2;\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError(\"'options' must be an object.\");\r\n        }\r\n      } else {\r\n        // decide whether arg1 is fetches or options\r\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\r\n        let isFetches = false;\r\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\r\n        for (const name of this.outputNames) {\r\n          if (arg1Keys.indexOf(name) !== -1) {\r\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\r\n            if (v === null || v instanceof Tensor) {\r\n              isFetches = true;\r\n              isFetchesEmpty = false;\r\n              fetches[name] = v;\r\n            }\r\n          }\r\n        }\r\n\r\n        if (isFetches) {\r\n          if (typeof arg2 === 'object' && arg2 !== null) {\r\n            options = arg2;\r\n          } else if (typeof arg2 !== 'undefined') {\r\n            throw new TypeError(\"'options' must be an object.\");\r\n          }\r\n        } else {\r\n          options = arg1 as RunOptions;\r\n        }\r\n      }\r\n    } else if (typeof arg1 !== 'undefined') {\r\n      throw new TypeError(\"Unexpected argument[1]: must be 'fetches' or 'options'.\");\r\n    }\r\n\r\n    // check if all inputs are in feed\r\n    for (const name of this.inputNames) {\r\n      if (typeof feeds[name] === 'undefined') {\r\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\r\n      }\r\n    }\r\n\r\n    // if no fetches is specified, we use the full output names list\r\n    if (isFetchesEmpty) {\r\n      for (const name of this.outputNames) {\r\n        fetches[name] = null;\r\n      }\r\n    }\r\n\r\n    // feeds, fetches and options are prepared\r\n\r\n    const results = await this.handler.run(feeds, fetches, options);\r\n    const returnValue: { [name: string]: OnnxValue } = {};\r\n    for (const key in results) {\r\n      if (Object.hasOwnProperty.call(results, key)) {\r\n        const result = results[key];\r\n        if (result instanceof Tensor) {\r\n          returnValue[key] = result;\r\n        } else {\r\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\r\n        }\r\n      }\r\n    }\r\n    TRACE_EVENT_END('InferenceSession.run');\r\n    TRACE_FUNC_END();\r\n    return returnValue;\r\n  }\r\n\r\n  async release(): Promise<void> {\r\n    return this.handler.dispose();\r\n  }\r\n\r\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(\r\n    buffer: ArrayBufferLike,\r\n    byteOffset: number,\r\n    byteLength?: number,\r\n    options?: SessionOptions,\r\n  ): Promise<InferenceSessionInterface>;\r\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static async create(\r\n    arg0: string | ArrayBufferLike | Uint8Array,\r\n    arg1?: SessionOptions | number,\r\n    arg2?: number,\r\n    arg3?: SessionOptions,\r\n  ): Promise<InferenceSessionInterface> {\r\n    TRACE_FUNC_BEGIN();\r\n    TRACE_EVENT_BEGIN('InferenceSession.create');\r\n    // either load from a file or buffer\r\n    let filePathOrUint8Array: string | Uint8Array;\r\n    let options: SessionOptions = {};\r\n\r\n    if (typeof arg0 === 'string') {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n    } else if (arg0 instanceof Uint8Array) {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n    } else if (\r\n      arg0 instanceof ArrayBuffer ||\r\n      (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)\r\n    ) {\r\n      const buffer = arg0;\r\n      let byteOffset = 0;\r\n      let byteLength = arg0.byteLength;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 === 'number') {\r\n        byteOffset = arg1;\r\n        if (!Number.isSafeInteger(byteOffset)) {\r\n          throw new RangeError(\"'byteOffset' must be an integer.\");\r\n        }\r\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\r\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\r\n        }\r\n        byteLength = arg0.byteLength - byteOffset;\r\n        if (typeof arg2 === 'number') {\r\n          byteLength = arg2;\r\n          if (!Number.isSafeInteger(byteLength)) {\r\n            throw new RangeError(\"'byteLength' must be an integer.\");\r\n          }\r\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\r\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\r\n          }\r\n          if (typeof arg3 === 'object' && arg3 !== null) {\r\n            options = arg3;\r\n          } else if (typeof arg3 !== 'undefined') {\r\n            throw new TypeError(\"'options' must be an object.\");\r\n          }\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError(\"'byteLength' must be a number.\");\r\n        }\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError(\"'options' must be an object.\");\r\n      }\r\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\r\n    } else {\r\n      throw new TypeError(\"Unexpected argument[0]: must be 'path' or 'buffer'.\");\r\n    }\r\n\r\n    // resolve backend, update session options with validated EPs, and create session handler\r\n    const [backend, optionsWithValidatedEPs] = await resolveBackendAndExecutionProviders(options);\r\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, optionsWithValidatedEPs);\r\n    TRACE_EVENT_END('InferenceSession.create');\r\n    TRACE_FUNC_END();\r\n    return new InferenceSession(handler);\r\n  }\r\n\r\n  startProfiling(): void {\r\n    this.handler.startProfiling();\r\n  }\r\n  endProfiling(): void {\r\n    this.handler.endProfiling();\r\n  }\r\n\r\n  get inputNames(): readonly string[] {\r\n    return this.handler.inputNames;\r\n  }\r\n  get outputNames(): readonly string[] {\r\n    return this.handler.outputNames;\r\n  }\r\n\r\n  get inputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\r\n    return this.handler.inputMetadata;\r\n  }\r\n\r\n  get outputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\r\n    return this.handler.outputMetadata;\r\n  }\r\n\r\n  private handler: InferenceSessionHandler;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession as InferenceSessionImpl } from './inference-session-impl.js';\r\nimport { OnnxModelOptions } from './onnx-model.js';\r\nimport { OnnxValue, OnnxValueDataLocation } from './onnx-value.js';\r\nimport type { Tensor } from './tensor.js';\r\nimport { TryGetGlobalType } from './type-helper.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\nexport declare namespace InferenceSession {\r\n  // #region input/output types\r\n\r\n  type OnnxValueMapType = { readonly [name: string]: OnnxValue };\r\n  type NullableOnnxValueMapType = { readonly [name: string]: OnnxValue | null };\r\n\r\n  /**\r\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type FeedsType = OnnxValueMapType;\r\n\r\n  /**\r\n   * A fetches (model outputs) could be one of the following:\r\n   *\r\n   * - Omitted. Use model's output names definition.\r\n   * - An array of string indicating the output names.\r\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\r\n   *\r\n   * @remark\r\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\r\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\r\n   * internally.\r\n   */\r\n  type FetchesType = readonly string[] | NullableOnnxValueMapType;\r\n\r\n  /**\r\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type ReturnType = OnnxValueMapType;\r\n\r\n  // #endregion\r\n\r\n  // #region session options\r\n\r\n  /**\r\n   * A set of configurations for session behavior.\r\n   */\r\n  export interface SessionOptions extends OnnxModelOptions {\r\n    /**\r\n     * An array of execution provider options.\r\n     *\r\n     * An execution provider option can be a string indicating the name of the execution provider,\r\n     * or an object of corresponding type.\r\n     */\r\n    executionProviders?: readonly ExecutionProviderConfig[];\r\n\r\n    /**\r\n     * The intra OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    intraOpNumThreads?: number;\r\n\r\n    /**\r\n     * The inter OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    interOpNumThreads?: number;\r\n\r\n    /**\r\n     * The free dimension override.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    freeDimensionOverrides?: { readonly [dimensionName: string]: number };\r\n\r\n    /**\r\n     * The optimization level.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    graphOptimizationLevel?: 'disabled' | 'basic' | 'extended' | 'layout' | 'all';\r\n\r\n    /**\r\n     * Whether enable CPU memory arena.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableCpuMemArena?: boolean;\r\n\r\n    /**\r\n     * Whether enable memory pattern.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableMemPattern?: boolean;\r\n\r\n    /**\r\n     * Execution mode.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    executionMode?: 'sequential' | 'parallel';\r\n\r\n    /**\r\n     * Optimized model file path.\r\n     *\r\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\r\n     * with a pop-up window.\r\n     */\r\n    optimizedModelFilePath?: string;\r\n\r\n    /**\r\n     * Whether enable profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    enableProfiling?: boolean;\r\n\r\n    /**\r\n     * File prefix for profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    profileFilePrefix?: string;\r\n\r\n    /**\r\n     * Log ID.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logId?: string;\r\n\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\r\n     * preferred data location as corresponding values.\r\n     *\r\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\r\n     */\r\n    preferredOutputLocation?: OnnxValueDataLocation | { readonly [outputName: string]: OnnxValueDataLocation };\r\n\r\n    /**\r\n     * Whether enable graph capture.\r\n     * This setting is available only in ONNXRuntime Web for WebGPU EP.\r\n     */\r\n    enableGraphCapture?: boolean;\r\n\r\n    /**\r\n     * Store configurations for a session. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\r\n     * onnxruntime_session_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     * ```js\r\n     * extra: {\r\n     *   session: {\r\n     *     set_denormal_as_zero: \"1\",\r\n     *     disable_prepacking: \"1\"\r\n     *   },\r\n     *   optimization: {\r\n     *     enable_gelu_approximation: \"1\"\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  // #region execution providers\r\n\r\n  // Currently, we have the following backends to support execution providers:\r\n  // Backend Node.js binding: supports 'cpu', 'dml' (win32), 'coreml' (macOS) and 'cuda' (linux).\r\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'webgpu' and 'webnn'.\r\n  // Backend ONNX.js: supports 'webgl'.\r\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\r\n  interface ExecutionProviderOptionMap {\r\n    coreml: CoreMLExecutionProviderOption;\r\n    cpu: CpuExecutionProviderOption;\r\n    cuda: CudaExecutionProviderOption;\r\n    dml: DmlExecutionProviderOption;\r\n    nnapi: NnapiExecutionProviderOption;\r\n    tensorrt: TensorRtExecutionProviderOption;\r\n    wasm: WebAssemblyExecutionProviderOption;\r\n    webgl: WebGLExecutionProviderOption;\r\n    webgpu: WebGpuExecutionProviderOption;\r\n    webnn: WebNNExecutionProviderOption;\r\n    qnn: QnnExecutionProviderOption;\r\n    xnnpack: XnnpackExecutionProviderOption;\r\n  }\r\n\r\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\r\n  type ExecutionProviderConfig =\r\n    | ExecutionProviderOptionMap[ExecutionProviderName]\r\n    | ExecutionProviderOption\r\n    | ExecutionProviderName\r\n    | string;\r\n\r\n  export interface ExecutionProviderOption {\r\n    readonly name: string;\r\n  }\r\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cpu';\r\n    useArena?: boolean;\r\n  }\r\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cuda';\r\n    deviceId?: number;\r\n  }\r\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'dml';\r\n    deviceId?: number;\r\n  }\r\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'tensorrt';\r\n    deviceId?: number;\r\n  }\r\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'wasm';\r\n  }\r\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'webgl';\r\n    // TODO: add flags\r\n  }\r\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'xnnpack';\r\n  }\r\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'webgpu';\r\n    preferredLayout?: 'NCHW' | 'NHWC';\r\n  }\r\n\r\n  // #region WebNN options\r\n\r\n  interface WebNNExecutionProviderName extends ExecutionProviderOption {\r\n    readonly name: 'webnn';\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for creating a WebNN MLContext.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dictdef-mlcontextoptions\r\n   */\r\n  export interface WebNNContextOptions {\r\n    deviceType?: 'cpu' | 'gpu' | 'npu';\r\n    numThreads?: number;\r\n    powerPreference?: 'default' | 'low-power' | 'high-performance';\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider without MLContext.\r\n   */\r\n  export interface WebNNOptionsWithoutMLContext extends WebNNExecutionProviderName, WebNNContextOptions {\r\n    context?: never;\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider with MLContext.\r\n   *\r\n   * When MLContext is provided, the deviceType is also required so that the WebNN EP can determine the preferred\r\n   * channel layout.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext\r\n   */\r\n  export interface WebNNOptionsWithMLContext\r\n    extends WebNNExecutionProviderName,\r\n      Omit<WebNNContextOptions, 'deviceType'>,\r\n      Required<Pick<WebNNContextOptions, 'deviceType'>> {\r\n    context: TryGetGlobalType<'MLContext'>;\r\n  }\r\n\r\n  /**\r\n   * Represents a set of options for WebNN execution provider with MLContext which is created from GPUDevice.\r\n   *\r\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext-gpudevice\r\n   */\r\n  export interface WebNNOptionsWebGpu extends WebNNExecutionProviderName {\r\n    context: TryGetGlobalType<'MLContext'>;\r\n    gpuDevice: TryGetGlobalType<'GPUDevice'>;\r\n  }\r\n\r\n  /**\r\n   * Options for WebNN execution provider.\r\n   */\r\n  export type WebNNExecutionProviderOption =\r\n    | WebNNOptionsWithoutMLContext\r\n    | WebNNOptionsWithMLContext\r\n    | WebNNOptionsWebGpu;\r\n\r\n  // #endregion\r\n\r\n  export interface QnnExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'qnn';\r\n    /**\r\n     * Specify the QNN backend type. E.g., 'cpu' or 'htp'.\r\n     * Mutually exclusive with `backendPath`.\r\n     *\r\n     * @default 'htp'\r\n     */\r\n    backendType?: string;\r\n    /**\r\n     * Specify a path to the QNN backend library.\r\n     * Mutually exclusive with `backendType`.\r\n     */\r\n    backendPath?: string;\r\n    /**\r\n     * Specify whether to enable HTP FP16 precision.\r\n     *\r\n     * @default true\r\n     */\r\n    enableFp16Precision?: boolean;\r\n  }\r\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'coreml';\r\n    /**\r\n     * The bit flags for CoreML execution provider.\r\n     *\r\n     * ```\r\n     * COREML_FLAG_USE_CPU_ONLY = 0x001\r\n     * COREML_FLAG_ENABLE_ON_SUBGRAPH = 0x002\r\n     * COREML_FLAG_ONLY_ENABLE_DEVICE_WITH_ANE = 0x004\r\n     * COREML_FLAG_ONLY_ALLOW_STATIC_INPUT_SHAPES = 0x008\r\n     * COREML_FLAG_CREATE_MLPROGRAM = 0x010\r\n     * COREML_FLAG_USE_CPU_AND_GPU = 0x020\r\n     * ```\r\n     *\r\n     * See include/onnxruntime/core/providers/coreml/coreml_provider_factory.h for more details.\r\n     *\r\n     * This flag is available only in ONNXRuntime (Node.js binding).\r\n     */\r\n    coreMlFlags?: number;\r\n    /**\r\n     * Specify whether to use CPU only in CoreML EP.\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    useCPUOnly?: boolean;\r\n    useCPUAndGPU?: boolean;\r\n    /**\r\n     * Specify whether to enable CoreML EP on subgraph.\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    enableOnSubgraph?: boolean;\r\n    /**\r\n     * Specify whether to only enable CoreML EP for Apple devices with ANE (Apple Neural Engine).\r\n     *\r\n     * This setting is available only in ONNXRuntime (react-native).\r\n     */\r\n    onlyEnableDeviceWithANE?: boolean;\r\n  }\r\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'nnapi';\r\n    useFP16?: boolean;\r\n    useNCHW?: boolean;\r\n    cpuDisabled?: boolean;\r\n    cpuOnly?: boolean;\r\n  }\r\n  // #endregion\r\n\r\n  // #endregion\r\n\r\n  // #region run options\r\n\r\n  /**\r\n   * A set of configurations for inference run behavior\r\n   */\r\n  export interface RunOptions {\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Terminate all incomplete OrtRun calls as soon as possible if true\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    terminate?: boolean;\r\n\r\n    /**\r\n     * A tag for the Run() calls using this\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    tag?: string;\r\n\r\n    /**\r\n     * Set a single run configuration entry. See\r\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\r\n     * onnxruntime_run_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     *\r\n     * ```js\r\n     * extra: {\r\n     *   memory: {\r\n     *     enable_memory_arena_shrinkage: \"1\",\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  // #endregion\r\n\r\n  // #region value metadata\r\n\r\n  /**\r\n   * The common part of the value metadata type for both tensor and non-tensor values.\r\n   */\r\n  export interface ValueMetadataBase {\r\n    /**\r\n     * The name of the specified input or output.\r\n     */\r\n    readonly name: string;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a non-tensor value.\r\n   */\r\n  export interface NonTensorValueMetadata extends ValueMetadataBase {\r\n    /**\r\n     * Get a value indicating whether the value is a tensor.\r\n     */\r\n    readonly isTensor: false;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a tensor value.\r\n   */\r\n  export interface TensorValueMetadata extends ValueMetadataBase {\r\n    /**\r\n     * Get a value indicating whether the value is a tensor.\r\n     */\r\n    readonly isTensor: true;\r\n    /**\r\n     * Get the data type of the tensor.\r\n     */\r\n    readonly type: Tensor.Type;\r\n    /**\r\n     * Get the shape of the tensor.\r\n     *\r\n     * If the shape is not defined, the value will an empty array. Otherwise, it will be an array representing the shape\r\n     * of the tensor. Each element in the array can be a number or a string. If the element is a number, it represents\r\n     * the corresponding dimension size. If the element is a string, it represents a symbolic dimension.\r\n     */\r\n    readonly shape: ReadonlyArray<number | string>;\r\n  }\r\n\r\n  /**\r\n   * Represents the metadata of a value.\r\n   */\r\n  export type ValueMetadata = NonTensorValueMetadata | TensorValueMetadata;\r\n\r\n  // #endregion\r\n}\r\n\r\n/**\r\n * Represent a runtime instance of an ONNX model.\r\n */\r\nexport interface InferenceSession {\r\n  // #region run()\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds, fetches and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\r\n   * detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(\r\n    feeds: InferenceSession.FeedsType,\r\n    fetches: InferenceSession.FetchesType,\r\n    options?: InferenceSession.RunOptions,\r\n  ): Promise<InferenceSession.ReturnType>;\r\n\r\n  // #endregion\r\n\r\n  // #region release()\r\n\r\n  /**\r\n   * Release the inference session and the underlying resources.\r\n   */\r\n  release(): Promise<void>;\r\n\r\n  // #endregion\r\n\r\n  // #region profiling\r\n\r\n  /**\r\n   * Start profiling.\r\n   */\r\n  startProfiling(): void;\r\n\r\n  /**\r\n   * End profiling.\r\n   */\r\n  endProfiling(): void;\r\n\r\n  // #endregion\r\n\r\n  // #region metadata\r\n\r\n  /**\r\n   * Get input names of the loaded model.\r\n   */\r\n  readonly inputNames: readonly string[];\r\n\r\n  /**\r\n   * Get output names of the loaded model.\r\n   */\r\n  readonly outputNames: readonly string[];\r\n\r\n  /**\r\n   * Get input metadata of the loaded model.\r\n   */\r\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  /**\r\n   * Get output metadata of the loaded model.\r\n   */\r\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  // #endregion\r\n}\r\n\r\nexport interface InferenceSessionFactory {\r\n  // #region create()\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an ONNX model file.\r\n   *\r\n   * @param uri - The URI or file path of the model to load.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\r\n   * @param byteLength - The length in bytes of the array buffer.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(\r\n    buffer: ArrayBufferLike,\r\n    byteOffset: number,\r\n    byteLength?: number,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from a Uint8Array.\r\n   *\r\n   * @param buffer - A Uint8Array representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  // #endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { OptionsFormat, OptionsNormalizationParameters, OptionsTensorLayout } from './tensor-factory.js';\r\n\r\nexport interface TensorToDataUrlOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\r\n\r\nexport interface TensorToImageDataOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\r\n\r\nexport interface ConversionUtils {\r\n  /**\r\n   * creates a DataURL instance from tensor\r\n   *\r\n   * @param options - An optional object representing options for creating a DataURL instance from the tensor.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `format`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * @returns a DataURL string representing the image converted from tensor data\r\n   */\r\n  toDataURL(options?: TensorToDataUrlOptions): string;\r\n\r\n  /**\r\n   * creates an ImageData instance from tensor\r\n   *\r\n   * @param options - An optional object representing options for creating an ImageData instance from the tensor.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `format`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * @returns an ImageData instance representing the image converted from tensor data\r\n   */\r\n  toImageData(options?: TensorToImageDataOptions): ImageData;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor, TypedTensor } from './tensor.js';\r\n\r\nexport type ImageFormat = 'RGB' | 'RGBA' | 'BGR' | 'RBG';\r\nexport type ImageTensorLayout = 'NHWC' | 'NCHW';\r\n\r\n// the following region contains type definitions for constructing tensor from a specific location.\r\n\r\n// #region types for constructing a tensor from a specific location\r\n\r\n/**\r\n * represent common properties of the parameter for constructing a tensor from a specific location.\r\n */\r\ninterface CommonConstructorParameters<T> extends Pick<Tensor, 'dims'> {\r\n  /**\r\n   * Specify the data type of the tensor.\r\n   */\r\n  readonly type: T;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a GPU resource.\r\n */\r\ninterface GpuResourceConstructorParameters<T extends Tensor.Type> {\r\n  /**\r\n   * an optional callback function to download data from GPU to CPU.\r\n   *\r\n   * If not provided, the tensor treat the GPU data as external resource.\r\n   */\r\n  download?(): Promise<Tensor.DataTypeMap[T]>;\r\n\r\n  /**\r\n   * an optional callback function that will be called when the tensor is disposed.\r\n   *\r\n   * If not provided, the tensor treat the GPU data as external resource.\r\n   */\r\n  dispose?(): void;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a pinned CPU buffer\r\n */\r\nexport interface CpuPinnedConstructorParameters<T extends Tensor.CpuPinnedDataTypes = Tensor.CpuPinnedDataTypes>\r\n  extends CommonConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'cpu-pinned'.\r\n   */\r\n  readonly location: 'cpu-pinned';\r\n  /**\r\n   * Specify the CPU pinned buffer that holds the tensor data.\r\n   */\r\n  readonly data: Tensor.DataTypeMap[T];\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a WebGL texture\r\n */\r\nexport interface TextureConstructorParameters<T extends Tensor.TextureDataTypes = Tensor.TextureDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'texture'.\r\n   */\r\n  readonly location: 'texture';\r\n  /**\r\n   * Specify the WebGL texture that holds the tensor data.\r\n   */\r\n  readonly texture: Tensor.TextureType;\r\n}\r\n\r\n/**\r\n * represent the parameter for constructing a tensor from a WebGPU buffer\r\n */\r\nexport interface GpuBufferConstructorParameters<T extends Tensor.GpuBufferDataTypes = Tensor.GpuBufferDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'gpu-buffer'.\r\n   */\r\n  readonly location: 'gpu-buffer';\r\n  /**\r\n   * Specify the WebGPU buffer that holds the tensor data.\r\n   */\r\n  readonly gpuBuffer: Tensor.GpuBufferType;\r\n}\r\n\r\nexport interface MLTensorConstructorParameters<T extends Tensor.MLTensorDataTypes = Tensor.MLTensorDataTypes>\r\n  extends CommonConstructorParameters<T>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Specify the location of the data to be 'ml-tensor'.\r\n   */\r\n  readonly location: 'ml-tensor';\r\n\r\n  /**\r\n   * Specify the WebNN MLTensor that holds the tensor data.\r\n   */\r\n  readonly mlTensor: Tensor.MLTensorType;\r\n}\r\n\r\n// #endregion\r\n\r\n// the following region contains type definitions of each individual options.\r\n// the tensor factory functions use a composition of those options as the parameter type.\r\n\r\n// #region Options fields\r\n\r\nexport interface OptionsFormat {\r\n  /**\r\n   * Describes the image format represented in RGBA color space.\r\n   */\r\n  format?: ImageFormat;\r\n}\r\n\r\nexport interface OptionsTensorFormat {\r\n  /**\r\n   * Describes the image format of the tensor.\r\n   *\r\n   * NOTE: this is different from option 'format'. While option 'format' represents the original image, 'tensorFormat'\r\n   * represents the target format of the tensor. A transpose will be performed if they are different.\r\n   */\r\n  tensorFormat?: ImageFormat;\r\n}\r\n\r\nexport interface OptionsTensorDataType {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: 'float32' | 'uint8';\r\n}\r\n\r\nexport interface OptionsTensorLayout {\r\n  /**\r\n   * Describes the tensor layout when representing data of one or more image(s).\r\n   */\r\n  tensorLayout?: ImageTensorLayout;\r\n}\r\n\r\nexport interface OptionsDimensions {\r\n  /**\r\n   * Describes the image height in pixel\r\n   */\r\n  height?: number;\r\n  /**\r\n   * Describes the image width in pixel\r\n   */\r\n  width?: number;\r\n}\r\n\r\nexport interface OptionResizedDimensions {\r\n  /**\r\n   * Describes the resized height. If omitted, original height will be used.\r\n   */\r\n  resizedHeight?: number;\r\n  /**\r\n   * Describes resized width - can be accessed via tensor dimensions as well\r\n   */\r\n  resizedWidth?: number;\r\n}\r\n\r\nexport interface OptionsNormalizationParameters {\r\n  /**\r\n   * Describes normalization parameters when preprocessing the image as model input.\r\n   *\r\n   * Data element are ranged from 0 to 255.\r\n   */\r\n  norm?: {\r\n    /**\r\n     * The 'bias' value for image normalization.\r\n     * - If omitted, use default value 0.\r\n     * - If it's a single number, apply to each channel\r\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\r\n     * for the corresponding image format\r\n     */\r\n    bias?: number | [number, number, number] | [number, number, number, number];\r\n    /**\r\n     * The 'mean' value for image normalization.\r\n     * - If omitted, use default value 255.\r\n     * - If it's a single number, apply to each channel\r\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\r\n     * for the corresponding image format\r\n     */\r\n    mean?: number | [number, number, number] | [number, number, number, number];\r\n  };\r\n}\r\n\r\n// #endregion\r\n\r\n// #region Options composition\r\n\r\nexport interface TensorFromImageDataOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromImageElementOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromUrlOptions\r\n  extends OptionsDimensions,\r\n    OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromImageBitmapOptions\r\n  extends OptionResizedDimensions,\r\n    OptionsTensorFormat,\r\n    OptionsTensorLayout,\r\n    OptionsTensorDataType,\r\n    OptionsNormalizationParameters {}\r\n\r\nexport interface TensorFromTextureOptions<T extends Tensor.TextureDataTypes>\r\n  extends Required<OptionsDimensions>,\r\n    OptionsFormat,\r\n    GpuResourceConstructorParameters<T> /* TODO: add more */ {}\r\n\r\nexport interface TensorFromGpuBufferOptions<T extends Tensor.GpuBufferDataTypes>\r\n  extends Pick<Tensor, 'dims'>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: T;\r\n}\r\n\r\nexport interface TensorFromMLTensorOptions<T extends Tensor.MLTensorDataTypes>\r\n  extends Pick<Tensor, 'dims'>,\r\n    GpuResourceConstructorParameters<T> {\r\n  /**\r\n   * Describes the data type of the tensor.\r\n   */\r\n  dataType?: T;\r\n}\r\n\r\n// #endregion\r\n\r\n/**\r\n * type TensorFactory defines the factory functions of 'Tensor' to create tensor instances from existing data or\r\n * resources.\r\n */\r\nexport interface TensorFactory {\r\n  /**\r\n   * create a tensor from an ImageData object\r\n   *\r\n   * @param imageData - the ImageData object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from ImageData.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    imageData: ImageData,\r\n    options?: TensorFromImageDataOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from a HTMLImageElement object\r\n   *\r\n   * @param imageElement - the HTMLImageElement object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from HTMLImageElement.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    imageElement: HTMLImageElement,\r\n    options?: TensorFromImageElementOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from URL\r\n   *\r\n   * @param urlSource - a string as a URL to the image or a data URL containing the image data.\r\n   * @param options - An optional object representing options for creating tensor from URL.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(urlSource: string, options?: TensorFromUrlOptions): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from an ImageBitmap object\r\n   *\r\n   * @param bitmap - the ImageBitmap object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from URL.\r\n   *\r\n   * The following default settings will be applied:\r\n   * - `tensorFormat`: `'RGB'`\r\n   * - `tensorLayout`: `'NCHW'`\r\n   * - `dataType`: `'float32'`\r\n   * @returns A promise that resolves to a tensor object\r\n   */\r\n  fromImage(\r\n    bitmap: ImageBitmap,\r\n    options: TensorFromImageBitmapOptions,\r\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n\r\n  /**\r\n   * create a tensor from a WebGL texture\r\n   *\r\n   * @param texture - the WebGLTexture object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from WebGL texture.\r\n   *\r\n   * The options include following properties:\r\n   * - `width`: the width of the texture. Required.\r\n   * - `height`: the height of the texture. Required.\r\n   * - `format`: the format of the texture. If omitted, assume 'RGBA'.\r\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\r\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\r\n   * need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\r\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromTexture<T extends Tensor.TextureDataTypes = 'float32'>(\r\n    texture: Tensor.TextureType,\r\n    options: TensorFromTextureOptions<T>,\r\n  ): TypedTensor<'float32'>;\r\n\r\n  /**\r\n   * create a tensor from a WebGPU buffer\r\n   *\r\n   * @param buffer - the GPUBuffer object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from WebGPU buffer.\r\n   *\r\n   * The options include following properties:\r\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\r\n   * - `dims`: the dimension of the tensor. Required.\r\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\r\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\r\n   * need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\r\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromGpuBuffer<T extends Tensor.GpuBufferDataTypes>(\r\n    buffer: Tensor.GpuBufferType,\r\n    options: TensorFromGpuBufferOptions<T>,\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * create a tensor from a WebNN MLTensor\r\n   *\r\n   * @param tensor - the MLTensor object to create tensor from\r\n   * @param options - An optional object representing options for creating tensor from a WebNN MLTensor.\r\n   *\r\n   * The options include following properties:\r\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\r\n   * - `dims`: the dimension of the tensor. Required.\r\n   * - `download`: an optional function to download the tensor data from the MLTensor to CPU. If omitted, the MLTensor\r\n   * data will not be able to download. Usually, this is provided by the WebNN backend for the inference outputs.\r\n   * Users don't need to provide this function.\r\n   * - `dispose`: an optional function to dispose the tensor data on the WebNN MLTensor. If omitted, the MLTensor will\r\n   * not be disposed. Usually, this is provided by the WebNN backend for the inference outputs. Users don't need to\r\n   * provide this function.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromMLTensor<T extends Tensor.MLTensorDataTypes>(\r\n    tensor: Tensor.MLTensorType,\r\n    options: TensorFromMLTensorOptions<T>,\r\n  ): TypedTensor<T>;\r\n\r\n  /**\r\n   * create a tensor from a pre-allocated buffer. The buffer will be used as a pinned buffer.\r\n   *\r\n   * @param type - the tensor element type.\r\n   * @param buffer - a TypedArray corresponding to the type.\r\n   * @param dims - specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   *\r\n   * @returns a tensor object\r\n   */\r\n  fromPinnedBuffer<T extends Exclude<Tensor.Type, 'string'>>(\r\n    type: T,\r\n    buffer: Tensor.DataTypeMap[T],\r\n    dims?: readonly number[],\r\n  ): TypedTensor<T>;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/**\r\n * A string that represents a file's URL or path.\r\n *\r\n * Path is vailable only in onnxruntime-node or onnxruntime-web running in Node.js.\r\n */\r\nexport type FileUrlOrPath = string;\r\n\r\n/**\r\n * A Blob object that represents a file.\r\n */\r\nexport type FileBlob = Blob;\r\n\r\n/**\r\n * A Uint8Array, ArrayBuffer or SharedArrayBuffer object that represents a file content.\r\n *\r\n * When it is an ArrayBuffer or SharedArrayBuffer, the whole buffer is assumed to be the file content.\r\n */\r\nexport type FileData = Uint8Array | ArrayBufferLike;\r\n\r\n/**\r\n * Represents a file that can be loaded by the ONNX Runtime JavaScript API.\r\n */\r\nexport type FileType = FileUrlOrPath | FileBlob | FileData;\r\n\r\n/**\r\n * Represents an external data file.\r\n */\r\nexport interface ExternalDataFileDescription {\r\n  /**\r\n   * Specify the external data file.\r\n   */\r\n  data: FileType;\r\n  /**\r\n   * Specify the file path.\r\n   */\r\n  path: string;\r\n}\r\n\r\n/**\r\n * Represents an external data file.\r\n *\r\n * When using a string, it should be a file URL or path that in the same directory as the model file.\r\n */\r\nexport type ExternalDataFileType = ExternalDataFileDescription | FileUrlOrPath;\r\n\r\n/**\r\n * Options for model loading.\r\n */\r\nexport interface OnnxModelOptions {\r\n  /**\r\n   * Specifying a list of files that represents the external data.\r\n   */\r\n  externalData?: readonly ExternalDataFileType[];\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from './tensor.js';\r\n\r\nexport type NonTensorType = never;\r\n\r\n/**\r\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\r\n *\r\n * NOTE: currently not support non-tensor\r\n */\r\nexport type OnnxValue = Tensor | NonTensorType;\r\n\r\n/**\r\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\r\n */\r\nexport type OnnxValueDataLocation = Tensor.DataLocation;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/**\r\n * # ONNX Runtime JavaScript API\r\n *\r\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\r\n *\r\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\r\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\r\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\r\n *\r\n * See also:\r\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript/)\r\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\r\n *\r\n * @packageDocumentation\r\n */\r\n\r\nexport * from './backend.js';\r\nexport * from './env.js';\r\nexport * from './inference-session.js';\r\nexport * from './tensor.js';\r\nexport * from './tensor-conversion.js';\r\nexport * from './tensor-factory.js';\r\nexport * from './trace.js';\r\nexport * from './onnx-model.js';\r\nexport * from './onnx-value.js';\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nexport const isNode = !!(typeof process !== 'undefined' && process.versions && process.versions.node);\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/// <reference lib=\"webworker\" />\r\n\r\n//\r\n// * type hack for \"HTMLImageElement\"\r\n//\r\n// in typescript, the type of \"HTMLImageElement\" is defined in lib.dom.d.ts, which is conflict with lib.webworker.d.ts.\r\n// when we use webworker, the lib.webworker.d.ts will be used, which does not have HTMLImageElement defined.\r\n//\r\n// we will get the following errors complaining that HTMLImageElement is not defined:\r\n//\r\n// ====================================================================================================================\r\n//\r\n// ../common/dist/cjs/tensor-factory.d.ts:187:29 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 187     fromImage(imageElement: HTMLImageElement, options?: TensorFromImageElementOptions):\r\n// Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\r\n//                                 ~~~~~~~~~~~~~~~~\r\n//\r\n// node_modules/@webgpu/types/dist/index.d.ts:83:7 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 83     | HTMLImageElement\r\n//          ~~~~~~~~~~~~~~~~\r\n//\r\n// ====================================================================================================================\r\n//\r\n// `HTMLImageElement` is only used in type declaration and not in real code. So we define it as `unknown` here to\r\n// bypass the type check.\r\n\r\n//\r\n// * type hack for \"document\"\r\n//\r\n// in typescript, the type of \"document\" is defined in lib.dom.d.ts, so it's not available in webworker.\r\n//\r\n// we will get the following errors complaining that document is not defined:\r\n//\r\n// ====================================================================================================================\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:33 - error TS2584: Cannot find name 'document'. Do you need to change your target\r\n// library? Try changing the 'lib' compiler option to include 'dom'.\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                   ~~~~~~~~\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:61 - error TS2584: Cannot find name 'document'. Do you need to change your target\r\n// library? Try changing the 'lib' compiler option to include 'dom'.\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                                               ~~~~~~~~\r\n//\r\n// lib/wasm/wasm-utils-import.ts:7:88 - error TS2552: Cannot find name 'HTMLScriptElement'. Did you mean\r\n// 'HTMLLIElement'?\r\n//\r\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\r\n//                                                                                          ~~~~~~~~~~~~~~~~~\r\n// ====================================================================================================================\r\n//\r\n// `document` is used to get the current script URL, which is not available in webworker. This file is served as a\r\n// \"dual\" file for entries of both webworker and the esm module.\r\n//\r\ndeclare global {\r\n  type HTMLImageElement = unknown;\r\n  type HTMLScriptElement = { src?: string };\r\n  const document: undefined | { currentScript?: HTMLScriptElement };\r\n}\r\n\r\n/**\r\n * @summary\r\n *\r\n * This file is served as a \"dual\" file for both entries of the following:\r\n * - The proxy worker itself.\r\n *   - When used as a worker, it listens to the messages from the main thread and performs the corresponding operations.\r\n *   - Should be imported directly using `new Worker()` in the main thread.\r\n *\r\n * - The ESM module that creates the proxy worker (as a worker launcher).\r\n *   - When used as a worker launcher, it creates the proxy worker and returns it.\r\n *   - Should be imported using `import()` in the main thread, with the query parameter `import=1`.\r\n *\r\n * This file will be always compiling into ESM format.\r\n */\r\n\r\nimport type { OrtWasmMessage, SerializableTensorMetadata } from '../proxy-messages.js';\r\nimport {\r\n  createSession,\r\n  copyFromExternalBuffer,\r\n  endProfiling,\r\n  extractTransferableBuffers,\r\n  initEp,\r\n  initRuntime,\r\n  releaseSession,\r\n  run,\r\n} from '../wasm-core-impl.js';\r\nimport { initializeWebAssembly } from '../wasm-factory.js';\r\nimport { scriptSrc } from '../wasm-utils-import.js';\r\n\r\nconst WORKER_NAME = 'ort-wasm-proxy-worker';\r\nconst isProxyWorker = globalThis.self?.name === WORKER_NAME;\r\n\r\nif (isProxyWorker) {\r\n  // Worker thread\r\n  self.onmessage = (ev: MessageEvent<OrtWasmMessage>): void => {\r\n    const { type, in: message } = ev.data;\r\n    try {\r\n      switch (type) {\r\n        case 'init-wasm':\r\n          initializeWebAssembly(message!.wasm).then(\r\n            () => {\r\n              initRuntime(message!).then(\r\n                () => {\r\n                  postMessage({ type });\r\n                },\r\n                (err) => {\r\n                  postMessage({ type, err });\r\n                },\r\n              );\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        case 'init-ep': {\r\n          const { epName, env } = message!;\r\n          initEp(env, epName).then(\r\n            () => {\r\n              postMessage({ type });\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'copy-from': {\r\n          const { buffer } = message!;\r\n          const bufferData = copyFromExternalBuffer(buffer);\r\n          postMessage({ type, out: bufferData } as OrtWasmMessage);\r\n          break;\r\n        }\r\n        case 'create': {\r\n          const { model, options } = message!;\r\n          createSession(model, options).then(\r\n            (sessionMetadata) => {\r\n              postMessage({ type, out: sessionMetadata } as OrtWasmMessage);\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'release':\r\n          releaseSession(message!);\r\n          postMessage({ type });\r\n          break;\r\n        case 'run': {\r\n          const { sessionId, inputIndices, inputs, outputIndices, options } = message!;\r\n          run(sessionId, inputIndices, inputs, outputIndices, new Array(outputIndices.length).fill(null), options).then(\r\n            (outputs) => {\r\n              if (outputs.some((o) => o[3] !== 'cpu')) {\r\n                postMessage({ type, err: 'Proxy does not support non-cpu tensor location.' });\r\n              } else {\r\n                postMessage(\r\n                  { type, out: outputs } as OrtWasmMessage,\r\n                  extractTransferableBuffers([...inputs, ...outputs] as SerializableTensorMetadata[]),\r\n                );\r\n              }\r\n            },\r\n            (err) => {\r\n              postMessage({ type, err });\r\n            },\r\n          );\r\n          break;\r\n        }\r\n        case 'end-profiling':\r\n          endProfiling(message!);\r\n          postMessage({ type });\r\n          break;\r\n        default:\r\n      }\r\n    } catch (err) {\r\n      postMessage({ type, err } as OrtWasmMessage);\r\n    }\r\n  };\r\n}\r\n\r\nexport default isProxyWorker\r\n  ? null\r\n  : (urlOverride?: string) =>\r\n      new Worker(urlOverride ?? scriptSrc!, { type: BUILD_DEFS.IS_ESM ? 'module' : 'classic', name: WORKER_NAME });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport type { OrtWasmModule } from './wasm-types';\r\nimport { isNode } from './wasm-utils-env';\r\n\r\n/**\r\n * The origin of the current location.\r\n *\r\n * In Node.js, this is undefined.\r\n */\r\nconst origin = isNode || typeof location === 'undefined' ? undefined : location.origin;\r\n\r\n/**\r\n * Some bundlers (eg. Webpack) will rewrite `import.meta.url` to a file URL at compile time.\r\n *\r\n * This function checks if `import.meta.url` starts with `file:`, but using the `>` and `<` operators instead of\r\n * `startsWith` function so that code minimizers can remove the dead code correctly.\r\n *\r\n * For example, if we use terser to minify the following code:\r\n * ```js\r\n * if (\"file://hard-coded-filename\".startsWith(\"file:\")) {\r\n *   console.log(1)\r\n * } else {\r\n *   console.log(2)\r\n * }\r\n *\r\n * if (\"file://hard-coded-filename\" > \"file:\" && \"file://hard-coded-filename\" < \"file;\") {\r\n *   console.log(3)\r\n * } else {\r\n *   console.log(4)\r\n * }\r\n * ```\r\n *\r\n * The minified code will be:\r\n * ```js\r\n * \"file://hard-coded-filename\".startsWith(\"file:\")?console.log(1):console.log(2),console.log(3);\r\n * ```\r\n *\r\n * (use Terser 5.39.0 with default options, https://try.terser.org/)\r\n *\r\n * @returns true if the import.meta.url is hardcoded as a file URI.\r\n */\r\nexport const isEsmImportMetaUrlHardcodedAsFileUri =\r\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ESM_IMPORT_META_URL! > 'file:' && BUILD_DEFS.ESM_IMPORT_META_URL! < 'file;';\r\n\r\nconst getScriptSrc = (): string | undefined => {\r\n  // if Nodejs, return undefined\r\n  if (isNode) {\r\n    return undefined;\r\n  }\r\n  // if It's ESM, use import.meta.url\r\n  if (BUILD_DEFS.IS_ESM) {\r\n    // For ESM, if the import.meta.url is a file URL, this usually means the bundler rewrites `import.meta.url` to\r\n    // the file path at compile time. In this case, this file path cannot be used to determine the runtime URL.\r\n    //\r\n    // We need to use the URL constructor like this:\r\n    // ```js\r\n    // new URL('actual-bundle-name.js', import.meta.url).href\r\n    // ```\r\n    // So that bundler can preprocess the URL correctly.\r\n    if (isEsmImportMetaUrlHardcodedAsFileUri) {\r\n      // if the rewritten URL is a relative path, we need to use the origin to resolve the URL.\r\n\r\n      // The following is a workaround for Vite.\r\n      //\r\n      // Vite uses a bundler(rollup/rolldown) that does not rewrite `import.meta.url` to a file URL. So in theory, this\r\n      // code path should not be executed in Vite. However, the bundler does not know it and it still try to load the\r\n      // following pattern:\r\n      // - `return new URL('filename', import.meta.url).href`\r\n      //\r\n      // By replacing the pattern above with the following code, we can skip the resource loading behavior:\r\n      // - `const URL2 = URL; return new URL2('filename', import.meta.url).href;`\r\n      //\r\n      // And it still works in Webpack.\r\n      const URL2 = URL;\r\n      return new URL(new URL2(BUILD_DEFS.BUNDLE_FILENAME, BUILD_DEFS.ESM_IMPORT_META_URL).href, origin).href;\r\n    }\r\n\r\n    return BUILD_DEFS.ESM_IMPORT_META_URL;\r\n  }\r\n\r\n  return typeof document !== 'undefined'\r\n    ? (document.currentScript as HTMLScriptElement)?.src\r\n    : // use `self.location.href` if available\r\n      typeof self !== 'undefined'\r\n      ? self.location?.href\r\n      : undefined;\r\n};\r\n\r\n/**\r\n * The classic script source URL. This is not always available in non ESModule environments.\r\n *\r\n * In Node.js, this is undefined.\r\n */\r\nexport const scriptSrc = getScriptSrc();\r\n\r\n/**\r\n * Infer the wasm path prefix from the script source URL.\r\n *\r\n * @returns The inferred wasm path prefix, or undefined if the script source URL is not available or is a blob URL.\r\n */\r\nexport const inferWasmPathPrefixFromScriptSrc = (): string | undefined => {\r\n  if (scriptSrc && !scriptSrc.startsWith('blob:')) {\r\n    return scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);\r\n  }\r\n  return undefined;\r\n};\r\n\r\n/**\r\n * Check if the given filename with prefix is from the same origin.\r\n */\r\nconst isSameOrigin = (filename: string, prefixOverride?: string) => {\r\n  try {\r\n    const baseUrl = prefixOverride ?? scriptSrc;\r\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\r\n    return url.origin === origin;\r\n  } catch {\r\n    return false;\r\n  }\r\n};\r\n\r\n/**\r\n * Normalize the inputs to an absolute URL with the given prefix override. If failed, return undefined.\r\n */\r\nconst normalizeUrl = (filename: string, prefixOverride?: string) => {\r\n  const baseUrl = prefixOverride ?? scriptSrc;\r\n  try {\r\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\r\n    return url.href;\r\n  } catch {\r\n    return undefined;\r\n  }\r\n};\r\n\r\n/**\r\n * Create a fallback URL if an absolute URL cannot be created by the normalizeUrl function.\r\n */\r\nconst fallbackUrl = (filename: string, prefixOverride?: string) => `${prefixOverride ?? './'}${filename}`;\r\n\r\n/**\r\n * This helper function is used to preload a module from a URL.\r\n *\r\n * If the origin of the worker URL is different from the current origin, the worker cannot be loaded directly.\r\n * See discussions in https://github.com/webpack-contrib/worker-loader/issues/154\r\n *\r\n * In this case, we will fetch the worker URL and create a new Blob URL with the same origin as a workaround.\r\n *\r\n * @param absoluteUrl - The absolute URL to preload.\r\n *\r\n * @returns - A promise that resolves to a new Blob URL\r\n */\r\nconst preload = async (absoluteUrl: string): Promise<string> => {\r\n  const response = await fetch(absoluteUrl, { credentials: 'same-origin' });\r\n  const blob = await response.blob();\r\n  return URL.createObjectURL(blob);\r\n};\r\n\r\n/**\r\n * This helper function is used to dynamically import a module from a URL.\r\n *\r\n * The build script has special handling for this function to ensure that the URL is not bundled into the final output.\r\n *\r\n * @param url - The URL to import.\r\n *\r\n * @returns - A promise that resolves to the default export of the module.\r\n */\r\nconst dynamicImportDefault = async <T>(url: string): Promise<T> =>\r\n  (await import(/* webpackIgnore: true */ url)).default;\r\n\r\n/**\r\n * The proxy worker factory imported from the proxy worker module.\r\n *\r\n * This is only available when the WebAssembly proxy is not disabled.\r\n */\r\nconst createProxyWorker: ((urlOverride?: string) => Worker) | undefined =\r\n  // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n  BUILD_DEFS.DISABLE_WASM_PROXY ? undefined : require('./proxy-worker/main').default;\r\n\r\n/**\r\n * Import the proxy worker.\r\n *\r\n * This function will perform the following steps:\r\n * 1. If a preload is needed, it will preload the module and return the object URL.\r\n * 2. Use the proxy worker factory to create the proxy worker.\r\n *\r\n * @returns - A promise that resolves to a tuple of 2 elements:\r\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\r\n *            - The proxy worker.\r\n */\r\nexport const importProxyWorker = async (): Promise<[undefined | string, Worker]> => {\r\n  if (!scriptSrc) {\r\n    throw new Error('Failed to load proxy worker: cannot determine the script source URL.');\r\n  }\r\n\r\n  // If the script source is from the same origin, we can use the embedded proxy module directly.\r\n  if (isSameOrigin(scriptSrc)) {\r\n    return [undefined, createProxyWorker!()];\r\n  }\r\n\r\n  // Otherwise, need to preload\r\n  const url = await preload(scriptSrc);\r\n  return [url, createProxyWorker!(url)];\r\n};\r\n\r\n/**\r\n * The embedded WebAssembly module.\r\n *\r\n * This is only available in ESM and when embedding is not disabled.\r\n */\r\nconst embeddedWasmModule: EmscriptenModuleFactory<OrtWasmModule> | undefined =\r\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ENABLE_BUNDLE_WASM_JS\r\n    ? // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n      require(\r\n        !BUILD_DEFS.DISABLE_JSEP\r\n          ? '../../dist/ort-wasm-simd-threaded.jsep.mjs'\r\n          : !BUILD_DEFS.DISABLE_WEBGPU\r\n            ? '../../dist/ort-wasm-simd-threaded.asyncify.mjs'\r\n            : '../../dist/ort-wasm-simd-threaded.mjs',\r\n      ).default\r\n    : undefined;\r\n\r\n/**\r\n * Import the WebAssembly module.\r\n *\r\n * This function will perform the following steps:\r\n * 1. If the embedded module exists and no custom URL is specified, use the embedded module.\r\n * 2. If a preload is needed, it will preload the module and return the object URL.\r\n * 3. Otherwise, it will perform a dynamic import of the module.\r\n *\r\n * @returns - A promise that resolves to a tuple of 2 elements:\r\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\r\n *            - The default export of the module, which is a factory function to create the WebAssembly module.\r\n */\r\nexport const importWasmModule = async (\r\n  urlOverride: string | undefined,\r\n  prefixOverride: string | undefined,\r\n  isMultiThreaded: boolean,\r\n  isWasmOverridden: boolean,\r\n): Promise<[undefined | string, EmscriptenModuleFactory<OrtWasmModule>]> => {\r\n  //\r\n  // Check if we should use the embedded module.\r\n  //\r\n\r\n  // To use the embedded module, it should be available, and no URL override or prefix override should be specified.\r\n  let useEmbeddedModule = embeddedWasmModule && !(urlOverride || prefixOverride);\r\n  if (useEmbeddedModule) {\r\n    if (!scriptSrc) {\r\n      // no URL info available.\r\n      //\r\n      // Note: when the embedded module is available, it means the current script is ESM. Usually, in ESM, the\r\n      // `import.meta.url` is available. But in some cases (eg. Cloudflare Workers), the value of `import.meta.url`\r\n      // can be `null` or `undefined`. In this case, we can only load the embedded module when:\r\n      //\r\n      // 1. The WebAssembly module binary is overridden:\r\n      //    ```js\r\n      //    env.wasm.wasmPaths = undefined;  // or not specified\r\n      //    env.wasm.wasmBinary = /* a Uint8Array containing the WebAssembly binary */;\r\n      //    ```\r\n      //\r\n      // 2. The \".wasm\" only is overridden.\r\n      //    ```js\r\n      //    env.wasm.wasmPaths = { wasm: /* URL of the .wasm file */ };\r\n      //    ```\r\n      //\r\n      if (isWasmOverridden && !isMultiThreaded) {\r\n        useEmbeddedModule = true;\r\n      } else {\r\n        throw new Error('cannot determine the script source URL.');\r\n      }\r\n    } else {\r\n      // if the script source is available, we can check if it is from the same origin.\r\n      useEmbeddedModule = isSameOrigin(scriptSrc);\r\n    }\r\n  }\r\n  if (useEmbeddedModule) {\r\n    return [undefined, embeddedWasmModule!];\r\n  } else {\r\n    const wasmModuleFilename = !BUILD_DEFS.DISABLE_JSEP\r\n      ? 'ort-wasm-simd-threaded.jsep.mjs'\r\n      : !BUILD_DEFS.DISABLE_WEBGPU\r\n        ? 'ort-wasm-simd-threaded.asyncify.mjs'\r\n        : 'ort-wasm-simd-threaded.mjs';\r\n    const wasmModuleUrl = urlOverride ?? normalizeUrl(wasmModuleFilename, prefixOverride);\r\n    // need to preload if all of the following conditions are met:\r\n    // 1. not in Node.js.\r\n    //    - Node.js does not have the same origin policy for creating workers.\r\n    // 2. multi-threaded is enabled.\r\n    //    - If multi-threaded is disabled, no worker will be created. So we don't need to preload the module.\r\n    // 3. the absolute URL is available.\r\n    //    - If the absolute URL is failed to be created, the origin cannot be determined. In this case, we will not\r\n    //    preload the module.\r\n    // 4. the worker URL is not from the same origin.\r\n    //    - If the worker URL is from the same origin, we can create the worker directly.\r\n    const needPreload = !isNode && isMultiThreaded && wasmModuleUrl && !isSameOrigin(wasmModuleUrl, prefixOverride);\r\n    const url = needPreload\r\n      ? await preload(wasmModuleUrl)\r\n      : (wasmModuleUrl ?? fallbackUrl(wasmModuleFilename, prefixOverride));\r\n    return [needPreload ? url : undefined, await dynamicImportDefault<EmscriptenModuleFactory<OrtWasmModule>>(url)];\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Env } from 'onnxruntime-common';\r\n\r\nimport type { OrtWasmModule } from './wasm-types';\r\nimport { importWasmModule, inferWasmPathPrefixFromScriptSrc } from './wasm-utils-import';\r\n\r\nlet wasm: OrtWasmModule | undefined;\r\nlet initialized = false;\r\nlet initializing = false;\r\nlet aborted = false;\r\n\r\nconst isMultiThreadSupported = (): boolean => {\r\n  // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\r\n  if (typeof SharedArrayBuffer === 'undefined') {\r\n    return false;\r\n  }\r\n\r\n  try {\r\n    // Test for transferability of SABs (for browsers. needed for Firefox)\r\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\r\n    if (typeof MessageChannel !== 'undefined') {\r\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\r\n    }\r\n\r\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing threaded instructions.\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16,\r\n        2, 0, 26, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nconst isSimdSupported = (): boolean => {\r\n  try {\r\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing SIMD instructions.\r\n\r\n    // The binary data is generated from the following code by wat2wasm:\r\n    //\r\n    // (module\r\n    //   (type $t0 (func))\r\n    //   (func $f0 (type $t0)\r\n    //     (drop\r\n    //       (i32x4.dot_i16x8_s\r\n    //         (i8x16.splat\r\n    //           (i32.const 0))\r\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\r\n\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0,\r\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nconst isRelaxedSimdSupported = (): boolean => {\r\n  try {\r\n    // Test for WebAssembly Relaxed SIMD capability (for both browsers and Node.js)\r\n    // This typed array is a WebAssembly program containing Relaxed SIMD instructions.\r\n\r\n    // The binary data is generated from the following code by wat2wasm:\r\n    // (module\r\n    //   (func (result v128)\r\n    //      i32.const 1\r\n    //      i8x16.splat\r\n    //      i32.const 2\r\n    //      i8x16.splat\r\n    //      i32.const 3\r\n    //      i8x16.splat\r\n    //      i32x4.relaxed_dot_i8x16_i7x16_add_s\r\n    //   )\r\n    //  )\r\n    return WebAssembly.validate(\r\n      new Uint8Array([\r\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 19, 1, 17, 0, 65, 1, 253, 15, 65, 2, 253,\r\n        15, 65, 3, 253, 15, 253, 147, 2, 11,\r\n      ]),\r\n    );\r\n  } catch (e) {\r\n    return false;\r\n  }\r\n};\r\n\r\nexport const initializeWebAssembly = async (flags: Env.WebAssemblyFlags): Promise<void> => {\r\n  if (initialized) {\r\n    return Promise.resolve();\r\n  }\r\n  if (initializing) {\r\n    throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");\r\n  }\r\n  if (aborted) {\r\n    throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");\r\n  }\r\n\r\n  initializing = true;\r\n\r\n  // wasm flags are already initialized\r\n  const timeout = flags.initTimeout!;\r\n  let numThreads = flags.numThreads!;\r\n\r\n  // ensure SIMD is supported\r\n  if (flags.simd === false) {\r\n    // skip SIMD feature checking as it is disabled explicitly by user\r\n  } else if (flags.simd === 'relaxed') {\r\n    // check if relaxed SIMD is supported\r\n    if (!isRelaxedSimdSupported()) {\r\n      throw new Error('Relaxed WebAssembly SIMD is not supported in the current environment.');\r\n    }\r\n  } else if (!isSimdSupported()) {\r\n    throw new Error('WebAssembly SIMD is not supported in the current environment.');\r\n  }\r\n\r\n  // check if multi-threading is supported\r\n  const multiThreadSupported = isMultiThreadSupported();\r\n  if (numThreads > 1 && !multiThreadSupported) {\r\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\r\n      // eslint-disable-next-line no-console\r\n      console.warn(\r\n        'env.wasm.numThreads is set to ' +\r\n          numThreads +\r\n          ', but this will not work unless you enable crossOriginIsolated mode. ' +\r\n          'See https://web.dev/cross-origin-isolation-guide/ for more info.',\r\n      );\r\n    }\r\n\r\n    // eslint-disable-next-line no-console\r\n    console.warn(\r\n      'WebAssembly multi-threading is not supported in the current environment. ' + 'Falling back to single-threading.',\r\n    );\r\n\r\n    // set flags.numThreads to 1 so that OrtInit() will not create a global thread pool.\r\n    flags.numThreads = numThreads = 1;\r\n  }\r\n\r\n  const wasmPaths = flags.wasmPaths;\r\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\r\n  const mjsPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.mjs;\r\n  const mjsPathOverride = (mjsPathOverrideFlag as URL)?.href ?? mjsPathOverrideFlag;\r\n  const wasmPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.wasm;\r\n  const wasmPathOverride = (wasmPathOverrideFlag as URL)?.href ?? wasmPathOverrideFlag;\r\n  const wasmBinaryOverride = flags.wasmBinary;\r\n\r\n  const [objectUrl, ortWasmFactory] = await importWasmModule(\r\n    mjsPathOverride,\r\n    wasmPrefixOverride,\r\n    numThreads > 1,\r\n    !!wasmBinaryOverride || !!wasmPathOverride,\r\n  );\r\n\r\n  let isTimeout = false;\r\n\r\n  const tasks: Array<Promise<void>> = [];\r\n\r\n  // promise for timeout\r\n  if (timeout > 0) {\r\n    tasks.push(\r\n      new Promise((resolve) => {\r\n        setTimeout(() => {\r\n          isTimeout = true;\r\n          resolve();\r\n        }, timeout);\r\n      }),\r\n    );\r\n  }\r\n\r\n  // promise for module initialization\r\n  tasks.push(\r\n    new Promise((resolve, reject) => {\r\n      const config: Partial<OrtWasmModule> = {\r\n        /**\r\n         * The number of threads. WebAssembly will create (Module.numThreads - 1) workers. If it is 1, no worker will be\r\n         * created.\r\n         */\r\n        numThreads,\r\n      };\r\n\r\n      if (wasmBinaryOverride) {\r\n        // Set a custom buffer which contains the WebAssembly binary. This will skip the wasm file fetching.\r\n        config.wasmBinary = wasmBinaryOverride;\r\n      } else if (wasmPathOverride || wasmPrefixOverride) {\r\n        // A callback function to locate the WebAssembly file. The function should return the full path of the file.\r\n        //\r\n        // Since Emscripten 3.1.58, this function is only called for the .wasm file.\r\n        config.locateFile = (fileName) => wasmPathOverride ?? wasmPrefixOverride + fileName;\r\n      } else if (mjsPathOverride && mjsPathOverride.indexOf('blob:') !== 0) {\r\n        // if mjs path is specified, use it as the base path for the .wasm file.\r\n        config.locateFile = (fileName) => new URL(fileName, mjsPathOverride).href;\r\n      } else if (objectUrl) {\r\n        const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\r\n        if (inferredWasmPathPrefix) {\r\n          // if the wasm module is preloaded, use the inferred wasm path as the base path for the .wasm file.\r\n          config.locateFile = (fileName) => inferredWasmPathPrefix + fileName;\r\n        }\r\n      }\r\n\r\n      ortWasmFactory(config).then(\r\n        // wasm module initialized successfully\r\n        (module) => {\r\n          initializing = false;\r\n          initialized = true;\r\n          wasm = module;\r\n          resolve();\r\n          if (objectUrl) {\r\n            URL.revokeObjectURL(objectUrl);\r\n          }\r\n        },\r\n        // wasm module failed to initialize\r\n        (what) => {\r\n          initializing = false;\r\n          aborted = true;\r\n          reject(what);\r\n        },\r\n      );\r\n    }),\r\n  );\r\n\r\n  await Promise.race(tasks);\r\n\r\n  if (isTimeout) {\r\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\r\n  }\r\n};\r\n\r\nexport const getInstance = (): OrtWasmModule => {\r\n  if (initialized && wasm) {\r\n    return wasm;\r\n  }\r\n\r\n  throw new Error('WebAssembly is not initialized yet.');\r\n};\r\n\r\nexport const dispose = (): void => {\r\n  if (initialized && !initializing && !aborted) {\r\n    // TODO: currently \"PThread.terminateAllThreads()\" is not exposed in the wasm module.\r\n    //       And this function is not yet called by any code.\r\n    //       If it is needed in the future, we should expose it in the wasm module and uncomment the following line.\r\n\r\n    // wasm?.PThread?.terminateAllThreads();\r\n    wasm = undefined;\r\n\r\n    initializing = false;\r\n    initialized = false;\r\n    aborted = true;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { getInstance } from './wasm-factory';\r\n\r\nexport const allocWasmString = (data: string, allocs: number[]): number => {\r\n  const wasm = getInstance();\r\n\r\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\r\n  const dataOffset = wasm._malloc(dataLength);\r\n  wasm.stringToUTF8(data, dataOffset, dataLength);\r\n  allocs.push(dataOffset);\r\n\r\n  return dataOffset;\r\n};\r\n\r\ninterface ExtraOptionsHandler {\r\n  (name: string, value: string): void;\r\n}\r\n\r\nexport const iterateExtraOptions = (\r\n  options: Record<string, unknown>,\r\n  prefix: string,\r\n  seen: WeakSet<Record<string, unknown>>,\r\n  handler: ExtraOptionsHandler,\r\n): void => {\r\n  if (typeof options == 'object' && options !== null) {\r\n    if (seen.has(options)) {\r\n      throw new Error('Circular reference in options');\r\n    } else {\r\n      seen.add(options);\r\n    }\r\n  }\r\n\r\n  Object.entries(options).forEach(([key, value]) => {\r\n    const name = prefix ? prefix + key : key;\r\n    if (typeof value === 'object') {\r\n      iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\r\n    } else if (typeof value === 'string' || typeof value === 'number') {\r\n      handler(name, value.toString());\r\n    } else if (typeof value === 'boolean') {\r\n      handler(name, value ? '1' : '0');\r\n    } else {\r\n      throw new Error(`Can't handle extra config type: ${typeof value}`);\r\n    }\r\n  });\r\n};\r\n\r\n/**\r\n * check web assembly API's last error and throw error if any error occurred.\r\n * @param message a message used when an error occurred.\r\n */\r\nexport const checkLastError = (message: string): void => {\r\n  const wasm = getInstance();\r\n\r\n  const stack = wasm.stackSave();\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const paramsOffset = wasm.stackAlloc(2 * ptrSize);\r\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + ptrSize);\r\n    const errorCode = Number(wasm.getValue(paramsOffset, ptrSize === 4 ? 'i32' : 'i64'));\r\n    const errorMessagePointer = wasm.getValue(paramsOffset + ptrSize, '*');\r\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\r\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { InferenceSession } from 'onnxruntime-common';\r\n\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\r\n\r\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\r\n  const wasm = getInstance();\r\n  let runOptionsHandle = 0;\r\n  const allocs: number[] = [];\r\n\r\n  const runOptions: InferenceSession.RunOptions = options || {};\r\n\r\n  try {\r\n    if (options?.logSeverityLevel === undefined) {\r\n      runOptions.logSeverityLevel = 2; // Default to warning\r\n    } else if (\r\n      typeof options.logSeverityLevel !== 'number' ||\r\n      !Number.isInteger(options.logSeverityLevel) ||\r\n      options.logSeverityLevel < 0 ||\r\n      options.logSeverityLevel > 4\r\n    ) {\r\n      throw new Error(`log severity level is not valid: ${options.logSeverityLevel}`);\r\n    }\r\n\r\n    if (options?.logVerbosityLevel === undefined) {\r\n      runOptions.logVerbosityLevel = 0; // Default to 0\r\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\r\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\r\n    }\r\n\r\n    if (options?.terminate === undefined) {\r\n      runOptions.terminate = false;\r\n    }\r\n\r\n    let tagDataOffset = 0;\r\n    if (options?.tag !== undefined) {\r\n      tagDataOffset = allocWasmString(options.tag, allocs);\r\n    }\r\n\r\n    runOptionsHandle = wasm._OrtCreateRunOptions(\r\n      runOptions.logSeverityLevel!,\r\n      runOptions.logVerbosityLevel!,\r\n      !!runOptions.terminate!,\r\n      tagDataOffset,\r\n    );\r\n    if (runOptionsHandle === 0) {\r\n      checkLastError(\"Can't create run options.\");\r\n    }\r\n\r\n    if (options?.extra !== undefined) {\r\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\r\n        const keyDataOffset = allocWasmString(key, allocs);\r\n        const valueDataOffset = allocWasmString(value, allocs);\r\n\r\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\r\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\r\n        }\r\n      });\r\n    }\r\n\r\n    return [runOptionsHandle, allocs];\r\n  } catch (e) {\r\n    if (runOptionsHandle !== 0) {\r\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n    throw e;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport type { InferenceSession } from 'onnxruntime-common';\r\n\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\r\n\r\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string | unknown): number => {\r\n  switch (graphOptimizationLevel) {\r\n    case 'disabled':\r\n      return 0;\r\n    case 'basic':\r\n      return 1;\r\n    case 'extended':\r\n      return 2;\r\n    case 'layout':\r\n      return 3;\r\n    case 'all':\r\n      return 99;\r\n    default:\r\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\r\n  }\r\n};\r\n\r\nconst getExecutionMode = (executionMode: 'sequential' | 'parallel'): number => {\r\n  switch (executionMode) {\r\n    case 'sequential':\r\n      return 0;\r\n    case 'parallel':\r\n      return 1;\r\n    default:\r\n      throw new Error(`unsupported execution mode: ${executionMode}`);\r\n  }\r\n};\r\n\r\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\r\n  if (!options.extra) {\r\n    options.extra = {};\r\n  }\r\n  if (!options.extra.session) {\r\n    options.extra.session = {};\r\n  }\r\n  const session = options.extra.session as Record<string, string>;\r\n  if (!session.use_ort_model_bytes_directly) {\r\n    // eslint-disable-next-line camelcase\r\n    session.use_ort_model_bytes_directly = '1';\r\n  }\r\n\r\n  // if using JSEP with WebGPU, always disable memory pattern\r\n  if (\r\n    options.executionProviders &&\r\n    options.executionProviders.some((ep) => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')\r\n  ) {\r\n    options.enableMemPattern = false;\r\n  }\r\n};\r\n\r\nconst appendSessionConfig = (sessionOptionsHandle: number, key: string, value: string, allocs: number[]): void => {\r\n  const keyDataOffset = allocWasmString(key, allocs);\r\n  const valueDataOffset = allocWasmString(value, allocs);\r\n  if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\r\n    checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\r\n  }\r\n};\r\n\r\nconst appendEpOption = (epOptions: Array<[number, number]>, key: string, value: string, allocs: number[]): void => {\r\n  const keyDataOffset = allocWasmString(key, allocs);\r\n  const valueDataOffset = allocWasmString(value, allocs);\r\n  epOptions.push([keyDataOffset, valueDataOffset]);\r\n};\r\n\r\nconst setExecutionProviders = async (\r\n  sessionOptionsHandle: number,\r\n  executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\r\n  allocs: number[],\r\n): Promise<void> => {\r\n  for (const ep of executionProviders) {\r\n    let epName = typeof ep === 'string' ? ep : ep.name;\r\n    const epOptions: Array<[number, number]> = [];\r\n\r\n    // check EP name\r\n    switch (epName) {\r\n      case 'webnn':\r\n        epName = 'WEBNN';\r\n        if (typeof ep !== 'string') {\r\n          const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\r\n          // const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\r\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\r\n          if (deviceType) {\r\n            appendSessionConfig(sessionOptionsHandle, 'deviceType', deviceType, allocs);\r\n          }\r\n        }\r\n        break;\r\n      case 'webgpu':\r\n        if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n          epName = 'WebGPU';\r\n          let customDevice: GPUDevice | undefined;\r\n\r\n          if (typeof ep !== 'string') {\r\n            const customOptions = ep as unknown as { device: GPUDevice };\r\n            if (customOptions.device) {\r\n              if (typeof GPUDevice !== 'undefined' && customOptions.device instanceof GPUDevice) {\r\n                customDevice = customOptions.device;\r\n              } else {\r\n                throw new Error('Invalid GPU device set in WebGPU EP options.');\r\n              }\r\n            }\r\n\r\n            // TODO: handle more options\r\n          }\r\n\r\n          const info = getInstance().webgpuRegisterDevice!(customDevice);\r\n          if (info) {\r\n            const [deviceId, instanceHandle, deviceHandle] = info;\r\n            appendEpOption(epOptions, 'deviceId', deviceId.toString(), allocs);\r\n            appendEpOption(epOptions, 'webgpuInstance', instanceHandle.toString(), allocs);\r\n            appendEpOption(epOptions, 'webgpuDevice', deviceHandle.toString(), allocs);\r\n          }\r\n        } else {\r\n          epName = 'JS';\r\n          if (typeof ep !== 'string') {\r\n            const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\r\n            if (webgpuOptions?.preferredLayout) {\r\n              if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\r\n                throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\r\n              }\r\n              appendSessionConfig(sessionOptionsHandle, 'preferredLayout', webgpuOptions.preferredLayout, allocs);\r\n            }\r\n          }\r\n        }\r\n        break;\r\n      case 'wasm':\r\n      case 'cpu':\r\n        continue;\r\n      default:\r\n        throw new Error(`not supported execution provider: ${epName}`);\r\n    }\r\n\r\n    const epNameDataOffset = allocWasmString(epName, allocs);\r\n    const epOptionsCount = epOptions.length;\r\n    let keysOffset = 0;\r\n    let valuesOffset = 0;\r\n    if (epOptionsCount > 0) {\r\n      keysOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\r\n      allocs.push(keysOffset);\r\n      valuesOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\r\n      allocs.push(valuesOffset);\r\n      for (let i = 0; i < epOptionsCount; i++) {\r\n        getInstance().setValue(keysOffset + i * getInstance().PTR_SIZE, epOptions[i][0], '*');\r\n        getInstance().setValue(valuesOffset + i * getInstance().PTR_SIZE, epOptions[i][1], '*');\r\n      }\r\n    }\r\n    if (\r\n      (await getInstance()._OrtAppendExecutionProvider(\r\n        sessionOptionsHandle,\r\n        epNameDataOffset,\r\n        keysOffset,\r\n        valuesOffset,\r\n        epOptionsCount,\r\n      )) !== 0\r\n    ) {\r\n      checkLastError(`Can't append execution provider: ${epName}.`);\r\n    }\r\n  }\r\n};\r\n\r\nexport const setSessionOptions = async (options?: InferenceSession.SessionOptions): Promise<[number, number[]]> => {\r\n  const wasm = getInstance();\r\n  let sessionOptionsHandle = 0;\r\n  const allocs: number[] = [];\r\n\r\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\r\n  appendDefaultOptions(sessionOptions);\r\n\r\n  try {\r\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\r\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\r\n    const logIdDataOffset =\r\n      typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\r\n\r\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2; // Default to 2 - warning\r\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\r\n      throw new Error(`log severity level is not valid: ${logSeverityLevel}`);\r\n    }\r\n\r\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0; // Default to 0 - verbose\r\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\r\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\r\n    }\r\n\r\n    const optimizedModelFilePathOffset =\r\n      typeof sessionOptions.optimizedModelFilePath === 'string'\r\n        ? allocWasmString(sessionOptions.optimizedModelFilePath, allocs)\r\n        : 0;\r\n\r\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\r\n      graphOptimizationLevel,\r\n      !!sessionOptions.enableCpuMemArena,\r\n      !!sessionOptions.enableMemPattern,\r\n      executionMode,\r\n      !!sessionOptions.enableProfiling,\r\n      0,\r\n      logIdDataOffset,\r\n      logSeverityLevel,\r\n      logVerbosityLevel,\r\n      optimizedModelFilePathOffset,\r\n    );\r\n    if (sessionOptionsHandle === 0) {\r\n      checkLastError(\"Can't create session options.\");\r\n    }\r\n\r\n    if (sessionOptions.executionProviders) {\r\n      await setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\r\n    }\r\n\r\n    if (sessionOptions.enableGraphCapture !== undefined) {\r\n      if (typeof sessionOptions.enableGraphCapture !== 'boolean') {\r\n        throw new Error(`enableGraphCapture must be a boolean value: ${sessionOptions.enableGraphCapture}`);\r\n      }\r\n      appendSessionConfig(\r\n        sessionOptionsHandle,\r\n        'enableGraphCapture',\r\n        sessionOptions.enableGraphCapture.toString(),\r\n        allocs,\r\n      );\r\n    }\r\n\r\n    if (sessionOptions.freeDimensionOverrides) {\r\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\r\n        if (typeof name !== 'string') {\r\n          throw new Error(`free dimension override name must be a string: ${name}`);\r\n        }\r\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\r\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\r\n        }\r\n        const nameOffset = allocWasmString(name, allocs);\r\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\r\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\r\n        }\r\n      }\r\n    }\r\n\r\n    if (sessionOptions.extra !== undefined) {\r\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\r\n        appendSessionConfig(sessionOptionsHandle, key, value, allocs);\r\n      });\r\n    }\r\n\r\n    return [sessionOptionsHandle, allocs];\r\n  } catch (e) {\r\n    if (sessionOptionsHandle !== 0) {\r\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\r\n        checkLastError(\"Can't release session options.\");\r\n      }\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n    throw e;\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from 'onnxruntime-common';\r\n\r\n// a dummy type declaration for Float16Array in case any polyfill is available.\r\ndeclare global {\r\n  // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\r\n  const Float16Array: any;\r\n}\r\n\r\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\r\n\r\n/**\r\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\r\n */\r\nexport const enum DataType {\r\n  undefined = 0,\r\n  float = 1,\r\n  uint8 = 2,\r\n  int8 = 3,\r\n  uint16 = 4,\r\n  int16 = 5,\r\n  int32 = 6,\r\n  int64 = 7,\r\n  string = 8,\r\n  bool = 9,\r\n  float16 = 10,\r\n  double = 11,\r\n  uint32 = 12,\r\n  uint64 = 13,\r\n  complex64 = 14,\r\n  complex128 = 15,\r\n  bfloat16 = 16,\r\n\r\n  // 4-bit data-types\r\n  uint4 = 21,\r\n  int4 = 22,\r\n}\r\n\r\n/**\r\n * Map string tensor data to enum value\r\n */\r\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\r\n  switch (type) {\r\n    case 'int8':\r\n      return DataType.int8;\r\n    case 'uint8':\r\n      return DataType.uint8;\r\n    case 'bool':\r\n      return DataType.bool;\r\n    case 'int16':\r\n      return DataType.int16;\r\n    case 'uint16':\r\n      return DataType.uint16;\r\n    case 'int32':\r\n      return DataType.int32;\r\n    case 'uint32':\r\n      return DataType.uint32;\r\n    case 'float16':\r\n      return DataType.float16;\r\n    case 'float32':\r\n      return DataType.float;\r\n    case 'float64':\r\n      return DataType.double;\r\n    case 'string':\r\n      return DataType.string;\r\n    case 'int64':\r\n      return DataType.int64;\r\n    case 'uint64':\r\n      return DataType.uint64;\r\n    case 'int4':\r\n      return DataType.int4;\r\n    case 'uint4':\r\n      return DataType.uint4;\r\n\r\n    default:\r\n      throw new Error(`unsupported data type: ${type}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map enum value to string tensor data\r\n */\r\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\r\n  switch (typeProto) {\r\n    case DataType.int8:\r\n      return 'int8';\r\n    case DataType.uint8:\r\n      return 'uint8';\r\n    case DataType.bool:\r\n      return 'bool';\r\n    case DataType.int16:\r\n      return 'int16';\r\n    case DataType.uint16:\r\n      return 'uint16';\r\n    case DataType.int32:\r\n      return 'int32';\r\n    case DataType.uint32:\r\n      return 'uint32';\r\n    case DataType.float16:\r\n      return 'float16';\r\n    case DataType.float:\r\n      return 'float32';\r\n    case DataType.double:\r\n      return 'float64';\r\n    case DataType.string:\r\n      return 'string';\r\n    case DataType.int64:\r\n      return 'int64';\r\n    case DataType.uint64:\r\n      return 'uint64';\r\n    case DataType.int4:\r\n      return 'int4';\r\n    case DataType.uint4:\r\n      return 'uint4';\r\n\r\n    default:\r\n      throw new Error(`unsupported data type: ${typeProto}`);\r\n  }\r\n};\r\n\r\n/**\r\n * get tensor size in bytes by the given data type and dimensions\r\n * @returns size in integer or undefined if the data type is not supported\r\n */\r\nexport const calculateTensorSizeInBytes = (\r\n  dateType: number,\r\n  dimsOrSize: readonly number[] | number,\r\n): number | undefined => {\r\n  const elementSize = [\r\n    -1, // undefined = 0\r\n    4, // float = 1\r\n    1, // uint8 = 2\r\n    1, // int8 = 3\r\n    2, // uint16 = 4\r\n    2, // int16 = 5\r\n    4, // int32 = 6\r\n    8, // int64 = 7\r\n    -1, // string = 8\r\n    1, // bool = 9\r\n    2, // float16 = 10\r\n    8, // double = 11\r\n    4, // uint32 = 12\r\n    8, // uint64 = 13\r\n    -1, // complex64 = 14\r\n    -1, // complex128 = 15\r\n    -1, // bfloat16 = 16\r\n    -1, // FLOAT8E4M3FN = 17\r\n    -1, // FLOAT8E4M3FNUZ = 18\r\n    -1, // FLOAT8E5M2 = 19\r\n    -1, // FLOAT8E5M2FNUZ = 20\r\n    0.5, // uint4 = 21\r\n    0.5, // int4 = 22\r\n  ][dateType];\r\n\r\n  const size = typeof dimsOrSize === 'number' ? dimsOrSize : dimsOrSize.reduce((a, b) => a * b, 1);\r\n  return elementSize > 0 ? Math.ceil(size * elementSize) : undefined;\r\n};\r\n\r\n/**\r\n * get typed array constructor by the given tensor type\r\n */\r\nexport const tensorTypeToTypedArrayConstructor = (\r\n  type: Tensor.Type,\r\n):\r\n  | Float32ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Int8ArrayConstructor\r\n  | Uint16ArrayConstructor\r\n  | Int16ArrayConstructor\r\n  | Int32ArrayConstructor\r\n  | BigInt64ArrayConstructor\r\n  | Uint8ArrayConstructor\r\n  | Float64ArrayConstructor\r\n  | Uint32ArrayConstructor\r\n  | BigUint64ArrayConstructor => {\r\n  switch (type) {\r\n    case 'float16':\r\n      // allow Float16Array polyfill.\r\n      return typeof Float16Array !== 'undefined' && Float16Array.from ? Float16Array : Uint16Array;\r\n    case 'float32':\r\n      return Float32Array;\r\n    case 'uint8':\r\n      return Uint8Array;\r\n    case 'int8':\r\n      return Int8Array;\r\n    case 'uint16':\r\n      return Uint16Array;\r\n    case 'int16':\r\n      return Int16Array;\r\n    case 'int32':\r\n      return Int32Array;\r\n    case 'bool':\r\n      return Uint8Array;\r\n    case 'float64':\r\n      return Float64Array;\r\n    case 'uint32':\r\n      return Uint32Array;\r\n    case 'int64':\r\n      return BigInt64Array;\r\n    case 'uint64':\r\n      return BigUint64Array;\r\n    default:\r\n      throw new Error(`unsupported type: ${type}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map string log level to integer value\r\n */\r\nexport const logLevelStringToEnum = (logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal'): number => {\r\n  switch (logLevel) {\r\n    case 'verbose':\r\n      return 0;\r\n    case 'info':\r\n      return 1;\r\n    case 'warning':\r\n      return 2;\r\n    case 'error':\r\n      return 3;\r\n    case 'fatal':\r\n      return 4;\r\n    default:\r\n      throw new Error(`unsupported logging level: ${logLevel}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Check whether the given tensor type is supported by GPU buffer\r\n */\r\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes =>\r\n  type === 'float32' ||\r\n  type === 'float16' ||\r\n  type === 'int32' ||\r\n  type === 'int64' ||\r\n  type === 'uint32' ||\r\n  type === 'uint8' ||\r\n  type === 'bool' ||\r\n  type === 'uint4' ||\r\n  type === 'int4';\r\n\r\n/**\r\n * Check whether the given tensor type is supported by WebNN MLTensor\r\n */\r\nexport const isMLTensorSupportedType = (type: Tensor.Type): type is Tensor.MLTensorDataTypes =>\r\n  type === 'float32' ||\r\n  type === 'float16' ||\r\n  type === 'int32' ||\r\n  type === 'int64' ||\r\n  type === 'uint32' ||\r\n  type === 'uint64' ||\r\n  type === 'int8' ||\r\n  type === 'uint8' ||\r\n  type === 'bool' ||\r\n  type === 'uint4' ||\r\n  type === 'int4';\r\n\r\n/**\r\n * Map string data location to integer value\r\n */\r\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\r\n  switch (location) {\r\n    case 'none':\r\n      return 0;\r\n    case 'cpu':\r\n      return 1;\r\n    case 'cpu-pinned':\r\n      return 2;\r\n    case 'texture':\r\n      return 3;\r\n    case 'gpu-buffer':\r\n      return 4;\r\n    case 'ml-tensor':\r\n      return 5;\r\n    default:\r\n      throw new Error(`unsupported data location: ${location}`);\r\n  }\r\n};\r\n\r\n/**\r\n * Map integer data location to string value\r\n */\r\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation | undefined =>\r\n  (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer', 'ml-tensor'] as const)[location];\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { isNode } from './wasm-utils-env';\r\n\r\n/**\r\n * Load a file into a Uint8Array.\r\n *\r\n * @param file - the file to load. Can be a URL/path, a Blob, an ArrayBuffer, or a Uint8Array.\r\n * @returns a Uint8Array containing the file data.\r\n */\r\nexport const loadFile = async (file: string | Blob | ArrayBufferLike | Uint8Array): Promise<Uint8Array> => {\r\n  if (typeof file === 'string') {\r\n    if (isNode) {\r\n      // load file into ArrayBuffer in Node.js\r\n      try {\r\n        const { readFile } = require('node:fs/promises');\r\n        return new Uint8Array(await readFile(file));\r\n      } catch (e) {\r\n        if (e.code === 'ERR_FS_FILE_TOO_LARGE') {\r\n          // file is too large, use fs.createReadStream instead\r\n          const { createReadStream } = require('node:fs');\r\n          const stream = createReadStream(file);\r\n          const chunks: Uint8Array[] = [];\r\n          for await (const chunk of stream) {\r\n            chunks.push(chunk);\r\n          }\r\n          return new Uint8Array(Buffer.concat(chunks));\r\n        }\r\n        throw e;\r\n      }\r\n    } else {\r\n      // load file into ArrayBuffer in browsers\r\n      const response = await fetch(file);\r\n      if (!response.ok) {\r\n        throw new Error(`failed to load external data file: ${file}`);\r\n      }\r\n      const contentLengthHeader = response.headers.get('Content-Length');\r\n      const fileSize = contentLengthHeader ? parseInt(contentLengthHeader, 10) : 0;\r\n      if (fileSize < 1073741824 /* 1GB */) {\r\n        // when Content-Length header is not set, we cannot determine the file size. We assume it is small enough to\r\n        // load into memory.\r\n        return new Uint8Array(await response.arrayBuffer());\r\n      } else {\r\n        // file is too large, use stream instead\r\n        if (!response.body) {\r\n          throw new Error(`failed to load external data file: ${file}, no response body.`);\r\n        }\r\n        const reader = response.body.getReader();\r\n\r\n        let buffer;\r\n        try {\r\n          // try to create ArrayBuffer directly\r\n          buffer = new ArrayBuffer(fileSize);\r\n        } catch (e) {\r\n          if (e instanceof RangeError) {\r\n            // use WebAssembly Memory to allocate larger ArrayBuffer\r\n            const pages = Math.ceil(fileSize / 65536);\r\n            buffer = new WebAssembly.Memory({ initial: pages, maximum: pages }).buffer;\r\n          } else {\r\n            throw e;\r\n          }\r\n        }\r\n\r\n        let offset = 0;\r\n        // eslint-disable-next-line no-constant-condition\r\n        while (true) {\r\n          const { done, value } = await reader.read();\r\n          if (done) {\r\n            break;\r\n          }\r\n          const chunkSize = value.byteLength;\r\n          const chunk = new Uint8Array(buffer, offset, chunkSize);\r\n          chunk.set(value);\r\n          offset += chunkSize;\r\n        }\r\n        return new Uint8Array(buffer, 0, fileSize);\r\n      }\r\n    }\r\n  } else if (file instanceof Blob) {\r\n    return new Uint8Array(await file.arrayBuffer());\r\n  } else if (file instanceof Uint8Array) {\r\n    return file;\r\n  } else {\r\n    return new Uint8Array(file);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Tensor } from 'onnxruntime-common';\r\n\r\nimport { tensorTypeToTypedArrayConstructor } from '../wasm-common';\r\n\r\nexport const createView = (\r\n  dataBuffer: ArrayBuffer,\r\n  type: Tensor.Type,\r\n):\r\n  | Int32Array\r\n  | Uint32Array\r\n  | BigInt64Array\r\n  | BigUint64Array\r\n  | Uint8Array\r\n  | Float32Array\r\n  | Float64Array\r\n  | Int8Array\r\n  | Int16Array\r\n  | Uint16Array => new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\r\n\r\n/**\r\n * a TensorView does not own the data.\r\n */\r\nexport interface TensorView {\r\n  readonly data: number;\r\n  readonly dataType: number;\r\n  readonly dims: readonly number[];\r\n\r\n  /**\r\n   * get a Float16Array data view of the tensor data. tensor data must be on CPU.\r\n   */\r\n  getUint16Array(): Uint16Array;\r\n\r\n  /**\r\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\r\n   */\r\n  getFloat32Array(): Float32Array;\r\n\r\n  /**\r\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\r\n   */\r\n  getBigInt64Array(): BigInt64Array;\r\n\r\n  /**\r\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\r\n   */\r\n  getInt32Array(): Int32Array;\r\n\r\n  /**\r\n   * get a Uint16Array data view of the tensor data. tensor data must be on CPU.\r\n   */\r\n  getUint16Array(): Uint16Array;\r\n\r\n  /**\r\n   * create a new tensor view with the same data but different dimensions.\r\n   */\r\n  reshape(newDims: readonly number[]): TensorView;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Env } from 'onnxruntime-common';\r\n\r\nimport { logLevelStringToEnum } from '../wasm-common';\r\n\r\ntype LogLevel = NonNullable<Env['logLevel']>;\r\ntype MessageString = string;\r\ntype MessageFunction = () => string;\r\ntype Message = MessageString | MessageFunction;\r\n\r\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\r\n\r\nconst doLog = (level: number, message: string): void => {\r\n  // eslint-disable-next-line no-console\r\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\r\n};\r\n\r\nlet configLogLevel: LogLevel | undefined;\r\nlet debug: boolean | undefined;\r\n\r\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\r\n  configLogLevel = $configLogLevel;\r\n  debug = $debug;\r\n};\r\n\r\n/**\r\n * A simple logging utility to log messages to the console.\r\n */\r\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\r\n  const messageLevel = logLevelStringToEnum(logLevel);\r\n  const configLevel = logLevelStringToEnum(configLogLevel);\r\n  if (messageLevel >= configLevel) {\r\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\r\n  }\r\n};\r\n\r\n/**\r\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\r\n */\r\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\r\n  if (debug) {\r\n    LOG(...args);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { WebNNBackend } from '../backend-webnn';\r\nimport { tensorTypeToTypedArrayConstructor } from '../../wasm-common';\r\nimport { LOG_DEBUG } from '../log';\r\n\r\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\r\n// WebNN API specification.\r\n// https://github.com/webmachinelearning/webnn/issues/677\r\n/// <reference path=\"webnn.d.ts\" />\r\n\r\n/**\r\n * Map from MLOperandDataType to size in bits. Using bits instead of bytes to avoid possible precision loss on int4 and uint4.\r\n */\r\nconst webnnDataTypeToSize = new Map<MLOperandDataType, number>([\r\n  ['float32', 32],\r\n  ['float16', 16],\r\n  ['int32', 32],\r\n  ['uint32', 32],\r\n  ['int64', 64],\r\n  ['uint64', 64],\r\n  ['int8', 8],\r\n  ['uint8', 8],\r\n  ['int4', 4],\r\n  ['uint4', 4],\r\n]);\r\n\r\n// Convert integer data to an Int32Array buffer.\r\n// Supports conversion from int64, uint64, uint32, int8 and uint8 to int32.\r\nexport const convertDataToInt32 = (data: Uint8Array, dataType: MLOperandDataType): Uint8Array => {\r\n  if (dataType === 'int32') {\r\n    return data;\r\n  }\r\n\r\n  const dataTypeSize = webnnDataTypeToSize.get(dataType);\r\n  if (!dataTypeSize) {\r\n    throw new Error(`WebNN backend does not support data type: ${dataType}`);\r\n  }\r\n  const bytesPerElement = dataTypeSize / 8;\r\n  // Make sure the data length is a multiple of the data type size.\r\n  if (data.byteLength % bytesPerElement !== 0) {\r\n    throw new Error(`Invalid Uint8Array length - must be a multiple of ${bytesPerElement}.`);\r\n  }\r\n\r\n  // Convert Uint8Array to original typed array.\r\n  const numElements = data.byteLength / bytesPerElement;\r\n  const originalArray = new (tensorTypeToTypedArrayConstructor(dataType))(data.buffer, data.byteOffset, numElements);\r\n\r\n  switch (dataType) {\r\n    case 'int64':\r\n    case 'uint64': {\r\n      // Convert original typed array to Int32Array.\r\n      const int32Array = new Int32Array(numElements);\r\n      for (let i = 0; i < numElements; i++) {\r\n        const value = originalArray[i];\r\n\r\n        // Check for overflow.\r\n        if (value > 2147483647n || value < -2147483648n) {\r\n          throw new Error(`Can not convert int64 data to int32 - value out of range.`);\r\n        }\r\n\r\n        int32Array[i] = Number(value);\r\n      }\r\n\r\n      return new Uint8Array(int32Array.buffer);\r\n    }\r\n    case 'int8':\r\n    case 'uint8':\r\n    case 'uint32': {\r\n      // Check for overflow.\r\n      if (dataType === 'uint32') {\r\n        if (originalArray.some((value) => value > 2147483647)) {\r\n          throw new Error(`Can not convert uint32 data to int32 - value out of range.`);\r\n        }\r\n      }\r\n      // Convert original typed array to Int32Array.\r\n      const int32Array = Int32Array.from(originalArray, Number);\r\n      return new Uint8Array(int32Array.buffer);\r\n    }\r\n    default:\r\n      throw new Error(`Unsupported data conversion from ${dataType} to 'int32'`);\r\n  }\r\n};\r\n\r\n// Convert Int32Array data to original integer data buffer.\r\n// Supports conversion from int32 to int64, uint64, uint32, int8 and uint8.\r\nexport const convertInt32ToData = (data: Uint8Array, dataType: MLOperandDataType): Uint8Array => {\r\n  if (dataType === 'int32') {\r\n    return data;\r\n  }\r\n\r\n  // Make sure the data length is a multiple of 4 bytes (Int32Array).\r\n  if (data.byteLength % 4 !== 0) {\r\n    throw new Error('Invalid Uint8Array length - must be a multiple of 4 (int32).');\r\n  }\r\n\r\n  // Convert Uint8Array to Int32Array.\r\n  const numElements = data.byteLength / 4;\r\n  const int32Array = new Int32Array(data.buffer, data.byteOffset, numElements);\r\n\r\n  switch (dataType) {\r\n    case 'int64': {\r\n      const bigInt64Array = BigInt64Array.from(int32Array, BigInt);\r\n      return new Uint8Array(bigInt64Array.buffer);\r\n    }\r\n    case 'uint64': {\r\n      if (int32Array.some((value) => value < 0)) {\r\n        throw new Error('Can not convert int32 data to uin64 - negative value found.');\r\n      }\r\n      const bigUint64Array = BigUint64Array.from(int32Array, BigInt);\r\n      return new Uint8Array(bigUint64Array.buffer);\r\n    }\r\n    case 'int8': {\r\n      if (int32Array.some((value) => value < -128 || value > 127)) {\r\n        throw new Error('Can not convert int32 data to int8 - value out of range.');\r\n      }\r\n      const int8Array = Int8Array.from(int32Array, Number);\r\n      return new Uint8Array(int8Array.buffer);\r\n    }\r\n    case 'uint8': {\r\n      if (int32Array.some((value) => value < 0 || value > 255)) {\r\n        throw new Error('Can not convert int32 data to uint8 - value out of range.');\r\n      }\r\n      return Uint8Array.from(int32Array, Number);\r\n    }\r\n    case 'uint32': {\r\n      if (int32Array.some((value) => value < 0)) {\r\n        throw new Error('Can not convert int32 data to uint32 - negative value found.');\r\n      }\r\n      const uint32Array = Uint32Array.from(int32Array, Number);\r\n      return new Uint8Array(uint32Array.buffer);\r\n    }\r\n    default:\r\n      throw new Error(`Unsupported data conversion from 'int32' to ${dataType}`);\r\n  }\r\n};\r\n\r\nexport type TensorId = number;\r\n\r\n/**\r\n * Manages TensorId to MLTensor mapping.\r\n */\r\nexport interface TensorManager {\r\n  /**\r\n   * Reserve a new TensorId.\r\n   */\r\n  reserveTensorId(): TensorId;\r\n  /**\r\n   * Release a TensorId.\r\n   */\r\n  releaseTensorId(tensorId: TensorId): void;\r\n  /**\r\n   * Ensure a MLTensor is created for the TensorId.\r\n   */\r\n  ensureTensor(\r\n    sessionId: number,\r\n    tensorId: TensorId,\r\n    dataType: MLOperandDataType,\r\n    shape: readonly number[],\r\n    copyOld: boolean,\r\n  ): Promise<MLTensor>;\r\n  /**\r\n   * Upload data to a MLTensor.\r\n   */\r\n  upload(tensorId: TensorId, data: Uint8Array): void;\r\n  /**\r\n   * Download data from a MLTensor.\r\n   */\r\n  download(tensorId: TensorId): Promise<ArrayBuffer>;\r\n  download(tensorId: TensorId, dstTensor: ArrayBufferView | ArrayBuffer): Promise<undefined>;\r\n  /**\r\n   * Release all tensors for a given session.\r\n   */\r\n  releaseTensorsForSession(session: number): void;\r\n  /**\r\n   * Register an externally created MLTensor with a given session id and return a TensorId.\r\n   */\r\n  registerTensor(sessionId: number, mlTensor: MLTensor, dataType: MLOperandDataType, shape: number[]): TensorId;\r\n}\r\n\r\nlet tensorGuid = 1;\r\nconst createNewTensorId = (): TensorId => tensorGuid++;\r\n\r\n/**\r\n * Map from data type to fallback data type.\r\n * When the context does not support the original data type, use fallback data type as workaround.\r\n * Note: Currently, we only support fallback to int32 for certain integer data types.\r\n */\r\nconst webnnDataTypeToFallback = new Map<MLOperandDataType, MLOperandDataType>([\r\n  ['int8', 'int32'],\r\n  ['uint8', 'int32'],\r\n  ['uint32', 'int32'],\r\n  ['int64', 'int32'],\r\n]);\r\n\r\n/**\r\n * Calculate the byte length of a tensor with the given data type and shape.\r\n */\r\nconst calculateByteLength = (dataType: MLOperandDataType, shape: readonly number[]): number => {\r\n  const dataTypeSize = webnnDataTypeToSize.get(dataType);\r\n  if (!dataTypeSize) {\r\n    throw new Error(`WebNN backend does not support data type: ${dataType}`);\r\n  }\r\n  return shape.length > 0 ? Math.ceil((shape.reduce((a, b) => a * b) * dataTypeSize) / 8) : 0;\r\n};\r\n\r\n/**\r\n * TensorWrapper wraps an MLTensor and provides a way to track the last session that used it.\r\n */\r\nclass TensorWrapper {\r\n  // The id of the last session that used this tensor.\r\n  public sessionId: number;\r\n  // This flag is used to indicate whether the data has been converted to fallback data type.\r\n  public isDataConverted = false;\r\n\r\n  private mlContext: MLContext;\r\n  private mlTensor: MLTensor;\r\n  private dataType: MLOperandDataType;\r\n  // Fallback data type to use when the context does not support the original data type.\r\n  private fallbackDataType: MLOperandDataType | undefined;\r\n  private tensorShape: readonly number[];\r\n\r\n  constructor(descriptor: {\r\n    sessionId: number;\r\n    context: MLContext;\r\n    tensor: MLTensor;\r\n    dataType: MLOperandDataType;\r\n    shape: readonly number[];\r\n    fallbackDataType?: MLOperandDataType;\r\n  }) {\r\n    const { sessionId, context, tensor, dataType, shape, fallbackDataType } = descriptor;\r\n    this.sessionId = sessionId;\r\n    this.mlContext = context;\r\n    this.mlTensor = tensor;\r\n    this.dataType = dataType;\r\n    this.tensorShape = shape;\r\n    this.fallbackDataType = fallbackDataType;\r\n  }\r\n\r\n  public get tensor(): MLTensor {\r\n    return this.mlTensor;\r\n  }\r\n\r\n  public get type(): MLOperandDataType {\r\n    return this.dataType;\r\n  }\r\n\r\n  public get fallbackType(): MLOperandDataType | undefined {\r\n    return this.fallbackDataType;\r\n  }\r\n\r\n  public get shape(): readonly number[] {\r\n    return this.tensorShape;\r\n  }\r\n\r\n  public get byteLength(): number {\r\n    return calculateByteLength(this.dataType, this.tensorShape);\r\n  }\r\n\r\n  public destroy(): void {\r\n    LOG_DEBUG('verbose', () => '[WebNN] TensorWrapper.destroy');\r\n    this.mlTensor.destroy();\r\n  }\r\n\r\n  public write(data: Uint8Array): void {\r\n    this.mlContext.writeTensor(this.mlTensor, data);\r\n  }\r\n\r\n  public async read(): Promise<ArrayBuffer>;\r\n  public async read(dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined>;\r\n  public async read(dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined> {\r\n    if (this.fallbackDataType) {\r\n      // This tensor has been fallback to int32 as workaround, we need to read it as its original integer data type.\r\n      const data = await this.mlContext.readTensor(this.mlTensor);\r\n      const originalData = convertInt32ToData(new Uint8Array(data), this.dataType);\r\n\r\n      if (dstBuffer) {\r\n        const targetBuffer =\r\n          dstBuffer instanceof ArrayBuffer\r\n            ? new Uint8Array(dstBuffer)\r\n            : new Uint8Array(dstBuffer.buffer, dstBuffer.byteOffset, dstBuffer.byteLength);\r\n        targetBuffer.set(originalData);\r\n        return undefined;\r\n      } else {\r\n        return originalData.buffer;\r\n      }\r\n    } else {\r\n      return dstBuffer ? this.mlContext.readTensor(this.mlTensor, dstBuffer) : this.mlContext.readTensor(this.mlTensor);\r\n    }\r\n  }\r\n\r\n  public canReuseTensor(context: MLContext, dataType: MLOperandDataType, shape: readonly number[]): boolean {\r\n    return (\r\n      this.mlContext === context &&\r\n      this.dataType === dataType &&\r\n      this.tensorShape.length === shape.length &&\r\n      this.tensorShape.every((v, i) => v === shape[i])\r\n    );\r\n  }\r\n\r\n  public setIsDataConverted(isConverted: boolean): void {\r\n    this.isDataConverted = isConverted;\r\n  }\r\n}\r\n\r\n/**\r\n * TensorTracker tracks the MLTensor and pending upload data.\r\n *\r\n * We need to track the MLTensor and pending upload data because we delay the creation of MLTensor until\r\n * we know the data type and shape. This is because WebNN only support creating MLTensors with dataTypes and shape.\r\n */\r\nclass TensorIdTracker {\r\n  private activeUpload?: Uint8Array;\r\n\r\n  constructor(\r\n    private tensorManager: TensorManagerImpl,\r\n    private wrapper?: TensorWrapper,\r\n  ) {}\r\n\r\n  public get tensorWrapper(): TensorWrapper | undefined {\r\n    return this.wrapper;\r\n  }\r\n\r\n  public releaseTensor(): void {\r\n    if (this.tensorWrapper) {\r\n      this.tensorManager.releaseTensor(this.tensorWrapper);\r\n      this.wrapper = undefined;\r\n    }\r\n  }\r\n\r\n  public async ensureTensor(\r\n    sessionId: number,\r\n    dataType: MLOperandDataType,\r\n    shape: readonly number[],\r\n    copyOld: boolean,\r\n  ): Promise<MLTensor> {\r\n    const context = this.tensorManager.getMLContext(sessionId);\r\n    let fallbackDataType: MLOperandDataType | undefined;\r\n    // Check if the context supports the data type. If not, try to use the fallback data type.\r\n    if (!context.opSupportLimits().input.dataTypes.includes(dataType)) {\r\n      fallbackDataType = webnnDataTypeToFallback.get(dataType);\r\n      if (!fallbackDataType || !context.opSupportLimits().input.dataTypes.includes(fallbackDataType)) {\r\n        throw new Error(`WebNN backend does not support data type: ${dataType}`);\r\n      }\r\n      LOG_DEBUG(\r\n        'verbose',\r\n        () => `[WebNN] TensorIdTracker.ensureTensor: fallback dataType from ${dataType} to ${fallbackDataType}`,\r\n      );\r\n    }\r\n\r\n    if (this.wrapper) {\r\n      if (this.wrapper.canReuseTensor(context, dataType, shape)) {\r\n        return this.wrapper.tensor;\r\n      } else {\r\n        if (copyOld) {\r\n          if (this.wrapper.byteLength !== calculateByteLength(dataType, shape)) {\r\n            throw new Error('Unable to copy data to tensor with different size.');\r\n          }\r\n          this.activeUpload = new Uint8Array(await this.wrapper.read());\r\n        }\r\n        this.tensorManager.releaseTensor(this.wrapper);\r\n      }\r\n    }\r\n\r\n    // eslint-disable-next-line no-bitwise\r\n    const usage = typeof MLTensorUsage == 'undefined' ? undefined : MLTensorUsage.READ | MLTensorUsage.WRITE;\r\n    this.wrapper = await this.tensorManager.getCachedTensor(\r\n      sessionId,\r\n      dataType,\r\n      shape,\r\n      usage,\r\n      true,\r\n      true,\r\n      fallbackDataType,\r\n    );\r\n\r\n    if (copyOld && this.activeUpload) {\r\n      // We don't need to convert the original integer data to int32,\r\n      // because it has been converted when it was uploaded.\r\n      this.wrapper.write(this.activeUpload);\r\n      this.activeUpload = undefined;\r\n    }\r\n\r\n    return this.wrapper.tensor;\r\n  }\r\n\r\n  public upload(data: Uint8Array): void {\r\n    let newData = data;\r\n    if (this.wrapper) {\r\n      if (this.wrapper.fallbackType) {\r\n        if (this.wrapper.fallbackType === 'int32') {\r\n          // Convert original integer data to int32.\r\n          newData = convertDataToInt32(data, this.wrapper.type);\r\n          this.wrapper.setIsDataConverted(true);\r\n        } else {\r\n          throw new Error(`Unsupported fallback data type: ${this.wrapper.fallbackType}`);\r\n        }\r\n      }\r\n\r\n      // Check if the data size matches the tensor size.\r\n      if (data.byteLength === this.wrapper.byteLength) {\r\n        // Write the newData to the tensor.\r\n        this.wrapper.write(newData);\r\n        return;\r\n      } else {\r\n        LOG_DEBUG('verbose', () => 'Data size does not match tensor size. Releasing tensor.');\r\n        this.releaseTensor();\r\n      }\r\n    }\r\n\r\n    if (this.activeUpload) {\r\n      this.activeUpload.set(newData);\r\n    } else {\r\n      this.activeUpload = new Uint8Array(newData);\r\n    }\r\n  }\r\n\r\n  public async download(dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined> {\r\n    if (this.activeUpload) {\r\n      // If this.activeUpload has been converted to int32, we need to convert it back to original integer data type.\r\n      const dstData = this.wrapper?.isDataConverted\r\n        ? convertInt32ToData(this.activeUpload, this.wrapper?.type)\r\n        : this.activeUpload;\r\n\r\n      if (dstBuffer) {\r\n        if (dstBuffer instanceof ArrayBuffer) {\r\n          new Uint8Array(dstBuffer).set(dstData);\r\n        } else {\r\n          new Uint8Array(dstBuffer.buffer, dstBuffer.byteOffset, dstBuffer.byteLength).set(dstData);\r\n        }\r\n        return;\r\n      } else {\r\n        return dstData.buffer;\r\n      }\r\n    }\r\n    if (!this.wrapper) {\r\n      throw new Error('Tensor has not been created.');\r\n    }\r\n\r\n    if (!dstBuffer) {\r\n      return this.wrapper.read();\r\n    }\r\n    return this.wrapper.read(dstBuffer);\r\n  }\r\n}\r\n\r\nclass TensorManagerImpl implements TensorManager {\r\n  private tensorTrackersById: Map<TensorId, TensorIdTracker> = new Map();\r\n  private freeTensors: TensorWrapper[] = [];\r\n  private externalTensors: Set<TensorWrapper> = new Set();\r\n\r\n  constructor(private backend: WebNNBackend) {}\r\n\r\n  public getMLContext(sessionId: number): MLContext {\r\n    const context = this.backend.getMLContext(sessionId);\r\n    if (!context) {\r\n      throw new Error('MLContext not found for session.');\r\n    }\r\n    return context;\r\n  }\r\n\r\n  public reserveTensorId(): TensorId {\r\n    const tensorId = createNewTensorId();\r\n    this.tensorTrackersById.set(tensorId, new TensorIdTracker(this));\r\n    return tensorId;\r\n  }\r\n\r\n  public releaseTensorId(tensorId: TensorId): void {\r\n    const tensorTracker = this.tensorTrackersById.get(tensorId);\r\n    if (!tensorTracker) {\r\n      return;\r\n    }\r\n    this.tensorTrackersById.delete(tensorId);\r\n    if (tensorTracker.tensorWrapper) {\r\n      this.releaseTensor(tensorTracker.tensorWrapper);\r\n    }\r\n  }\r\n\r\n  public async ensureTensor(\r\n    sessionId: number,\r\n    tensorId: TensorId,\r\n    dataType: MLOperandDataType,\r\n    shape: number[],\r\n    copyOld: boolean,\r\n  ): Promise<MLTensor> {\r\n    LOG_DEBUG(\r\n      'verbose',\r\n      () =>\r\n        `[WebNN] TensorManager.ensureTensor {tensorId: ${tensorId}, dataType: ${\r\n          dataType\r\n        }, shape: ${shape}, copyOld: ${copyOld}}`,\r\n    );\r\n    const tensor = this.tensorTrackersById.get(tensorId);\r\n    if (!tensor) {\r\n      throw new Error('Tensor not found.');\r\n    }\r\n    return tensor.ensureTensor(sessionId, dataType, shape, copyOld);\r\n  }\r\n\r\n  public upload(tensorId: TensorId, data: Uint8Array): void {\r\n    const tensor = this.tensorTrackersById.get(tensorId);\r\n    if (!tensor) {\r\n      throw new Error('Tensor not found.');\r\n    }\r\n    tensor.upload(data);\r\n  }\r\n\r\n  public async download(tensorId: TensorId): Promise<ArrayBuffer>;\r\n  public async download(tensorId: TensorId, dstBuffer: ArrayBufferView | ArrayBuffer): Promise<undefined>;\r\n  async download(tensorId: TensorId, dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined> {\r\n    LOG_DEBUG(\r\n      'verbose',\r\n      () => `[WebNN] TensorManager.download {tensorId: ${tensorId}, dstBuffer: ${dstBuffer?.byteLength}}`,\r\n    );\r\n    const tensorTracker = this.tensorTrackersById.get(tensorId);\r\n    if (!tensorTracker) {\r\n      throw new Error('Tensor not found.');\r\n    }\r\n    return tensorTracker.download(dstBuffer);\r\n  }\r\n\r\n  public releaseTensorsForSession(sessionId: number): void {\r\n    for (const tensor of this.freeTensors) {\r\n      if (tensor.sessionId === sessionId) {\r\n        tensor.destroy();\r\n      }\r\n    }\r\n    this.freeTensors = this.freeTensors.filter((tensor) => tensor.sessionId !== sessionId);\r\n  }\r\n\r\n  public registerTensor(\r\n    sessionId: number,\r\n    mlTensor: MLTensor,\r\n    dataType: MLOperandDataType,\r\n    shape: readonly number[],\r\n  ): TensorId {\r\n    const context = this.getMLContext(sessionId);\r\n    const tensorId = createNewTensorId();\r\n    // Defaulting to READ | WRITE if usage is not provided.\r\n    // eslint-disable-next-line no-bitwise\r\n    const wrapper = new TensorWrapper({\r\n      sessionId,\r\n      context,\r\n      tensor: mlTensor,\r\n      dataType,\r\n      shape,\r\n    });\r\n    this.tensorTrackersById.set(tensorId, new TensorIdTracker(this, wrapper));\r\n    this.externalTensors.add(wrapper);\r\n    return tensorId;\r\n  }\r\n\r\n  /**\r\n   * Get or create an MLTensor with the given data type and shape.\r\n   */\r\n  public async getCachedTensor(\r\n    sessionId: number,\r\n    dataType: MLOperandDataType,\r\n    shape: readonly number[],\r\n    usage: MLTensorUsageFlags | undefined,\r\n    writable: boolean,\r\n    readable: boolean,\r\n    fallbackDataType?: MLOperandDataType,\r\n  ): Promise<TensorWrapper> {\r\n    const context = this.getMLContext(sessionId);\r\n    for (const [index, tensor] of this.freeTensors.entries()) {\r\n      if (tensor.canReuseTensor(context, dataType, shape)) {\r\n        LOG_DEBUG(\r\n          'verbose',\r\n          () =>\r\n            `[WebNN] Reusing tensor {dataType: ${dataType}, ${\r\n              fallbackDataType ? `fallbackDataType: ${fallbackDataType},` : ''\r\n            } shape: ${shape}`,\r\n        );\r\n        const wrapper = this.freeTensors.splice(index, 1)[0];\r\n        wrapper.sessionId = sessionId;\r\n        return wrapper;\r\n      }\r\n    }\r\n    LOG_DEBUG(\r\n      'verbose',\r\n      () =>\r\n        `[WebNN] MLContext.createTensor {dataType: ${dataType}, ${\r\n          fallbackDataType ? `fallbackDataType: ${fallbackDataType},` : ''\r\n        } shape: ${shape}}`,\r\n    );\r\n    const tensor = await context.createTensor({\r\n      dataType: fallbackDataType ?? dataType, // If fallback data type is provided, use it.\r\n      shape,\r\n      dimensions: shape,\r\n      usage,\r\n      writable,\r\n      readable,\r\n    });\r\n    return new TensorWrapper({ sessionId, context, tensor, dataType, shape, fallbackDataType });\r\n  }\r\n\r\n  /**\r\n   * Release tensor for reuse unless external.\r\n   */\r\n  public releaseTensor(tensorWrapper: TensorWrapper) {\r\n    if (this.externalTensors.has(tensorWrapper)) {\r\n      this.externalTensors.delete(tensorWrapper);\r\n    }\r\n    this.freeTensors.push(tensorWrapper);\r\n  }\r\n}\r\n\r\nexport const createTensorManager = (...args: ConstructorParameters<typeof TensorManagerImpl>): TensorManager =>\r\n  new TensorManagerImpl(...args);\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\r\n// WebNN API specification.\r\n// https://github.com/webmachinelearning/webnn/issues/677\r\n/// <reference path=\"webnn/webnn.d.ts\" />\r\n\r\nimport { Env, Tensor } from 'onnxruntime-common';\r\n\r\nimport { DataType, tensorDataTypeStringToEnum } from '../wasm-common';\r\nimport { getInstance } from '../wasm-factory';\r\n\r\nimport { createView } from './tensor-view';\r\nimport { TensorId, createTensorManager, convertDataToInt32 } from './webnn/tensor-manager';\r\nimport { configureLogger, LOG_DEBUG } from './log';\r\n\r\n/*\r\n * TensorProto::data_type to WebNN OperandType mapping.\r\n */\r\nconst onnxDataTypeToWebnnDataType = new Map<DataType, MLOperandDataType>([\r\n  [DataType.float, 'float32'],\r\n  [DataType.float16, 'float16'],\r\n  [DataType.int32, 'int32'],\r\n  [DataType.uint32, 'uint32'],\r\n  [DataType.int64, 'int64'],\r\n  [DataType.uint64, 'uint64'],\r\n  [DataType.int4, 'int4'],\r\n  [DataType.uint4, 'uint4'],\r\n  [DataType.int8, 'int8'],\r\n  [DataType.uint8, 'uint8'],\r\n  [DataType.bool, 'uint8'],\r\n]);\r\n\r\ntype MLContextEntry = {\r\n  gpuDevice?: GPUDevice;\r\n  options?: MLContextOptions;\r\n  mlContext: MLContext;\r\n};\r\n\r\nconst compareMLContextOptions = (a?: MLContextOptions, b?: MLContextOptions): boolean => {\r\n  if (a === b) {\r\n    return true;\r\n  }\r\n  if (a === undefined || b === undefined) {\r\n    return false;\r\n  }\r\n  const aKeys = Object.keys(a).sort() as Array<keyof typeof a>;\r\n  const bKeys = Object.keys(b).sort() as Array<keyof typeof b>;\r\n  return aKeys.length === bKeys.length && aKeys.every((key, index) => key === bKeys[index] && a[key] === b[key]);\r\n};\r\n\r\n/**\r\n * WebNN backend implementation. This class is used to keep track of the MLTensors created by the backend and keep track\r\n * of the current MLContext being used by the sessions.\r\n */\r\nexport class WebNNBackend {\r\n  /**\r\n   * Tensor managers for each session.\r\n   */\r\n  private tensorManager = createTensorManager(this);\r\n  /**\r\n   * Maps from session id to MLContexts.\r\n   */\r\n  private mlContextBySessionId = new Map<number, MLContext>();\r\n  /**\r\n   * Maps from MLContext to session ids.\r\n   */\r\n  private sessionIdsByMLContext = new Map<MLContext, Set<number>>();\r\n  /**\r\n   * Cache of MLContexts.\r\n   */\r\n  private mlContextCache: MLContextEntry[] = [];\r\n  /**\r\n   * Current session id.\r\n   */\r\n  private activeSessionId?: number;\r\n  /**\r\n   * Maps from session id to list of graph inputs.\r\n   */\r\n  private sessionGraphInputs: Map<number, string[]> = new Map();\r\n  /**\r\n   * Maps from session id to list of graph outputs.\r\n   */\r\n  private sessionGraphOutputs: Map<number, string[]> = new Map();\r\n  /**\r\n   * Temporary graph inputs for the current session.\r\n   * These inputs will be registered when the session is created.\r\n   */\r\n  private temporaryGraphInputs: string[] = [];\r\n  /**\r\n   * Temporary graph outputs for the current session.\r\n   * These outputs will be registered when the session is created.\r\n   */\r\n  private temporaryGraphOutputs: string[] = [];\r\n  /**\r\n   * Temporary tensors for the current session.\r\n   */\r\n  private temporarySessionTensorIds: Map<number, TensorId[]> = new Map();\r\n\r\n  constructor(env: Env) {\r\n    configureLogger(env.logLevel!, !!env.debug);\r\n  }\r\n\r\n  public get currentSessionId(): number {\r\n    if (this.activeSessionId === undefined) {\r\n      throw new Error('No active session');\r\n    }\r\n    return this.activeSessionId;\r\n  }\r\n\r\n  public onRunStart(sessionId: number): void {\r\n    LOG_DEBUG('verbose', () => `[WebNN] onRunStart {sessionId: ${sessionId}}`);\r\n    this.activeSessionId = sessionId;\r\n  }\r\n\r\n  public onRunEnd(sessionId: number): void {\r\n    LOG_DEBUG('verbose', () => `[WebNN] onRunEnd {sessionId: ${sessionId}}`);\r\n    const tensorIds = this.temporarySessionTensorIds.get(sessionId);\r\n    if (!tensorIds) {\r\n      return;\r\n    }\r\n    for (const tensorId of tensorIds) {\r\n      LOG_DEBUG('verbose', () => `[WebNN] releasing temporary tensor {tensorId: ${tensorId}}`);\r\n      this.tensorManager.releaseTensorId(tensorId);\r\n    }\r\n    this.temporarySessionTensorIds.delete(sessionId);\r\n    this.activeSessionId = undefined;\r\n  }\r\n\r\n  public async createMLContext(optionsOrDevice?: MLContextOptions | GPUDevice): Promise<MLContext> {\r\n    if (optionsOrDevice instanceof GPUDevice) {\r\n      const mlContextIndex = this.mlContextCache.findIndex((entry) => entry.gpuDevice === optionsOrDevice);\r\n      if (mlContextIndex !== -1) {\r\n        return this.mlContextCache[mlContextIndex].mlContext;\r\n      } else {\r\n        const mlContext = await navigator.ml.createContext(optionsOrDevice);\r\n        this.mlContextCache.push({ gpuDevice: optionsOrDevice, mlContext });\r\n        return mlContext;\r\n      }\r\n    } else if (optionsOrDevice === undefined) {\r\n      const mlContextIndex = this.mlContextCache.findIndex(\r\n        (entry) => entry.options === undefined && entry.gpuDevice === undefined,\r\n      );\r\n      if (mlContextIndex !== -1) {\r\n        return this.mlContextCache[mlContextIndex].mlContext;\r\n      } else {\r\n        const mlContext = await navigator.ml.createContext();\r\n        this.mlContextCache.push({ mlContext });\r\n        return mlContext;\r\n      }\r\n    }\r\n\r\n    const mlContextIndex = this.mlContextCache.findIndex((entry) =>\r\n      compareMLContextOptions(entry.options, optionsOrDevice),\r\n    );\r\n    if (mlContextIndex !== -1) {\r\n      return this.mlContextCache[mlContextIndex].mlContext;\r\n    } else {\r\n      const mlContext = await navigator.ml.createContext(optionsOrDevice);\r\n      this.mlContextCache.push({ options: optionsOrDevice, mlContext });\r\n      return mlContext;\r\n    }\r\n  }\r\n\r\n  public registerMLContext(sessionId: number, mlContext: MLContext): void {\r\n    this.mlContextBySessionId.set(sessionId, mlContext);\r\n    let sessionIds = this.sessionIdsByMLContext.get(mlContext);\r\n    if (!sessionIds) {\r\n      sessionIds = new Set();\r\n      this.sessionIdsByMLContext.set(mlContext, sessionIds);\r\n    }\r\n    sessionIds.add(sessionId);\r\n\r\n    if (this.temporaryGraphInputs.length > 0) {\r\n      this.sessionGraphInputs.set(sessionId, this.temporaryGraphInputs);\r\n      this.temporaryGraphInputs = [];\r\n    }\r\n    if (this.temporaryGraphOutputs.length > 0) {\r\n      this.sessionGraphOutputs.set(sessionId, this.temporaryGraphOutputs);\r\n      this.temporaryGraphOutputs = [];\r\n    }\r\n  }\r\n\r\n  public onReleaseSession(sessionId: number): void {\r\n    this.sessionGraphInputs.delete(sessionId);\r\n    this.sessionGraphOutputs.delete(sessionId);\r\n    const mlContext = this.mlContextBySessionId.get(sessionId)!;\r\n    if (!mlContext) {\r\n      // Current session is not a WebNN session.\r\n      return;\r\n    }\r\n    this.tensorManager.releaseTensorsForSession(sessionId);\r\n    this.mlContextBySessionId.delete(sessionId);\r\n    const sessionIds = this.sessionIdsByMLContext.get(mlContext)!;\r\n    sessionIds.delete(sessionId);\r\n    if (sessionIds.size === 0) {\r\n      this.sessionIdsByMLContext.delete(mlContext);\r\n      const mlContextIndex = this.mlContextCache.findIndex((entry) => entry.mlContext === mlContext);\r\n      if (mlContextIndex !== -1) {\r\n        this.mlContextCache.splice(mlContextIndex, 1);\r\n      }\r\n    }\r\n  }\r\n\r\n  public getMLContext(sessionId: number): MLContext | undefined {\r\n    return this.mlContextBySessionId.get(sessionId);\r\n  }\r\n\r\n  public reserveTensorId(): TensorId {\r\n    return this.tensorManager.reserveTensorId();\r\n  }\r\n\r\n  public releaseTensorId(tensorId: TensorId): void {\r\n    LOG_DEBUG('verbose', () => `[WebNN] releaseTensorId {tensorId: ${tensorId}}`);\r\n    this.tensorManager.releaseTensorId(tensorId);\r\n  }\r\n\r\n  public async ensureTensor(\r\n    sessionId: number | undefined,\r\n    tensorId: TensorId,\r\n    onnxDataType: DataType,\r\n    dimensions: number[],\r\n    copyOld: boolean,\r\n  ): Promise<MLTensor> {\r\n    const webnnDataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\r\n    if (!webnnDataType) {\r\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\r\n    }\r\n    return this.tensorManager.ensureTensor(\r\n      sessionId ?? this.currentSessionId,\r\n      tensorId,\r\n      webnnDataType,\r\n      dimensions,\r\n      copyOld,\r\n    );\r\n  }\r\n\r\n  public async createTemporaryTensor(\r\n    sessionId: number,\r\n    onnxDataType: DataType,\r\n    shape: readonly number[],\r\n  ): Promise<TensorId> {\r\n    LOG_DEBUG('verbose', () => `[WebNN] createTemporaryTensor {onnxDataType: ${onnxDataType}, shape: ${shape}}`);\r\n    const dataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\r\n    if (!dataType) {\r\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\r\n    }\r\n    const tensorId = this.tensorManager.reserveTensorId();\r\n    await this.tensorManager.ensureTensor(sessionId, tensorId, dataType, shape, false);\r\n    const tensorIds = this.temporarySessionTensorIds.get(sessionId);\r\n    if (!tensorIds) {\r\n      this.temporarySessionTensorIds.set(sessionId, [tensorId]);\r\n    } else {\r\n      tensorIds.push(tensorId);\r\n    }\r\n    return tensorId;\r\n  }\r\n\r\n  public uploadTensor(tensorId: TensorId, data: Uint8Array): void {\r\n    const wasm = getInstance();\r\n    if (!wasm.shouldTransferToMLTensor) {\r\n      throw new Error('Trying to upload to a MLTensor while shouldTransferToMLTensor is false');\r\n    }\r\n    LOG_DEBUG('verbose', () => `[WebNN] uploadTensor {tensorId: ${tensorId}, data: ${data.byteLength}}`);\r\n    this.tensorManager.upload(tensorId, data);\r\n  }\r\n\r\n  public async downloadTensor(tensorId: TensorId, dstBuffer: ArrayBufferView | ArrayBuffer): Promise<undefined> {\r\n    return this.tensorManager.download(tensorId, dstBuffer);\r\n  }\r\n\r\n  public createMLTensorDownloader(tensorId: TensorId, type: Tensor.MLTensorDataTypes): () => Promise<Tensor.DataType> {\r\n    return async () => {\r\n      const data = await this.tensorManager.download(tensorId);\r\n      return createView(data, type);\r\n    };\r\n  }\r\n\r\n  public registerMLTensor(sessionId: number, tensor: MLTensor, onnxDataType: DataType, dimensions: number[]): TensorId {\r\n    const webnnDataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\r\n    if (!webnnDataType) {\r\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\r\n    }\r\n\r\n    const id = this.tensorManager.registerTensor(sessionId, tensor, webnnDataType, dimensions);\r\n    LOG_DEBUG(\r\n      'verbose',\r\n      () =>\r\n        `[WebNN] registerMLTensor {tensor: ${tensor}, dataType: ${webnnDataType}, dimensions: ${\r\n          dimensions\r\n        }} -> {tensorId: ${id}}`,\r\n    );\r\n    return id;\r\n  }\r\n\r\n  // Register a WebNN Constant operand from external data.\r\n  public registerMLConstant(\r\n    externalFilePath: string,\r\n    dataOffset: number,\r\n    dataLength: number,\r\n    builder: MLGraphBuilder,\r\n    desc: MLOperandDescriptor,\r\n    mountedFiles: Map<string, Uint8Array> | undefined,\r\n    shouldConvertInt64ToInt32 = false,\r\n  ): MLOperand {\r\n    // If available, \"Module.MountedFiles\" is a Map for all preloaded files.\r\n    if (!mountedFiles) {\r\n      throw new Error('External mounted files are not available.');\r\n    }\r\n\r\n    let filePath = externalFilePath;\r\n    if (externalFilePath.startsWith('./')) {\r\n      filePath = externalFilePath.substring(2);\r\n    }\r\n    const fileData = mountedFiles.get(filePath);\r\n    if (!fileData) {\r\n      throw new Error(`File with name ${filePath} not found in preloaded files.`);\r\n    }\r\n\r\n    if (dataOffset + dataLength > fileData.byteLength) {\r\n      throw new Error('Out of bounds: data offset and length exceed the external file data size.');\r\n    }\r\n\r\n    const buffer = fileData.slice(dataOffset, dataOffset + dataLength).buffer;\r\n    let bufferView: ArrayBufferView;\r\n    switch (desc.dataType) {\r\n      case 'float32':\r\n        bufferView = new Float32Array(buffer);\r\n        break;\r\n      case 'float16':\r\n        bufferView =\r\n          typeof Float16Array !== 'undefined' && Float16Array.from ? new Float16Array(buffer) : new Uint16Array(buffer);\r\n        break;\r\n      case 'int32':\r\n        bufferView = new Int32Array(buffer);\r\n        break;\r\n      case 'uint32':\r\n        bufferView = new Uint32Array(buffer);\r\n        break;\r\n      case 'int64':\r\n        if (shouldConvertInt64ToInt32) {\r\n          // Int64 is not supported by current context, use int32 instead.\r\n          const int32Buffer = convertDataToInt32(new Uint8Array(buffer), 'int64');\r\n          bufferView = new Int32Array(int32Buffer.buffer);\r\n          desc.dataType = 'int32';\r\n        } else {\r\n          bufferView = new BigInt64Array(buffer);\r\n        }\r\n        break;\r\n      case 'uint64':\r\n        bufferView = new BigUint64Array(buffer);\r\n        break;\r\n      case 'int8':\r\n        bufferView = new Int8Array(buffer);\r\n        break;\r\n      case 'int4':\r\n      case 'uint4':\r\n      case 'uint8':\r\n        bufferView = new Uint8Array(buffer);\r\n        break;\r\n      default:\r\n        throw new Error(`Unsupported data type: ${desc.dataType} in creating WebNN Constant from external data.`);\r\n    }\r\n\r\n    LOG_DEBUG(\r\n      'verbose',\r\n      () =>\r\n        `[WebNN] registerMLConstant {dataType: ${desc.dataType}, shape: ${desc.shape}}} ${\r\n          shouldConvertInt64ToInt32 ? '(Note: it was int64 data type and registered to int32 as workaround)' : ''\r\n        }`,\r\n    );\r\n\r\n    return builder.constant(desc, bufferView);\r\n  }\r\n\r\n  public registerGraphInput(inputName: string): void {\r\n    this.temporaryGraphInputs.push(inputName);\r\n  }\r\n\r\n  public registerGraphOutput(outputName: string): void {\r\n    this.temporaryGraphOutputs.push(outputName);\r\n  }\r\n\r\n  public isGraphInput(sessionId: number, inputName: string): boolean {\r\n    const inputNames = this.sessionGraphInputs.get(sessionId);\r\n    if (!inputNames) {\r\n      return false;\r\n    }\r\n    return inputNames.includes(inputName);\r\n  }\r\n\r\n  public isGraphOutput(sessionId: number, outputName: string): boolean {\r\n    const outputNames = this.sessionGraphOutputs.get(sessionId);\r\n    if (!outputNames) {\r\n      return false;\r\n    }\r\n    return outputNames.includes(outputName);\r\n  }\r\n\r\n  public isGraphInputOutputTypeSupported(sessionId: number, type: Tensor.Type, isInput = true): boolean {\r\n    const context = this.mlContextBySessionId.get(sessionId);\r\n    const dataType = onnxDataTypeToWebnnDataType.get(tensorDataTypeStringToEnum(type));\r\n\r\n    if (typeof dataType === 'undefined') {\r\n      return false;\r\n    }\r\n\r\n    if (isInput) {\r\n      return !!context?.opSupportLimits().input.dataTypes.includes(dataType);\r\n    } else {\r\n      return !!context?.opSupportLimits().output.dataTypes.includes(dataType);\r\n    }\r\n  }\r\n\r\n  public flush(): void {\r\n    // Unlike the WebGPU backend, the WebNN backend does not need to flush any pending operations.\r\n  }\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\r\n// WebNN API specification.\r\n// https://github.com/webmachinelearning/webnn/issues/677\r\n/// <reference path=\"jsep/webnn/webnn.d.ts\" />\r\n\r\nimport { Env, InferenceSession, Tensor, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from 'onnxruntime-common';\r\n\r\nimport {\r\n  SerializableInternalBuffer,\r\n  SerializableSessionMetadata,\r\n  SerializableTensorMetadata,\r\n  TensorMetadata,\r\n} from './proxy-messages';\r\nimport { setRunOptions } from './run-options';\r\nimport { setSessionOptions } from './session-options';\r\nimport {\r\n  calculateTensorSizeInBytes,\r\n  dataLocationStringToEnum,\r\n  isGpuBufferSupportedType,\r\n  isMLTensorSupportedType,\r\n  logLevelStringToEnum,\r\n  tensorDataTypeEnumToString,\r\n  tensorDataTypeStringToEnum,\r\n  tensorTypeToTypedArrayConstructor,\r\n} from './wasm-common';\r\nimport { getInstance } from './wasm-factory';\r\nimport { allocWasmString, checkLastError } from './wasm-utils';\r\nimport { loadFile } from './wasm-utils-load-file';\r\n\r\n// #region Initializations\r\n\r\n/**\r\n * There are 4 different \"initialization\" steps for ORT. They happen in different places and different time.\r\n *\r\n * 1. JavaScript initialization for onnxruntime-common and onnxruntime-web.\r\n *    This is the first initialization step. In this step, onnxruntime-web calls onnxruntime-common's registerBackend()\r\n * function multiple times to register all the available backends. The backend registration is very fast. It only\r\n * registers the backend name with the uninitialized backend object. No heavy initialization is done in this step.\r\n *    Refer to web/lib/index.ts for the backend registration.\r\n *\r\n * 2. WebAssembly artifact initialization.\r\n *    This happens when any registered wasm backend is used for the first time (ie. `ort.InferenceSession.create()` is\r\n * called). In this step, onnxruntime-web does the followings:\r\n *     - create a proxy worker and make sure the proxy worker is ready to receive messages, if proxy is enabled.\r\n *     - perform feature detection, locate correct WebAssembly artifact path and call the Emscripten generated\r\n * JavaScript code to initialize the WebAssembly runtime.\r\n *         - if proxy is enabled, this step happens in the proxy worker using message 'init-wasm'.\r\n *         - downloading the 'ort-wasm{...}.wasm' file is done in this step.\r\n *         - if multi-thread is enabled, one or more webworker will be created to initialize the PThread threadpool.\r\n *\r\n * 3. ORT environment initialization.\r\n *    This happens after step 2. In this step, onnxruntime-web performs ONNX Runtime environment initialization.\r\n * Function `_OrtInit()` is called in this step.\r\n *     - if proxy is enabled, this step happens in the proxy worker using message 'init-ort'.\r\n *     - logging level (ort.env.logLevel) and thread number (ort.env.wasm.numThreads) are set in this step.\r\n *\r\n * 4. Session initialization.\r\n *    This happens when `ort.InferenceSession.create()` is called. Unlike the first 3 steps (they only called once),\r\n * this step will be done for each session. In this step, onnxruntime-web does the followings:\r\n *    If the parameter is a URL:\r\n *    - download the model data from the URL.\r\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\r\n *    - dereference the model buffer. This step allows the original ArrayBuffer to be garbage collected.\r\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\r\n *\r\n *    If the parameter is a Uint8Array object:\r\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\r\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\r\n *\r\n *\r\n */\r\n\r\n/**\r\n * initialize ORT environment.\r\n *\r\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\r\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\r\n */\r\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\r\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\r\n  if (errorCode !== 0) {\r\n    checkLastError(\"Can't initialize onnxruntime.\");\r\n  }\r\n};\r\n\r\n/**\r\n * initialize runtime environment.\r\n * @param env passed in the environment config object.\r\n */\r\nexport const initRuntime = async (env: Env): Promise<void> => {\r\n  // init ORT\r\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\r\n};\r\n\r\n/**\r\n * perform EP specific initialization.\r\n *\r\n * @param env\r\n * @param epName\r\n */\r\nexport const initEp = async (env: Env, epName: string): Promise<void> => {\r\n  // initialize ASYNCIFY support\r\n  getInstance().asyncInit?.();\r\n\r\n  // perform WebGPU availability check ( either JSEP or WebGPU EP )\r\n  let webgpuAdapter = env.webgpu.adapter as GPUAdapter | null;\r\n  if (epName === 'webgpu') {\r\n    if (typeof navigator === 'undefined' || !navigator.gpu) {\r\n      throw new Error('WebGPU is not supported in current environment');\r\n    }\r\n    if (!webgpuAdapter) {\r\n      // if adapter is not set, request a new adapter.\r\n      const powerPreference = env.webgpu.powerPreference;\r\n      if (powerPreference !== undefined && powerPreference !== 'low-power' && powerPreference !== 'high-performance') {\r\n        throw new Error(`Invalid powerPreference setting: \"${powerPreference}\"`);\r\n      }\r\n      const forceFallbackAdapter = env.webgpu.forceFallbackAdapter;\r\n      if (forceFallbackAdapter !== undefined && typeof forceFallbackAdapter !== 'boolean') {\r\n        throw new Error(`Invalid forceFallbackAdapter setting: \"${forceFallbackAdapter}\"`);\r\n      }\r\n      webgpuAdapter = await navigator.gpu.requestAdapter({ powerPreference, forceFallbackAdapter });\r\n      if (!webgpuAdapter) {\r\n        throw new Error(\r\n          'Failed to get GPU adapter. ' +\r\n            'You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.',\r\n        );\r\n      }\r\n    } else {\r\n      // if adapter is set, validate it.\r\n      if (\r\n        typeof webgpuAdapter.limits !== 'object' ||\r\n        typeof webgpuAdapter.features !== 'object' ||\r\n        typeof webgpuAdapter.requestDevice !== 'function'\r\n      ) {\r\n        throw new Error('Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.');\r\n      }\r\n    }\r\n  }\r\n\r\n  // perform WebNN availability check ( either JSEP or WebNN EP )\r\n  if (epName === 'webnn') {\r\n    if (typeof navigator === 'undefined' || !(navigator as unknown as { ml: unknown }).ml) {\r\n      throw new Error('WebNN is not supported in current environment');\r\n    }\r\n  }\r\n\r\n  if (!BUILD_DEFS.DISABLE_JSEP) {\r\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n    const initJsep = require('./jsep/init').init;\r\n\r\n    if (epName === 'webgpu') {\r\n      await initJsep('webgpu', getInstance(), env, webgpuAdapter);\r\n    }\r\n    if (epName === 'webnn') {\r\n      await initJsep('webnn', getInstance(), env);\r\n    }\r\n  } else {\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU && epName === 'webgpu') {\r\n      getInstance().webgpuInit!((device) => {\r\n        env.webgpu.device = device;\r\n      });\r\n    }\r\n    if (!BUILD_DEFS.DISABLE_WEBNN && epName === 'webnn') {\r\n      // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\r\n      const backend = new (require('./jsep/backend-webnn').WebNNBackend)(env);\r\n      getInstance().webnnInit!([\r\n        backend,\r\n        // webnnReserveTensorId\r\n        () => backend.reserveTensorId(),\r\n        // webnnReleaseTensorId,\r\n        (tensorId: number) => backend.releaseTensorId(tensorId),\r\n        // webnnEnsureTensor\r\n        async (sessionId: number | undefined, tensorId: number, onnxDataType: number, shape: number[], copyOld) =>\r\n          backend.ensureTensor(sessionId, tensorId, onnxDataType, shape, copyOld),\r\n        // webnnUploadTensor\r\n        (tensorId: number, data: Uint8Array) => {\r\n          backend.uploadTensor(tensorId, data);\r\n        },\r\n        // webnnDownloadTensor\r\n        async (tensorId: number, dstBuffer: ArrayBufferView | ArrayBuffer) =>\r\n          backend.downloadTensor(tensorId, dstBuffer),\r\n        // webnnRegisterMLContext\r\n        (sessionId: number, mlContext: MLContext) => backend.registerMLContext(sessionId, mlContext),\r\n        // webnnEnableTraceEvent\r\n        !!env.trace,\r\n      ]);\r\n    }\r\n  }\r\n};\r\n\r\n// #endregion Initializations\r\n\r\n/**\r\n * valid data locations for input/output tensors.\r\n */\r\ntype SupportedTensorDataLocationForInputOutput =\r\n  | 'cpu'\r\n  | 'cpu-pinned'\r\n  | 'gpu-buffer'\r\n  | 'ml-tensor'\r\n  // Use 'ml-tensor' during inference, but output a tensor located on the CPU.\r\n  | 'ml-tensor-cpu-output';\r\n\r\ntype IOBindingState = {\r\n  /**\r\n   * the handle of IO binding.\r\n   */\r\n  readonly handle: number;\r\n\r\n  /**\r\n   * the preferred location for each output tensor.\r\n   *\r\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer', 'ml-tensor'.\r\n   */\r\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\r\n\r\n  /**\r\n   * enum value of the preferred location for each output tensor.\r\n   */\r\n  readonly outputPreferredLocationsEncoded: readonly number[];\r\n};\r\n\r\n/**\r\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\r\n */\r\ntype SessionMetadata = [\r\n  inferenceSessionId: number,\r\n  inputNamesUTF8Encoded: number[],\r\n  outputNamesUTF8Encoded: number[],\r\n  bindingState: IOBindingState | null,\r\n  enableGraphCapture: boolean,\r\n  inputOutputBound: boolean,\r\n];\r\n\r\nconst activeSessions = new Map<number, SessionMetadata>();\r\n\r\n/**\r\n * get the input/output count of the session.\r\n * @param sessionHandle the handle representing the session. should be non-zero.\r\n * @returns a tuple including 2 numbers, representing the input count and output count.\r\n */\r\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\r\n  const wasm = getInstance();\r\n  const stack = wasm.stackSave();\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\r\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + ptrSize);\r\n    if (errorCode !== 0) {\r\n      checkLastError(\"Can't get session input/output count.\");\r\n    }\r\n    const type = ptrSize === 4 ? 'i32' : 'i64';\r\n    return [Number(wasm.getValue(dataOffset, type)), Number(wasm.getValue(dataOffset + ptrSize, type))];\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n\r\nconst getSessionInputOutputMetadata = (\r\n  sessionHandle: number,\r\n  index: number,\r\n): [nameOffset: number, elementType: number, dims?: Array<number | string>] => {\r\n  const wasm = getInstance();\r\n  const stack = wasm.stackSave();\r\n  let metadataOffset = 0;\r\n  try {\r\n    const ptrSize = wasm.PTR_SIZE;\r\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\r\n    const errorCode = wasm._OrtGetInputOutputMetadata(sessionHandle, index, dataOffset, dataOffset + ptrSize);\r\n    if (errorCode !== 0) {\r\n      checkLastError(\"Can't get session input/output metadata.\");\r\n    }\r\n    const nameOffset = Number(wasm.getValue(dataOffset, '*'));\r\n    metadataOffset = Number(wasm.getValue(dataOffset + ptrSize, '*'));\r\n    // get element type\r\n    const elementType = wasm.HEAP32[metadataOffset / 4];\r\n    if (elementType === 0) {\r\n      return [nameOffset, 0]; // non-tensor\r\n    }\r\n\r\n    // get dims count\r\n    const dimsCount = wasm.HEAPU32[metadataOffset / 4 + 1];\r\n    // get dims\r\n    const dims: Array<number | string> = [];\r\n    for (let i = 0; i < dimsCount; i++) {\r\n      const symbolicDimNameOffset = Number(wasm.getValue(metadataOffset + 8 + i * ptrSize, '*'));\r\n      dims.push(\r\n        symbolicDimNameOffset !== 0\r\n          ? wasm.UTF8ToString(symbolicDimNameOffset)\r\n          : Number(wasm.getValue(metadataOffset + 8 + (i + dimsCount) * ptrSize, '*')),\r\n      );\r\n    }\r\n    return [nameOffset, elementType, dims];\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n    if (metadataOffset !== 0) {\r\n      wasm._OrtFree(metadataOffset);\r\n    }\r\n  }\r\n};\r\n\r\n/**\r\n * allocate the memory and memcpy the external buffer.\r\n *\r\n * @param model - the external buffer containing the model data. Must not be the same buffer as the WASM heap.\r\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\r\n */\r\nexport const copyFromExternalBuffer = (model: Uint8Array): [number, number] => {\r\n  const wasm = getInstance();\r\n  const modelDataOffset = wasm._malloc(model.byteLength);\r\n  if (modelDataOffset === 0) {\r\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\r\n  }\r\n  wasm.HEAPU8.set(model, modelDataOffset);\r\n  return [modelDataOffset, model.byteLength];\r\n};\r\n\r\n/**\r\n * create an inference session from a model data buffer.\r\n *\r\n * @param modelData - either a Uint8Array object representing the model data, or a 2-elements tuple containing the\r\n *     pointer and size of the model data buffer.\r\n * @param options an optional session options object.\r\n * @returns a 3-elements tuple containing [session handle, input names, output names]\r\n */\r\nexport const createSession = async (\r\n  modelData: Uint8Array | SerializableInternalBuffer,\r\n  options?: InferenceSession.SessionOptions,\r\n): Promise<SerializableSessionMetadata> => {\r\n  let modelDataOffset: number, modelDataLength: number;\r\n  const wasm = getInstance();\r\n\r\n  if (Array.isArray(modelData)) {\r\n    // if model data is an array, it must be a 2-elements tuple containing the pointer and size of the model data\r\n    [modelDataOffset, modelDataLength] = modelData;\r\n  } else if (modelData.buffer === wasm.HEAPU8.buffer) {\r\n    // if model data uses the same buffer as the WASM heap, we don't need to copy it.\r\n    [modelDataOffset, modelDataLength] = [modelData.byteOffset, modelData.byteLength];\r\n  } else {\r\n    // otherwise, copy the model data to the WASM heap.\r\n    [modelDataOffset, modelDataLength] = copyFromExternalBuffer(modelData);\r\n  }\r\n\r\n  let sessionHandle = 0;\r\n  let sessionOptionsHandle = 0;\r\n  let ioBindingHandle = 0;\r\n  let allocs: number[] = [];\r\n  const inputNamesUTF8Encoded = [];\r\n  const outputNamesUTF8Encoded = [];\r\n\r\n  try {\r\n    [sessionOptionsHandle, allocs] = await setSessionOptions(options);\r\n\r\n    if (options?.externalData && wasm.mountExternalData) {\r\n      const loadingPromises = [];\r\n      for (const file of options.externalData) {\r\n        const path = typeof file === 'string' ? file : file.path;\r\n        loadingPromises.push(\r\n          loadFile(typeof file === 'string' ? file : file.data).then((data) => {\r\n            wasm.mountExternalData(path, data);\r\n          }),\r\n        );\r\n      }\r\n\r\n      // wait for all external data files to be loaded\r\n      await Promise.all(loadingPromises);\r\n    }\r\n\r\n    for (const provider of options?.executionProviders ?? []) {\r\n      const providerName = typeof provider === 'string' ? provider : provider.name;\r\n      if (providerName === 'webnn') {\r\n        wasm.shouldTransferToMLTensor = false;\r\n        if (typeof provider !== 'string') {\r\n          const webnnOptions = provider as InferenceSession.WebNNExecutionProviderOption;\r\n          const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\r\n          const gpuDevice = (webnnOptions as InferenceSession.WebNNOptionsWebGpu)?.gpuDevice;\r\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\r\n          const powerPreference = (webnnOptions as InferenceSession.WebNNContextOptions)?.powerPreference;\r\n          if (context) {\r\n            wasm.currentContext = context as MLContext;\r\n          } else if (gpuDevice) {\r\n            wasm.currentContext = await wasm.webnnCreateMLContext!(gpuDevice);\r\n          } else {\r\n            wasm.currentContext = await wasm.webnnCreateMLContext!({ deviceType, powerPreference });\r\n          }\r\n        } else {\r\n          wasm.currentContext = await wasm.webnnCreateMLContext!();\r\n        }\r\n        break;\r\n      }\r\n    }\r\n\r\n    sessionHandle = await wasm._OrtCreateSession(modelDataOffset, modelDataLength, sessionOptionsHandle);\r\n    wasm.webgpuOnCreateSession?.(sessionHandle);\r\n    if (sessionHandle === 0) {\r\n      checkLastError(\"Can't create a session.\");\r\n    }\r\n\r\n    wasm.jsepOnCreateSession?.();\r\n\r\n    // clear current MLContext after session creation\r\n    if (wasm.currentContext) {\r\n      wasm.webnnRegisterMLContext!(sessionHandle, wasm.currentContext);\r\n      wasm.currentContext = undefined;\r\n      wasm.shouldTransferToMLTensor = true;\r\n    }\r\n\r\n    const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\r\n\r\n    const enableGraphCapture = !!options?.enableGraphCapture;\r\n\r\n    const inputNames = [];\r\n    const outputNames = [];\r\n    const inputMetadata: InferenceSession.ValueMetadata[] = [];\r\n    const outputMetadata: InferenceSession.ValueMetadata[] = [];\r\n    const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\r\n    for (let i = 0; i < inputCount; i++) {\r\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i);\r\n      if (nameOffset === 0) {\r\n        checkLastError(\"Can't get an input name.\");\r\n      }\r\n      inputNamesUTF8Encoded.push(nameOffset);\r\n      const name = wasm.UTF8ToString(nameOffset);\r\n      inputNames.push(name);\r\n      inputMetadata.push(\r\n        elementType === 0\r\n          ? { name, isTensor: false }\r\n          : { name, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\r\n      );\r\n    }\r\n    for (let i = 0; i < outputCount; i++) {\r\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i + inputCount);\r\n      if (nameOffset === 0) {\r\n        checkLastError(\"Can't get an output name.\");\r\n      }\r\n      outputNamesUTF8Encoded.push(nameOffset);\r\n      const nameString = wasm.UTF8ToString(nameOffset);\r\n      outputNames.push(nameString);\r\n      outputMetadata.push(\r\n        elementType === 0\r\n          ? { name: nameString, isTensor: false }\r\n          : { name: nameString, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\r\n      );\r\n\r\n      if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\r\n        if (enableGraphCapture && options?.preferredOutputLocation === undefined) {\r\n          outputPreferredLocations.push('gpu-buffer');\r\n          continue;\r\n        }\r\n        const location =\r\n          typeof options?.preferredOutputLocation === 'string'\r\n            ? options.preferredOutputLocation\r\n            : (options?.preferredOutputLocation?.[nameString] ?? 'cpu');\r\n        const isGraphOutput = wasm.webnnIsGraphOutput;\r\n        if (location === 'cpu' && isGraphOutput && isGraphOutput(sessionHandle, nameString)) {\r\n          outputPreferredLocations.push('ml-tensor-cpu-output');\r\n          continue;\r\n        }\r\n        if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer' && location !== 'ml-tensor') {\r\n          throw new Error(`Not supported preferred output location: ${location}.`);\r\n        }\r\n        if (enableGraphCapture && location !== 'gpu-buffer') {\r\n          throw new Error(\r\n            `Not supported preferred output location: ${location}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`,\r\n          );\r\n        }\r\n        outputPreferredLocations.push(location);\r\n      }\r\n    }\r\n\r\n    // use IO binding only when at least one output is preferred to be on GPU.\r\n    let bindingState: IOBindingState | null = null;\r\n    if (\r\n      (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) &&\r\n      outputPreferredLocations.some((l) => l === 'gpu-buffer' || l === 'ml-tensor' || l === 'ml-tensor-cpu-output')\r\n    ) {\r\n      ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\r\n      if (ioBindingHandle === 0) {\r\n        checkLastError(\"Can't create IO binding.\");\r\n      }\r\n\r\n      bindingState = {\r\n        handle: ioBindingHandle,\r\n        outputPreferredLocations,\r\n        outputPreferredLocationsEncoded: outputPreferredLocations\r\n          // 'ml-tensor-cpu-output' is treated as 'ml-tensor' for the purpose of IO binding.\r\n          .map((l) => (l === 'ml-tensor-cpu-output' ? 'ml-tensor' : l))\r\n          .map((l) => dataLocationStringToEnum(l)),\r\n      };\r\n    }\r\n\r\n    activeSessions.set(sessionHandle, [\r\n      sessionHandle,\r\n      inputNamesUTF8Encoded,\r\n      outputNamesUTF8Encoded,\r\n      bindingState,\r\n      enableGraphCapture,\r\n      false,\r\n    ]);\r\n    return [sessionHandle, inputNames, outputNames, inputMetadata, outputMetadata];\r\n  } catch (e) {\r\n    inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n    outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n\r\n    if (ioBindingHandle !== 0) {\r\n      if (wasm._OrtReleaseBinding(ioBindingHandle) !== 0) {\r\n        checkLastError(\"Can't release IO binding.\");\r\n      }\r\n    }\r\n\r\n    if (sessionHandle !== 0) {\r\n      if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\r\n        checkLastError(\"Can't release session.\");\r\n      }\r\n    }\r\n    throw e;\r\n  } finally {\r\n    wasm._free(modelDataOffset);\r\n    if (sessionOptionsHandle !== 0) {\r\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\r\n        checkLastError(\"Can't release session options.\");\r\n      }\r\n    }\r\n    allocs.forEach((alloc) => wasm._free(alloc));\r\n\r\n    // unmount external data if necessary\r\n    wasm.unmountExternalData?.();\r\n  }\r\n};\r\n\r\nexport const releaseSession = (sessionId: number): void => {\r\n  const wasm = getInstance();\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\r\n  }\r\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState, enableGraphCapture] = session;\r\n\r\n  if (ioBindingState) {\r\n    if (enableGraphCapture) {\r\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\r\n        checkLastError(\"Can't clear bound outputs.\");\r\n      }\r\n    }\r\n    if (wasm._OrtReleaseBinding(ioBindingState.handle) !== 0) {\r\n      checkLastError(\"Can't release IO binding.\");\r\n    }\r\n  }\r\n\r\n  wasm.jsepOnReleaseSession?.(sessionId);\r\n  wasm.webnnOnReleaseSession?.(sessionId);\r\n  wasm.webgpuOnReleaseSession?.(sessionId);\r\n\r\n  inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n  outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\r\n  if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\r\n    checkLastError(\"Can't release session.\");\r\n  }\r\n  activeSessions.delete(sessionId);\r\n};\r\n\r\nexport const prepareInputOutputTensor = async (\r\n  tensor: TensorMetadata | null,\r\n  tensorHandles: number[],\r\n  allocs: number[],\r\n  sessionId: number,\r\n  tensorNameUTF8Encoded: number,\r\n  index: number,\r\n  enableGraphCapture = false,\r\n): Promise<void> => {\r\n  if (!tensor) {\r\n    tensorHandles.push(0);\r\n    return;\r\n  }\r\n\r\n  const wasm = getInstance();\r\n  const ptrSize = wasm.PTR_SIZE;\r\n\r\n  const dataType = tensor[0];\r\n  const dims = tensor[1];\r\n  const location = tensor[3];\r\n  let actualLocation = location;\r\n\r\n  let rawData: number;\r\n  let dataByteLength: number;\r\n\r\n  if (dataType === 'string' && (location === 'gpu-buffer' || location === 'ml-tensor')) {\r\n    throw new Error('String tensor is not supported on GPU.');\r\n  }\r\n\r\n  if (enableGraphCapture && location !== 'gpu-buffer') {\r\n    throw new Error(\r\n      `External buffer must be provided for input/output index ${index} when enableGraphCapture is true.`,\r\n    );\r\n  }\r\n\r\n  if (location === 'gpu-buffer') {\r\n    const gpuBuffer = tensor[2].gpuBuffer;\r\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\r\n\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n      const registerBuffer = wasm.webgpuRegisterBuffer;\r\n      if (!registerBuffer) {\r\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\r\n      }\r\n\r\n      rawData = registerBuffer(gpuBuffer, sessionId);\r\n    } else {\r\n      const registerBuffer = wasm.jsepRegisterBuffer;\r\n      if (!registerBuffer) {\r\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\r\n      }\r\n      rawData = registerBuffer(sessionId, index, gpuBuffer, dataByteLength);\r\n    }\r\n  } else if (location === 'ml-tensor') {\r\n    const mlTensor = tensor[2].mlTensor as MLTensor;\r\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\r\n\r\n    const registerMLTensor = wasm.webnnRegisterMLTensor;\r\n    if (!registerMLTensor) {\r\n      throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\r\n    }\r\n    rawData = registerMLTensor(sessionId, mlTensor, tensorDataTypeStringToEnum(dataType), dims);\r\n  } else {\r\n    const data = tensor[2];\r\n\r\n    if (Array.isArray(data)) {\r\n      // string tensor\r\n      dataByteLength = ptrSize * data.length;\r\n      rawData = wasm._malloc(dataByteLength);\r\n      allocs.push(rawData);\r\n      for (let i = 0; i < data.length; i++) {\r\n        if (typeof data[i] !== 'string') {\r\n          throw new TypeError(`tensor data at index ${i} is not a string`);\r\n        }\r\n        wasm.setValue(rawData + i * ptrSize, allocWasmString(data[i], allocs), '*');\r\n      }\r\n    } else {\r\n      const isGraphInput = wasm.webnnIsGraphInput;\r\n      const isGraphOutput = wasm.webnnIsGraphOutput;\r\n      if (dataType !== 'string' && isGraphInput && isGraphOutput) {\r\n        const tensorName = wasm.UTF8ToString(tensorNameUTF8Encoded);\r\n        // Promote the tensor to 'ml-tensor' if it is a graph input.\r\n        if (isGraphInput(sessionId, tensorName) || isGraphOutput(sessionId, tensorName)) {\r\n          const dataTypeEnum = tensorDataTypeStringToEnum(dataType);\r\n          dataByteLength = calculateTensorSizeInBytes(dataTypeEnum, dims)!;\r\n          actualLocation = 'ml-tensor';\r\n          const createTemporaryTensor = wasm.webnnCreateTemporaryTensor;\r\n          const uploadTensor = wasm.webnnUploadTensor;\r\n          if (!createTemporaryTensor || !uploadTensor) {\r\n            throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\r\n          }\r\n          const tensorId = await createTemporaryTensor(sessionId, dataTypeEnum, dims as number[]);\r\n          uploadTensor(tensorId, new Uint8Array(data.buffer, data.byteOffset, data.byteLength));\r\n          rawData = tensorId;\r\n        } else {\r\n          dataByteLength = data.byteLength;\r\n          rawData = wasm._malloc(dataByteLength);\r\n          allocs.push(rawData);\r\n          wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\r\n        }\r\n      } else {\r\n        dataByteLength = data.byteLength;\r\n        rawData = wasm._malloc(dataByteLength);\r\n        allocs.push(rawData);\r\n        wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\r\n      }\r\n    }\r\n  }\r\n\r\n  const stack = wasm.stackSave();\r\n  const dimsOffset = wasm.stackAlloc(4 * dims.length);\r\n  try {\r\n    dims.forEach((d, index) => wasm.setValue(dimsOffset + index * ptrSize, d, ptrSize === 4 ? 'i32' : 'i64'));\r\n    const tensor = wasm._OrtCreateTensor(\r\n      tensorDataTypeStringToEnum(dataType),\r\n      rawData,\r\n      dataByteLength,\r\n      dimsOffset,\r\n      dims.length,\r\n      dataLocationStringToEnum(actualLocation),\r\n    );\r\n    if (tensor === 0) {\r\n      checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\r\n    }\r\n    tensorHandles.push(tensor);\r\n  } finally {\r\n    wasm.stackRestore(stack);\r\n  }\r\n};\r\n\r\n/**\r\n * perform inference run\r\n */\r\nexport const run = async (\r\n  sessionId: number,\r\n  inputIndices: number[],\r\n  inputTensors: TensorMetadata[],\r\n  outputIndices: number[],\r\n  outputTensors: Array<TensorMetadata | null>,\r\n  options: InferenceSession.RunOptions,\r\n): Promise<TensorMetadata[]> => {\r\n  const wasm = getInstance();\r\n  const ptrSize = wasm.PTR_SIZE;\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\r\n  }\r\n  const sessionHandle = session[0];\r\n  const inputNamesUTF8Encoded = session[1];\r\n  const outputNamesUTF8Encoded = session[2];\r\n  const ioBindingState = session[3];\r\n  const enableGraphCapture = session[4];\r\n  const inputOutputBound = session[5];\r\n\r\n  const inputCount = inputIndices.length;\r\n  const outputCount = outputIndices.length;\r\n\r\n  let runOptionsHandle = 0;\r\n  let runOptionsAllocs: number[] = [];\r\n\r\n  const inputTensorHandles: number[] = [];\r\n  const outputTensorHandles: number[] = [];\r\n  const inputOutputAllocs: number[] = [];\r\n\r\n  const beforeRunStack = wasm.stackSave();\r\n  const inputValuesOffset = wasm.stackAlloc(inputCount * ptrSize);\r\n  const inputNamesOffset = wasm.stackAlloc(inputCount * ptrSize);\r\n  const outputValuesOffset = wasm.stackAlloc(outputCount * ptrSize);\r\n  const outputNamesOffset = wasm.stackAlloc(outputCount * ptrSize);\r\n\r\n  try {\r\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\r\n\r\n    TRACE_EVENT_BEGIN('wasm prepareInputOutputTensor');\r\n    // create input tensors\r\n    for (let i = 0; i < inputCount; i++) {\r\n      await prepareInputOutputTensor(\r\n        inputTensors[i],\r\n        inputTensorHandles,\r\n        inputOutputAllocs,\r\n        sessionId,\r\n        inputNamesUTF8Encoded[inputIndices[i]],\r\n        inputIndices[i],\r\n        enableGraphCapture,\r\n      );\r\n    }\r\n\r\n    // create output tensors\r\n    for (let i = 0; i < outputCount; i++) {\r\n      await prepareInputOutputTensor(\r\n        outputTensors[i],\r\n        outputTensorHandles,\r\n        inputOutputAllocs,\r\n        sessionId,\r\n        outputNamesUTF8Encoded[outputIndices[i]],\r\n        inputCount + outputIndices[i],\r\n        enableGraphCapture,\r\n      );\r\n    }\r\n    TRACE_EVENT_END('wasm prepareInputOutputTensor');\r\n\r\n    for (let i = 0; i < inputCount; i++) {\r\n      wasm.setValue(inputValuesOffset + i * ptrSize, inputTensorHandles[i], '*');\r\n      wasm.setValue(inputNamesOffset + i * ptrSize, inputNamesUTF8Encoded[inputIndices[i]], '*');\r\n    }\r\n    for (let i = 0; i < outputCount; i++) {\r\n      wasm.setValue(outputValuesOffset + i * ptrSize, outputTensorHandles[i], '*');\r\n      wasm.setValue(outputNamesOffset + i * ptrSize, outputNamesUTF8Encoded[outputIndices[i]], '*');\r\n    }\r\n\r\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState && !inputOutputBound) {\r\n      const { handle, outputPreferredLocations, outputPreferredLocationsEncoded } = ioBindingState;\r\n\r\n      if (inputNamesUTF8Encoded.length !== inputCount) {\r\n        throw new Error(\r\n          `input count from feeds (${inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`,\r\n        );\r\n      }\r\n\r\n      TRACE_EVENT_BEGIN('wasm bindInputsOutputs');\r\n      // process inputs\r\n      for (let i = 0; i < inputCount; i++) {\r\n        const index = inputIndices[i];\r\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\r\n        if (errorCode !== 0) {\r\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\r\n        }\r\n      }\r\n\r\n      // process pre-allocated outputs\r\n      for (let i = 0; i < outputCount; i++) {\r\n        const index = outputIndices[i];\r\n        const location = outputTensors[i]?.[3]; // undefined means output is not pre-allocated.\r\n\r\n        if (location) {\r\n          // output is pre-allocated. bind the tensor.\r\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\r\n          if (errorCode !== 0) {\r\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\r\n          }\r\n        } else {\r\n          // output is not pre-allocated. reset preferred location.\r\n          const errorCode = wasm._OrtBindOutput(\r\n            handle,\r\n            outputNamesUTF8Encoded[index],\r\n            0,\r\n            outputPreferredLocationsEncoded[index],\r\n          );\r\n          if (errorCode !== 0) {\r\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\r\n          }\r\n        }\r\n      }\r\n      TRACE_EVENT_END('wasm bindInputsOutputs');\r\n      activeSessions.set(sessionId, [\r\n        sessionHandle,\r\n        inputNamesUTF8Encoded,\r\n        outputNamesUTF8Encoded,\r\n        ioBindingState,\r\n        enableGraphCapture,\r\n        true,\r\n      ]);\r\n    }\r\n\r\n    wasm.jsepOnRunStart?.(sessionHandle);\r\n    wasm.webnnOnRunStart?.(sessionHandle);\r\n\r\n    let errorCode: number;\r\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState) {\r\n      errorCode = await wasm._OrtRunWithBinding(\r\n        sessionHandle,\r\n        ioBindingState.handle,\r\n        outputCount,\r\n        outputValuesOffset,\r\n        runOptionsHandle,\r\n      );\r\n    } else {\r\n      errorCode = await wasm._OrtRun(\r\n        sessionHandle,\r\n        inputNamesOffset,\r\n        inputValuesOffset,\r\n        inputCount,\r\n        outputNamesOffset,\r\n        outputCount,\r\n        outputValuesOffset,\r\n        runOptionsHandle,\r\n      );\r\n    }\r\n\r\n    if (errorCode !== 0) {\r\n      checkLastError('failed to call OrtRun().');\r\n    }\r\n\r\n    const output: TensorMetadata[] = [];\r\n    const outputPromises: Array<Promise<[number, Tensor.DataType]>> = [];\r\n\r\n    TRACE_EVENT_BEGIN('wasm ProcessOutputTensor');\r\n    for (let i = 0; i < outputCount; i++) {\r\n      const tensor = Number(wasm.getValue(outputValuesOffset + i * ptrSize, '*'));\r\n      if (tensor === outputTensorHandles[i]) {\r\n        // output tensor is pre-allocated. no need to copy data.\r\n        output.push(outputTensors[i]!);\r\n        continue;\r\n      }\r\n\r\n      const beforeGetTensorDataStack = wasm.stackSave();\r\n      // stack allocate 4 pointer value\r\n      const tensorDataOffset = wasm.stackAlloc(4 * ptrSize);\r\n\r\n      let keepOutputTensor = false;\r\n      let type: Tensor.Type | undefined,\r\n        dataOffset = 0;\r\n      try {\r\n        const errorCode = wasm._OrtGetTensorData(\r\n          tensor,\r\n          tensorDataOffset,\r\n          tensorDataOffset + ptrSize,\r\n          tensorDataOffset + 2 * ptrSize,\r\n\r\n          tensorDataOffset + 3 * ptrSize,\r\n        );\r\n        if (errorCode !== 0) {\r\n          checkLastError(`Can't access output tensor data on index ${i}.`);\r\n        }\r\n        const valueType = ptrSize === 4 ? 'i32' : 'i64';\r\n        const dataType = Number(wasm.getValue(tensorDataOffset, valueType));\r\n        dataOffset = wasm.getValue(tensorDataOffset + ptrSize, '*');\r\n        const dimsOffset = wasm.getValue(tensorDataOffset + ptrSize * 2, '*');\r\n        const dimsLength = Number(wasm.getValue(tensorDataOffset + ptrSize * 3, valueType));\r\n        const dims = [];\r\n        for (let i = 0; i < dimsLength; i++) {\r\n          dims.push(Number(wasm.getValue(dimsOffset + i * ptrSize, valueType)));\r\n        }\r\n        if (wasm._OrtFree(dimsOffset) !== 0) {\r\n          checkLastError(\"Can't free memory for tensor dims.\");\r\n        }\r\n        const size = dims.reduce((a, b) => a * b, 1);\r\n        type = tensorDataTypeEnumToString(dataType);\r\n\r\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\r\n\r\n        if (type === 'string') {\r\n          if (preferredLocation === 'gpu-buffer' || preferredLocation === 'ml-tensor') {\r\n            throw new Error('String tensor is not supported on GPU.');\r\n          }\r\n          const stringData: string[] = [];\r\n          for (let i = 0; i < size; i++) {\r\n            const offset = wasm.getValue(dataOffset + i * ptrSize, '*');\r\n            const nextOffset = wasm.getValue(dataOffset + (i + 1) * ptrSize, '*');\r\n            const maxBytesToRead = i === size - 1 ? undefined : nextOffset - offset;\r\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\r\n          }\r\n          output.push([type, dims, stringData, 'cpu']);\r\n        } else {\r\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\r\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\r\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\r\n            const getBuffer = !BUILD_DEFS.DISABLE_WEBGPU ? wasm.webgpuGetBuffer : wasm.jsepGetBuffer;\r\n            if (!getBuffer) {\r\n              throw new Error('preferredLocation \"gpu-buffer\" is not supported without using WebGPU.');\r\n            }\r\n            const gpuBuffer = getBuffer(dataOffset);\r\n            const bufferSize = calculateTensorSizeInBytes(dataType, size);\r\n            if (bufferSize === undefined || !isGpuBufferSupportedType(type)) {\r\n              throw new Error(`Unsupported data type: ${type}`);\r\n            }\r\n\r\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\r\n            keepOutputTensor = true;\r\n\r\n            if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n              wasm.webgpuRegisterBuffer!(gpuBuffer, sessionId, dataOffset);\r\n              const downloadDataFunction = wasm.webgpuCreateDownloader!(gpuBuffer, bufferSize, sessionId);\r\n              output.push([\r\n                type,\r\n                dims,\r\n                {\r\n                  gpuBuffer,\r\n                  download: async () => {\r\n                    const arrayBuffer = await downloadDataFunction();\r\n                    const data = new (tensorTypeToTypedArrayConstructor(type!))(arrayBuffer);\r\n                    return data as Tensor.DataTypeMap[Tensor.GpuBufferDataTypes];\r\n                  },\r\n                  dispose: () => {\r\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\r\n                      checkLastError(\"Can't release tensor.\");\r\n                    }\r\n                  },\r\n                },\r\n                'gpu-buffer',\r\n              ]);\r\n            } else {\r\n              output.push([\r\n                type,\r\n                dims,\r\n                {\r\n                  gpuBuffer,\r\n                  download: wasm.jsepCreateDownloader!(gpuBuffer, bufferSize, type),\r\n                  dispose: () => {\r\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\r\n                      checkLastError(\"Can't release tensor.\");\r\n                    }\r\n                  },\r\n                },\r\n                'gpu-buffer',\r\n              ]);\r\n            }\r\n          } else if (preferredLocation === 'ml-tensor' && size > 0) {\r\n            const ensureTensor = wasm.webnnEnsureTensor;\r\n            const isGraphInputOutputTypeSupported = wasm.webnnIsGraphInputOutputTypeSupported;\r\n            if (!ensureTensor || !isGraphInputOutputTypeSupported) {\r\n              throw new Error('preferredLocation \"ml-tensor\" is not supported without using WebNN.');\r\n            }\r\n            const tensorSize = calculateTensorSizeInBytes(dataType, size);\r\n            if (tensorSize === undefined || !isMLTensorSupportedType(type)) {\r\n              throw new Error(`Unsupported data type: ${type}`);\r\n            }\r\n            if (!isGraphInputOutputTypeSupported(sessionId, type, false)) {\r\n              throw new Error(\r\n                `preferredLocation \"ml-tensor\" for ${type} output is not supported by current WebNN Context.`,\r\n              );\r\n            }\r\n\r\n            // If the graph has been partitioned, the output tensor may have not been created. For this reason, we use\r\n            // ensureTensor to get/create the MLTensor. In which case, we don't need to copy the data if a new tensor\r\n            // has been created.\r\n            const mlTensor = await ensureTensor(sessionId, dataOffset, dataType, dims, false);\r\n\r\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\r\n            keepOutputTensor = true;\r\n\r\n            output.push([\r\n              type,\r\n              dims,\r\n              {\r\n                mlTensor,\r\n                download: wasm.webnnCreateMLTensorDownloader!(dataOffset, type),\r\n                dispose: () => {\r\n                  wasm.webnnReleaseTensorId!(dataOffset);\r\n                  wasm._OrtReleaseTensor(tensor);\r\n                },\r\n              },\r\n              'ml-tensor',\r\n            ]);\r\n          } else if (preferredLocation === 'ml-tensor-cpu-output' && size > 0) {\r\n            const data = wasm.webnnCreateMLTensorDownloader!(dataOffset, type as Tensor.MLTensorDataTypes)();\r\n            const index = output.length;\r\n            // Delay the data download and releasing the tensor until we can wait for all output tensors to be downloaded.\r\n            keepOutputTensor = true;\r\n            outputPromises.push(\r\n              (async () => {\r\n                const result: [number, Tensor.DataType] = [index, await data];\r\n                wasm.webnnReleaseTensorId!(dataOffset);\r\n                wasm._OrtReleaseTensor(tensor);\r\n                return result;\r\n              })(),\r\n            );\r\n            output.push([type, dims, [], 'cpu']);\r\n          } else {\r\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\r\n            const data = new typedArrayConstructor(size);\r\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength).set(\r\n              wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength),\r\n            );\r\n            output.push([type, dims, data, 'cpu']);\r\n          }\r\n        }\r\n      } finally {\r\n        wasm.stackRestore(beforeGetTensorDataStack);\r\n        if (type === 'string' && dataOffset) {\r\n          wasm._free(dataOffset);\r\n        }\r\n        if (!keepOutputTensor) {\r\n          wasm._OrtReleaseTensor(tensor);\r\n        }\r\n      }\r\n    }\r\n\r\n    if (ioBindingState && !enableGraphCapture) {\r\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\r\n        checkLastError(\"Can't clear bound outputs.\");\r\n      }\r\n      activeSessions.set(sessionId, [\r\n        sessionHandle,\r\n        inputNamesUTF8Encoded,\r\n        outputNamesUTF8Encoded,\r\n        ioBindingState,\r\n        enableGraphCapture,\r\n        false,\r\n      ]);\r\n    }\r\n    // Wait for all output tensor data to be downloaded.\r\n    for (const [index, data] of await Promise.all(outputPromises)) {\r\n      output[index][2] = data;\r\n    }\r\n    TRACE_EVENT_END('wasm ProcessOutputTensor');\r\n    return output;\r\n  } finally {\r\n    wasm.webnnOnRunEnd?.(sessionHandle);\r\n\r\n    wasm.stackRestore(beforeRunStack);\r\n\r\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\r\n      inputTensors.forEach((t) => {\r\n        if (t && t[3] === 'gpu-buffer') {\r\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\r\n        }\r\n      });\r\n      outputTensors.forEach((t) => {\r\n        if (t && t[3] === 'gpu-buffer') {\r\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\r\n        }\r\n      });\r\n    }\r\n    inputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\r\n    outputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\r\n    inputOutputAllocs.forEach((p) => wasm._free(p));\r\n\r\n    if (runOptionsHandle !== 0) {\r\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\r\n    }\r\n    runOptionsAllocs.forEach((p) => wasm._free(p));\r\n  }\r\n};\r\n\r\n/**\r\n * end profiling\r\n */\r\nexport const endProfiling = (sessionId: number): void => {\r\n  const wasm = getInstance();\r\n  const session = activeSessions.get(sessionId);\r\n  if (!session) {\r\n    throw new Error('invalid session id');\r\n  }\r\n  const sessionHandle = session[0];\r\n\r\n  // profile file name is not used yet, but it must be freed.\r\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\r\n  if (profileFileName === 0) {\r\n    checkLastError(\"Can't get an profile file name.\");\r\n  }\r\n  wasm._OrtFree(profileFileName);\r\n};\r\n\r\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\r\n  const buffers: ArrayBufferLike[] = [];\r\n  for (const tensor of tensors) {\r\n    const data = tensor[2];\r\n    if (!Array.isArray(data) && 'buffer' in data) {\r\n      buffers.push(data.buffer);\r\n    }\r\n  }\r\n  return buffers;\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { env, InferenceSession } from 'onnxruntime-common';\r\n\r\nimport {\r\n  OrtWasmMessage,\r\n  SerializableInternalBuffer,\r\n  SerializableSessionMetadata,\r\n  SerializableTensorMetadata,\r\n  TensorMetadata,\r\n} from './proxy-messages';\r\nimport * as core from './wasm-core-impl';\r\nimport { initializeWebAssembly } from './wasm-factory';\r\nimport {\r\n  importProxyWorker,\r\n  inferWasmPathPrefixFromScriptSrc,\r\n  isEsmImportMetaUrlHardcodedAsFileUri,\r\n} from './wasm-utils-import';\r\n\r\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\r\nlet proxyWorker: Worker | undefined;\r\nlet initializing = false;\r\nlet initialized = false;\r\nlet aborted = false;\r\nlet temporaryObjectUrl: string | undefined;\r\n\r\ntype PromiseCallbacks<T = void> = [resolve: (result: T) => void, reject: (reason: unknown) => void];\r\nlet initWasmCallbacks: PromiseCallbacks;\r\nconst queuedCallbacks: Map<OrtWasmMessage['type'], Array<PromiseCallbacks<unknown>>> = new Map();\r\n\r\nconst enqueueCallbacks = (type: OrtWasmMessage['type'], callbacks: PromiseCallbacks<unknown>): void => {\r\n  const queue = queuedCallbacks.get(type);\r\n  if (queue) {\r\n    queue.push(callbacks);\r\n  } else {\r\n    queuedCallbacks.set(type, [callbacks]);\r\n  }\r\n};\r\n\r\nconst ensureWorker = (): void => {\r\n  if (initializing || !initialized || aborted || !proxyWorker) {\r\n    throw new Error('worker not ready');\r\n  }\r\n};\r\n\r\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\r\n  switch (ev.data.type) {\r\n    case 'init-wasm':\r\n      initializing = false;\r\n      if (ev.data.err) {\r\n        aborted = true;\r\n        initWasmCallbacks[1](ev.data.err);\r\n      } else {\r\n        initialized = true;\r\n        initWasmCallbacks[0]();\r\n      }\r\n      if (temporaryObjectUrl) {\r\n        URL.revokeObjectURL(temporaryObjectUrl);\r\n        temporaryObjectUrl = undefined;\r\n      }\r\n      break;\r\n    case 'init-ep':\r\n    case 'copy-from':\r\n    case 'create':\r\n    case 'release':\r\n    case 'run':\r\n    case 'end-profiling': {\r\n      const callbacks = queuedCallbacks.get(ev.data.type)!;\r\n      if (ev.data.err) {\r\n        callbacks.shift()![1](ev.data.err);\r\n      } else {\r\n        callbacks.shift()![0](ev.data.out!);\r\n      }\r\n      break;\r\n    }\r\n    default:\r\n  }\r\n};\r\n\r\nexport const initializeWebAssemblyAndOrtRuntime = async (): Promise<void> => {\r\n  if (initialized) {\r\n    return;\r\n  }\r\n  if (initializing) {\r\n    throw new Error(\"multiple calls to 'initWasm()' detected.\");\r\n  }\r\n  if (aborted) {\r\n    throw new Error(\"previous call to 'initWasm()' failed.\");\r\n  }\r\n\r\n  initializing = true;\r\n\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    return new Promise<void>((resolve, reject) => {\r\n      proxyWorker?.terminate();\r\n\r\n      void importProxyWorker().then(([objectUrl, worker]) => {\r\n        try {\r\n          proxyWorker = worker;\r\n          proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\r\n          proxyWorker.onmessage = onProxyWorkerMessage;\r\n          initWasmCallbacks = [resolve, reject];\r\n          const message: OrtWasmMessage = { type: 'init-wasm', in: env };\r\n\r\n          // if the proxy worker is loaded from a blob URL, we need to make sure the path information is not lost.\r\n          //\r\n          // when `env.wasm.wasmPaths` is not set, we need to pass the path information to the worker.\r\n          //\r\n          if (!BUILD_DEFS.ENABLE_BUNDLE_WASM_JS && !message.in!.wasm.wasmPaths && objectUrl) {\r\n            // for a build not bundled the wasm JS, we need to pass the path prefix to the worker.\r\n            // the path prefix will be used to resolve the path to both the wasm JS and the wasm file.\r\n            const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\r\n            if (inferredWasmPathPrefix) {\r\n              message.in!.wasm.wasmPaths = inferredWasmPathPrefix;\r\n            }\r\n          }\r\n\r\n          if (\r\n            BUILD_DEFS.IS_ESM &&\r\n            BUILD_DEFS.ENABLE_BUNDLE_WASM_JS &&\r\n            !message.in!.wasm.wasmPaths &&\r\n            (objectUrl || isEsmImportMetaUrlHardcodedAsFileUri)\r\n          ) {\r\n            // for a build bundled the wasm JS, if either of the following conditions is met:\r\n            // - the proxy worker is loaded from a blob URL\r\n            // - `import.meta.url` is a file URL, it means it is overwritten by the bundler.\r\n            //\r\n            // in either case, the path information is lost, we need to pass the path of the .wasm file to the worker.\r\n            // we need to use the bundler preferred URL format:\r\n            // new URL('filename', import.meta.url)\r\n            // so that the bundler can handle the file using corresponding loaders.\r\n            message.in!.wasm.wasmPaths = {\r\n              wasm: !BUILD_DEFS.DISABLE_JSEP\r\n                ? new URL('ort-wasm-simd-threaded.jsep.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\r\n                : !BUILD_DEFS.DISABLE_WEBGPU\r\n                  ? new URL('ort-wasm-simd-threaded.asyncify.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\r\n                  : new URL('ort-wasm-simd-threaded.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href,\r\n            };\r\n          }\r\n          proxyWorker.postMessage(message);\r\n          temporaryObjectUrl = objectUrl;\r\n        } catch (e) {\r\n          reject(e);\r\n        }\r\n      }, reject);\r\n    });\r\n  } else {\r\n    try {\r\n      await initializeWebAssembly(env.wasm);\r\n      await core.initRuntime(env);\r\n      initialized = true;\r\n    } catch (e) {\r\n      aborted = true;\r\n      throw e;\r\n    } finally {\r\n      initializing = false;\r\n    }\r\n  }\r\n};\r\n\r\nexport const initializeOrtEp = async (epName: string): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('init-ep', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'init-ep', in: { epName, env } };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    await core.initEp(env, epName);\r\n  }\r\n};\r\n\r\nexport const copyFromExternalBuffer = async (buffer: Uint8Array): Promise<SerializableInternalBuffer> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<SerializableInternalBuffer>((resolve, reject) => {\r\n      enqueueCallbacks('copy-from', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'copy-from', in: { buffer } };\r\n      proxyWorker!.postMessage(message, [buffer.buffer]);\r\n    });\r\n  } else {\r\n    return core.copyFromExternalBuffer(buffer);\r\n  }\r\n};\r\n\r\nexport const createSession = async (\r\n  model: SerializableInternalBuffer | Uint8Array,\r\n  options?: InferenceSession.SessionOptions,\r\n): Promise<SerializableSessionMetadata> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    // check unsupported options\r\n    if (options?.preferredOutputLocation) {\r\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\r\n    }\r\n    ensureWorker();\r\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\r\n      enqueueCallbacks('create', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'create', in: { model, options: { ...options } } };\r\n      const transferable: Transferable[] = [];\r\n      if (model instanceof Uint8Array) {\r\n        transferable.push(model.buffer);\r\n      }\r\n      proxyWorker!.postMessage(message, transferable);\r\n    });\r\n  } else {\r\n    return core.createSession(model, options);\r\n  }\r\n};\r\n\r\nexport const releaseSession = async (sessionId: number): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('release', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'release', in: sessionId };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    core.releaseSession(sessionId);\r\n  }\r\n};\r\n\r\nexport const run = async (\r\n  sessionId: number,\r\n  inputIndices: number[],\r\n  inputs: TensorMetadata[],\r\n  outputIndices: number[],\r\n  outputs: Array<TensorMetadata | null>,\r\n  options: InferenceSession.RunOptions,\r\n): Promise<TensorMetadata[]> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    // check inputs location\r\n    if (inputs.some((t) => t[3] !== 'cpu')) {\r\n      throw new Error('input tensor on GPU is not supported for proxy.');\r\n    }\r\n    // check outputs location\r\n    if (outputs.some((t) => t)) {\r\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\r\n    }\r\n    ensureWorker();\r\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\r\n      enqueueCallbacks('run', [resolve, reject]);\r\n      const serializableInputs = inputs as SerializableTensorMetadata[]; // every input is on CPU.\r\n      const message: OrtWasmMessage = {\r\n        type: 'run',\r\n        in: { sessionId, inputIndices, inputs: serializableInputs, outputIndices, options },\r\n      };\r\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\r\n    });\r\n  } else {\r\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\r\n  }\r\n};\r\n\r\nexport const endProfiling = async (sessionId: number): Promise<void> => {\r\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\r\n    ensureWorker();\r\n    return new Promise<void>((resolve, reject) => {\r\n      enqueueCallbacks('end-profiling', [resolve, reject]);\r\n      const message: OrtWasmMessage = { type: 'end-profiling', in: sessionId };\r\n      proxyWorker!.postMessage(message);\r\n    });\r\n  } else {\r\n    core.endProfiling(sessionId);\r\n  }\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {\r\n  InferenceSession,\r\n  InferenceSessionHandler,\r\n  SessionHandler,\r\n  Tensor,\r\n  TRACE_FUNC_BEGIN,\r\n  TRACE_FUNC_END,\r\n} from 'onnxruntime-common';\r\n\r\nimport { SerializableInternalBuffer, TensorMetadata } from './proxy-messages';\r\nimport { copyFromExternalBuffer, createSession, endProfiling, releaseSession, run } from './proxy-wrapper';\r\nimport { isGpuBufferSupportedType, isMLTensorSupportedType } from './wasm-common';\r\nimport { isNode } from './wasm-utils-env';\r\nimport { loadFile } from './wasm-utils-load-file';\r\n\r\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\r\n  switch (tensor.location) {\r\n    case 'cpu':\r\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\r\n    case 'gpu-buffer':\r\n      return [tensor.type, tensor.dims, { gpuBuffer: tensor.gpuBuffer }, 'gpu-buffer'];\r\n    case 'ml-tensor':\r\n      return [tensor.type, tensor.dims, { mlTensor: tensor.mlTensor }, 'ml-tensor'];\r\n    default:\r\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\r\n  }\r\n};\r\n\r\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\r\n  switch (tensor[3]) {\r\n    case 'cpu':\r\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\r\n    case 'gpu-buffer': {\r\n      const dataType = tensor[0];\r\n      if (!isGpuBufferSupportedType(dataType)) {\r\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\r\n      }\r\n      const { gpuBuffer, download, dispose } = tensor[2];\r\n      return Tensor.fromGpuBuffer(gpuBuffer, { dataType, dims: tensor[1], download, dispose });\r\n    }\r\n    case 'ml-tensor': {\r\n      const dataType = tensor[0];\r\n      if (!isMLTensorSupportedType(dataType)) {\r\n        throw new Error(`not supported data type: ${dataType} for deserializing MLTensor tensor`);\r\n      }\r\n      const { mlTensor, download, dispose } = tensor[2];\r\n      return Tensor.fromMLTensor(mlTensor, { dataType, dims: tensor[1], download, dispose });\r\n    }\r\n    default:\r\n      throw new Error(`invalid data location: ${tensor[3]}`);\r\n  }\r\n};\r\n\r\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\r\n  private sessionId: number;\r\n\r\n  inputNames: readonly string[];\r\n  outputNames: readonly string[];\r\n  inputMetadata: readonly InferenceSession.ValueMetadata[];\r\n  outputMetadata: readonly InferenceSession.ValueMetadata[];\r\n\r\n  async fetchModelAndCopyToWasmMemory(path: string): Promise<SerializableInternalBuffer> {\r\n    // fetch model from url and move to wasm heap.\r\n    return copyFromExternalBuffer(await loadFile(path));\r\n  }\r\n\r\n  async loadModel(pathOrBuffer: string | Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\r\n    TRACE_FUNC_BEGIN();\r\n    let model: Parameters<typeof createSession>[0];\r\n\r\n    if (typeof pathOrBuffer === 'string') {\r\n      if (isNode) {\r\n        // node\r\n        model = await loadFile(pathOrBuffer);\r\n      } else {\r\n        // browser\r\n        // fetch model and copy to wasm heap.\r\n        model = await this.fetchModelAndCopyToWasmMemory(pathOrBuffer);\r\n      }\r\n    } else {\r\n      model = pathOrBuffer;\r\n    }\r\n\r\n    [this.sessionId, this.inputNames, this.outputNames, this.inputMetadata, this.outputMetadata] = await createSession(\r\n      model,\r\n      options,\r\n    );\r\n    TRACE_FUNC_END();\r\n  }\r\n\r\n  async dispose(): Promise<void> {\r\n    return releaseSession(this.sessionId);\r\n  }\r\n\r\n  async run(\r\n    feeds: SessionHandler.FeedsType,\r\n    fetches: SessionHandler.FetchesType,\r\n    options: InferenceSession.RunOptions,\r\n  ): Promise<SessionHandler.ReturnType> {\r\n    TRACE_FUNC_BEGIN();\r\n    const inputArray: Tensor[] = [];\r\n    const inputIndices: number[] = [];\r\n    Object.entries(feeds).forEach((kvp) => {\r\n      const name = kvp[0];\r\n      const tensor = kvp[1];\r\n      const index = this.inputNames.indexOf(name);\r\n      if (index === -1) {\r\n        throw new Error(`invalid input '${name}'`);\r\n      }\r\n      inputArray.push(tensor);\r\n      inputIndices.push(index);\r\n    });\r\n\r\n    const outputArray: Array<Tensor | null> = [];\r\n    const outputIndices: number[] = [];\r\n    Object.entries(fetches).forEach((kvp) => {\r\n      const name = kvp[0];\r\n      const tensor = kvp[1];\r\n      const index = this.outputNames.indexOf(name);\r\n      if (index === -1) {\r\n        throw new Error(`invalid output '${name}'`);\r\n      }\r\n      outputArray.push(tensor);\r\n      outputIndices.push(index);\r\n    });\r\n\r\n    const inputs = inputArray.map((t, i) =>\r\n      encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`),\r\n    );\r\n    const outputs = outputArray.map((t, i) =>\r\n      t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null,\r\n    );\r\n\r\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\r\n\r\n    const resultMap: SessionHandler.ReturnType = {};\r\n    for (let i = 0; i < results.length; i++) {\r\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\r\n    }\r\n    TRACE_FUNC_END();\r\n    return resultMap;\r\n  }\r\n\r\n  startProfiling(): void {\r\n    // TODO: implement profiling\r\n  }\r\n\r\n  endProfiling(): void {\r\n    void endProfiling(this.sessionId);\r\n  }\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport { Backend, env, InferenceSession, InferenceSessionHandler } from 'onnxruntime-common';\r\n\r\nimport { initializeOrtEp, initializeWebAssemblyAndOrtRuntime } from './wasm/proxy-wrapper';\r\nimport { OnnxruntimeWebAssemblySessionHandler } from './wasm/session-handler-inference';\r\n\r\n/**\r\n * This function initializes all flags for WebAssembly.\r\n *\r\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\r\n * being created, to override default value.\r\n */\r\nexport const initializeFlags = (): void => {\r\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\r\n    env.wasm.initTimeout = 0;\r\n  }\r\n\r\n  const simd = env.wasm.simd;\r\n  if (typeof simd !== 'boolean' && simd !== undefined && simd !== 'fixed' && simd !== 'relaxed') {\r\n    // eslint-disable-next-line no-console\r\n    console.warn(\r\n      `Property \"env.wasm.simd\" is set to unknown value \"${simd}\". Reset it to \\`false\\` and ignore SIMD feature checking.`,\r\n    );\r\n    env.wasm.simd = false;\r\n  }\r\n\r\n  if (typeof env.wasm.proxy !== 'boolean') {\r\n    env.wasm.proxy = false;\r\n  }\r\n\r\n  if (typeof env.wasm.trace !== 'boolean') {\r\n    env.wasm.trace = false;\r\n  }\r\n\r\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\r\n    // The following logic only applies when `ort.env.wasm.numThreads` is not set by user. We will always honor user's\r\n    // setting if it is provided.\r\n\r\n    // Browser: when crossOriginIsolated is false, SharedArrayBuffer is not available so WebAssembly threads will not\r\n    // work. In this case, we will set numThreads to 1.\r\n    //\r\n    // There is an exception: when the browser is configured to force-enable SharedArrayBuffer (e.g. Chromuim with\r\n    // --enable-features=SharedArrayBuffer), it is possible that `self.crossOriginIsolated` is false and\r\n    // SharedArrayBuffer is available at the same time. This is usually for testing. In this case,  we will still set\r\n    // numThreads to 1 here. If we want to enable multi-threading in test, we should set `ort.env.wasm.numThreads` to a\r\n    // value greater than 1.\r\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\r\n      env.wasm.numThreads = 1;\r\n    } else {\r\n      const numCpuLogicalCores =\r\n        typeof navigator === 'undefined' ? require('node:os').cpus().length : navigator.hardwareConcurrency;\r\n      env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\r\n    }\r\n  }\r\n};\r\n\r\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\r\n  /**\r\n   * This function initializes the WebAssembly backend.\r\n   *\r\n   * This function will be called only once for each backend name. It will be called the first time when\r\n   * `ort.InferenceSession.create()` is called with a registered backend name.\r\n   *\r\n   * @param backendName - the registered backend name.\r\n   */\r\n  async init(backendName: string): Promise<void> {\r\n    // populate wasm flags\r\n    initializeFlags();\r\n\r\n    // init wasm\r\n    await initializeWebAssemblyAndOrtRuntime();\r\n\r\n    // performe EP specific initialization\r\n    await initializeOrtEp(backendName);\r\n  }\r\n  createInferenceSessionHandler(\r\n    path: string,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n  createInferenceSessionHandler(\r\n    buffer: Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler>;\r\n  async createInferenceSessionHandler(\r\n    pathOrBuffer: string | Uint8Array,\r\n    options?: InferenceSession.SessionOptions,\r\n  ): Promise<InferenceSessionHandler> {\r\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\r\n    await handler.loadModel(pathOrBuffer, options);\r\n    return handler;\r\n  }\r\n}\r\n\r\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\r\n\r\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\r\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\r\n// So we import code inside the if-clause to allow bundler remove the code safely.\r\n\r\nexport * from 'onnxruntime-common';\r\nimport * as ort from 'onnxruntime-common';\r\nexport default ort;\r\n\r\nimport { registerBackend, env } from 'onnxruntime-common';\r\nimport { version } from './version';\r\n\r\nif (!BUILD_DEFS.DISABLE_WEBGL) {\r\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\r\n  registerBackend('webgl', onnxjsBackend, -10);\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_JSEP && !BUILD_DEFS.DISABLE_WEBGPU) {\r\n  throw new Error(\r\n    'The current build is specified to enable both JSEP and WebGPU EP. This is not a valid configuration. ' +\r\n      'JSEP and WebGPU EPs cannot be enabled at the same time.',\r\n  );\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_WEBNN && BUILD_DEFS.DISABLE_JSEP && BUILD_DEFS.DISABLE_WEBGPU) {\r\n  throw new Error(\r\n    'The current build is specified to enable WebNN EP without JSEP or WebGPU EP. This is not a valid configuration. ' +\r\n      'WebNN EP requires either JSEP or WebGPU EP to be enabled.',\r\n  );\r\n}\r\n\r\nif (!BUILD_DEFS.DISABLE_WASM) {\r\n  const wasmBackend = require('./backend-wasm').wasmBackend;\r\n  if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\r\n    registerBackend('webgpu', wasmBackend, 5);\r\n  }\r\n  if (!BUILD_DEFS.DISABLE_WEBNN) {\r\n    registerBackend('webnn', wasmBackend, 5);\r\n  }\r\n  registerBackend('cpu', wasmBackend, 10);\r\n  registerBackend('wasm', wasmBackend, 10);\r\n}\r\n\r\nObject.defineProperty(env.versions, 'web', { value: version, enumerable: true });\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\n// This file is generated by /js/scripts/update-version.ts\r\n// Do not modify file content manually.\r\n\r\nexport const version = '1.23.0';\r\n"]}